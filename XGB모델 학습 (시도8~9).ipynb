{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56d68521-30b2-457c-9209-e2794860002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 패키지\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 머신러닝 패키지\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 그래프 한글 표시\n",
    "plt.rcParams['font.family'] = 'NanumGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd9ba71-dffa-48bc-a60d-8c2e5cc71f73",
   "metadata": {},
   "source": [
    "<div style=\"background-color:red; padding:10px; border-radius:10px; font-size:18px;\">\n",
    "(시도 8)<br><br>\n",
    "요일 별, 월 별 가중치 파생변수 삭제 후 학습\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "259cc33a-b185-4d5b-bca3-a00deabbecf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>year_sin</th>\n",
       "      <th>year_cos</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  store  product  year  month  weekday  day  week_of_year   day_sin  \\\n",
       "0        3      0        4  2010      1        4    1            53  0.017213   \n",
       "1        3      0        3  2010      1        4    1            53  0.017213   \n",
       "2        3      0        1  2010      1        4    1            53  0.017213   \n",
       "3        3      0        2  2010      1        4    1            53  0.017213   \n",
       "4        3      1        0  2010      1        4    1            53  0.017213   \n",
       "\n",
       "    day_cos  month_sin  month_cos  year_sin  year_cos  group  \n",
       "0  0.999852        0.5   0.866025  0.781831   0.62349      4  \n",
       "1  0.999852        0.5   0.866025  0.781831   0.62349      4  \n",
       "2  0.999852        0.5   0.866025  0.781831   0.62349      4  \n",
       "3  0.999852        0.5   0.866025  0.781831   0.62349      4  \n",
       "4  0.999852        0.5   0.866025  0.781831   0.62349      4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# =================================================================================================================================\n",
    "# ==================================================== 시도 8 월별,요일별 가중치 삭제 후 제출 ==================================================\n",
    "# =================================================================================================================================\n",
    "\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "train = train.dropna()\n",
    "train = train.reset_index()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------데이터 전처리\n",
    "\n",
    "# 날짜 파생 변수 생성\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "train['year'] = train['date'].dt.year\n",
    "train['month'] = train['date'].dt.month\n",
    "train['weekday'] = train['date'].dt.weekday\n",
    "train['day'] = train['date'].dt.day\n",
    "train['day_of_week'] = train['date'].dt.dayofweek\n",
    "train['week_of_year'] = train['date'].dt.isocalendar().week\n",
    "train['day_sin'] = np.sin(2 * np.pi * train['day'] / 365)\n",
    "train['day_cos'] = np.cos(2 * np.pi * train['day'] / 365)\n",
    "train['month_sin'] = np.sin(2 * np.pi * train['month'] / 12)\n",
    "train['month_cos'] = np.cos(2 * np.pi * train['month'] / 12)\n",
    "train['year_sin'] = np.sin(2 * np.pi * train['year'] / 7)\n",
    "train['year_cos'] = np.cos(2 * np.pi * train['year'] / 7)\n",
    "train['group'] = (train['year'] - 2010) * 48 + train['month'] * 4 + train['day'] // 7\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------ 인코딩\n",
    "\n",
    "country_mapping = {\n",
    "    'Kenya': 0,\n",
    "    'Italy': 1,\n",
    "    'Finland': 2,\n",
    "    'Canada': 3,\n",
    "    'Singapore': 4,\n",
    "    'Norway': 5}\n",
    "train['country'] = train['country'].map(country_mapping)\n",
    "\n",
    "\n",
    "store_mapping = {\n",
    "    'Discount Stickers' : 0,\n",
    "    'Stickers for Less' : 1,\n",
    "    'Premium Sticker Mart' : 2}\n",
    "train['store'] = train['store'].map(store_mapping)\n",
    "\n",
    "product_mapping = {\n",
    "    'Holographic Goose' : 0,\n",
    "    'Kerneler' : 1,\n",
    "    'Kerneler Dark Mode' : 2,\n",
    "    'Kaggle Tiers' : 3,\n",
    "    'Kaggle' : 4}\n",
    "train['product'] = train['product'].map(product_mapping)\n",
    "\n",
    "\n",
    "'''\n",
    "# (월,화,수,목 = 0) (금 = 1) (토 = 2) (일 = 3)\n",
    "weekday_mapping = {\n",
    "    0 : 0,\n",
    "    1 : 0,\n",
    "    2 : 0,\n",
    "    3 : 0,\n",
    "    4 : 1,\n",
    "    5 : 2,\n",
    "    6 : 3}\n",
    "train['mapped_weekday'] = train['weekday'].map(weekday_mapping)\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 월별 매핑\n",
    "month_mapping = {\n",
    "    2: 1, 5: 1, 4: 1, 3: 1,   # 2, 5, 4, 3월 → 1\n",
    "    9: 2, 10: 2,              # 9, 10월 → 2\n",
    "    6: 3, 7: 3, 8: 3,         # 6, 7, 8월 → 3\n",
    "    1: 4, 11: 4,              # 1, 11월 → 4\n",
    "    12: 5}                     # 12월 → 5\n",
    "train['mapped_month'] = train['month'].map(month_mapping)   \n",
    "'''\n",
    "\n",
    "# 연도별 배핑\n",
    "'''\n",
    "year_mapping = {\n",
    "    2011: 1, 2013: 1,  # 2011년, 2013년 → 1\n",
    "    2012: 2, 2014: 2,  # 2012년, 2014년 → 2\n",
    "    2010: 3, 2015: 3, 2016: 3} # 2010년, 2015년, 2016년 → 3\n",
    "train['mapped_year'] = train['year'].map(year_mapping)\n",
    "'''\n",
    "\n",
    "# 반응변수 추출\n",
    "y_df = train['num_sold']\n",
    "log_y_df = np.log1p(y_df)\n",
    "\n",
    "# 필요없는 변수 삭제\n",
    "train = train.drop(['num_sold', 'id', 'date', 'index', 'day_of_week'] , axis = 1)\n",
    "\n",
    "# 데이터 확인\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ce044d1-0b75-4664-8bb2-73205bd7cdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e99ea8bb-31e9-4865-8302-fcc352a3ec40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>year_sin</th>\n",
       "      <th>year_cos</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  store  product  year  month  weekday  day  week_of_year   day_sin  \\\n",
       "0        3      0        0  2017      1        6    1            52  0.017213   \n",
       "1        3      0        4  2017      1        6    1            52  0.017213   \n",
       "2        3      0        3  2017      1        6    1            52  0.017213   \n",
       "3        3      0        1  2017      1        6    1            52  0.017213   \n",
       "4        3      0        2  2017      1        6    1            52  0.017213   \n",
       "\n",
       "    day_cos  month_sin  month_cos  year_sin  year_cos  group  \n",
       "0  0.999852        0.5   0.866025  0.781831   0.62349    340  \n",
       "1  0.999852        0.5   0.866025  0.781831   0.62349    340  \n",
       "2  0.999852        0.5   0.866025  0.781831   0.62349    340  \n",
       "3  0.999852        0.5   0.866025  0.781831   0.62349    340  \n",
       "4  0.999852        0.5   0.866025  0.781831   0.62349    340  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터 전처리\n",
    "\n",
    "# 테스트 데이터 전처리\n",
    "\n",
    "# =================================================================================================================================\n",
    "# ==================================================== 테스트 데이터 전처리 (시도 4로 ) ==================================================\n",
    "# =================================================================================================================================\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------데이터 전처리\n",
    "\n",
    "# 날짜 파생 변수 생성\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "test['year'] = test['date'].dt.year\n",
    "test['month'] = test['date'].dt.month\n",
    "test['weekday'] = test['date'].dt.weekday\n",
    "test['day'] = test['date'].dt.day\n",
    "test['day_of_week'] = test['date'].dt.dayofweek\n",
    "test['week_of_year'] = test['date'].dt.isocalendar().week\n",
    "test['day_sin'] = np.sin(2 * np.pi * test['day'] / 365)\n",
    "test['day_cos'] = np.cos(2 * np.pi * test['day'] / 365)\n",
    "test['month_sin'] = np.sin(2 * np.pi * test['month'] / 12)\n",
    "test['month_cos'] = np.cos(2 * np.pi * test['month'] / 12)\n",
    "test['year_sin'] = np.sin(2 * np.pi * test['year'] / 7)\n",
    "test['year_cos'] = np.cos(2 * np.pi * test['year'] / 7)\n",
    "test['group'] = (test['year'] - 2010) * 48 + test['month'] * 4 + test['day'] // 7\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------ 인코딩\n",
    "\n",
    "country_mapping = {\n",
    "    'Kenya': 0,\n",
    "    'Italy': 1,\n",
    "    'Finland': 2,\n",
    "    'Canada': 3,\n",
    "    'Singapore': 4,\n",
    "    'Norway': 5}\n",
    "test['country'] = test['country'].map(country_mapping)\n",
    "\n",
    "\n",
    "store_mapping = {\n",
    "    'Discount Stickers' : 0,\n",
    "    'Stickers for Less' : 1,\n",
    "    'Premium Sticker Mart' : 2}\n",
    "test['store'] = test['store'].map(store_mapping)\n",
    "\n",
    "\n",
    "product_mapping = {\n",
    "    'Holographic Goose' : 0,\n",
    "    'Kerneler' : 1,\n",
    "    'Kerneler Dark Mode' : 2,\n",
    "    'Kaggle Tiers' : 3,\n",
    "    'Kaggle' : 4}\n",
    "test['product'] = test['product'].map(product_mapping)\n",
    "\n",
    "'''\n",
    "# (월,화,수,목 = 0) (금 = 1) (토 = 2) (일 = 3)\n",
    "weekday_mapping = {\n",
    "    0 : 0,\n",
    "    1 : 0,\n",
    "    2 : 0,\n",
    "    3 : 0,\n",
    "    4 : 1,\n",
    "    5 : 2,\n",
    "    6 : 3}\n",
    "test['mapped_weekday'] = test['weekday'].map(weekday_mapping)\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 월별 매핑\n",
    "month_mapping = {\n",
    "    2: 1, 5: 1, 4: 1, 3: 1,   # 2, 5, 4, 3월 → 1\n",
    "    9: 2, 10: 2,              # 9, 10월 → 2\n",
    "    6: 3, 7: 3, 8: 3,         # 6, 7, 8월 → 3\n",
    "    1: 4, 11: 4,              # 1, 11월 → 4\n",
    "    12: 5}                     # 12월 → 5\n",
    "test['mapped_month'] = test['month'].map(month_mapping)   \n",
    "'''\n",
    "\n",
    "# 연도별 매핑 (2017년 부터인줄 몰랐어)............\n",
    "'''\n",
    "year_mapping = {\n",
    "    2011: 1, 2013: 1,  # 2011년, 2013년 → 1\n",
    "    2012: 2, 2014: 2,  # 2012년, 2014년 → 2\n",
    "    2010: 3, 2015: 3, 2016: 3} # 2010년, 2015년, 2016년 → 3\n",
    "test['mapped_year'] = test['year'].map(year_mapping)\n",
    "'''\n",
    "\n",
    "\n",
    "# 필요없는 변수 삭제\n",
    "test = test.drop(['id', 'date', 'day_of_week'] , axis = 1)\n",
    "\n",
    "# 데이터 확인\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57eb7072-12b4-4977-94e8-13eab3713525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221259, 15)\n",
      "(98550, 15)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef10bff5-982f-417e-8f1b-436668239e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-27 11:36:04,273] A new study created in memory with name: no-name-84522d6a-bf14-412c-a7cb-15f0b2305736\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   0%|                                                       | 0/200 [00:00<?, ?it/s]C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:36:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-01-27 11:36:07,558] Trial 0 finished with value: 0.0637427102835528 and parameters: {'n_estimators': 294, 'learning_rate': 0.3467763184120863, 'max_depth': 12, 'subsample': 0.9839271695460927, 'colsample_bytree': 0.838016341511917, 'min_child_weight': 7, 'gamma': 5.115271677041679, 'reg_alpha': 7.860155578720322, 'reg_lambda': 7.431333637530447}. Best is trial 0 with value: 0.0637427102835528.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   0%|▏                                              | 1/200 [00:03<10:53,  3.28s/it][I 2025-01-27 11:36:09,367] Trial 1 finished with value: 0.06623305381519731 and parameters: {'n_estimators': 143, 'learning_rate': 0.4063337763636748, 'max_depth': 10, 'subsample': 0.9073114648749532, 'colsample_bytree': 0.9875184826328844, 'min_child_weight': 1, 'gamma': 6.032200881070415, 'reg_alpha': 3.614816358803469, 'reg_lambda': 2.203399581392136}. Best is trial 0 with value: 0.0637427102835528.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   1%|▍                                              | 2/200 [00:05<07:58,  2.42s/it][I 2025-01-27 11:36:15,393] Trial 2 finished with value: 0.05964172629880522 and parameters: {'n_estimators': 737, 'learning_rate': 0.11713143775054166, 'max_depth': 13, 'subsample': 0.8497703889746338, 'colsample_bytree': 0.7469077228915729, 'min_child_weight': 1, 'gamma': 4.261928672502978, 'reg_alpha': 1.5614153962580568, 'reg_lambda': 2.816950214499585}. Best is trial 2 with value: 0.05964172629880522.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   2%|▋                                              | 3/200 [00:11<13:20,  4.06s/it][I 2025-01-27 11:36:23,681] Trial 3 finished with value: 0.06411222759559501 and parameters: {'n_estimators': 1133, 'learning_rate': 0.412162392761776, 'max_depth': 13, 'subsample': 0.877264283439452, 'colsample_bytree': 0.6793948104365825, 'min_child_weight': 1, 'gamma': 1.0146484275962908, 'reg_alpha': 7.978168628925499, 'reg_lambda': 6.050575374031526}. Best is trial 2 with value: 0.05964172629880522.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   2%|▉                                              | 4/200 [00:19<18:43,  5.73s/it][I 2025-01-27 11:36:27,234] Trial 4 finished with value: 0.06468759406471081 and parameters: {'n_estimators': 378, 'learning_rate': 0.20462699695630554, 'max_depth': 11, 'subsample': 0.6435068338588428, 'colsample_bytree': 0.5567185321083258, 'min_child_weight': 1, 'gamma': 5.76566402717475, 'reg_alpha': 5.715943521673175, 'reg_lambda': 0.7885836658413037}. Best is trial 2 with value: 0.05964172629880522.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   2%|█▏                                             | 5/200 [00:22<16:04,  4.95s/it][I 2025-01-27 11:36:40,190] Trial 5 finished with value: 0.088922124861772 and parameters: {'n_estimators': 1973, 'learning_rate': 0.5411805072801661, 'max_depth': 3, 'subsample': 0.9965029870929745, 'colsample_bytree': 0.8045773868515813, 'min_child_weight': 9, 'gamma': 6.5084386495643525, 'reg_alpha': 5.370524359929312, 'reg_lambda': 9.796119708398972}. Best is trial 2 with value: 0.05964172629880522.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   3%|█▍                                             | 6/200 [00:35<24:47,  7.67s/it][I 2025-01-27 11:36:41,888] Trial 6 finished with value: 0.07996379157615345 and parameters: {'n_estimators': 133, 'learning_rate': 0.6932068414852901, 'max_depth': 12, 'subsample': 0.572167702857591, 'colsample_bytree': 0.9490893913133963, 'min_child_weight': 8, 'gamma': 8.327090463159696, 'reg_alpha': 9.48461670545835, 'reg_lambda': 1.5942824716152681}. Best is trial 2 with value: 0.05964172629880522.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   4%|█▋                                             | 7/200 [00:37<18:23,  5.72s/it][I 2025-01-27 11:36:43,439] Trial 7 finished with value: 0.06735896821708606 and parameters: {'n_estimators': 106, 'learning_rate': 0.9135195795704008, 'max_depth': 3, 'subsample': 0.936461545073014, 'colsample_bytree': 0.9926682186717617, 'min_child_weight': 7, 'gamma': 0.9196245795260116, 'reg_alpha': 9.224512857845179, 'reg_lambda': 4.2074505997616365}. Best is trial 2 with value: 0.05964172629880522.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   4%|█▉                                             | 8/200 [00:39<14:03,  4.39s/it][I 2025-01-27 11:36:52,553] Trial 8 finished with value: 0.07107893163692322 and parameters: {'n_estimators': 1323, 'learning_rate': 0.5065667458694548, 'max_depth': 5, 'subsample': 0.9034580636507992, 'colsample_bytree': 0.6002823012438966, 'min_child_weight': 6, 'gamma': 7.549243678053703, 'reg_alpha': 2.3093789281346835, 'reg_lambda': 2.795040448929961}. Best is trial 2 with value: 0.05964172629880522.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   4%|██                                             | 9/200 [00:48<18:40,  5.87s/it][I 2025-01-27 11:37:03,496] Trial 9 finished with value: 0.0673334356796321 and parameters: {'n_estimators': 1601, 'learning_rate': 0.3174590148472015, 'max_depth': 8, 'subsample': 0.7310421525859945, 'colsample_bytree': 0.5474914501330774, 'min_child_weight': 3, 'gamma': 8.685214977516736, 'reg_alpha': 6.240416674158304, 'reg_lambda': 7.6680634166547}. Best is trial 2 with value: 0.05964172629880522.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   5%|██▎                                           | 10/200 [00:59<23:32,  7.43s/it][I 2025-01-27 11:37:09,902] Trial 10 finished with value: 0.060075545414282394 and parameters: {'n_estimators': 684, 'learning_rate': 0.09781488631756596, 'max_depth': 15, 'subsample': 0.8065328205494829, 'colsample_bytree': 0.7080374163185309, 'min_child_weight': 4, 'gamma': 3.0768871962785926, 'reg_alpha': 0.025848774148883535, 'reg_lambda': 0.03095696078463961}. Best is trial 2 with value: 0.05964172629880522.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   6%|██▌                                           | 11/200 [01:05<22:25,  7.12s/it][I 2025-01-27 11:37:21,885] Trial 11 finished with value: 0.056360288684976986 and parameters: {'n_estimators': 710, 'learning_rate': 0.01967803075847828, 'max_depth': 15, 'subsample': 0.7923540009112657, 'colsample_bytree': 0.7103176580189267, 'min_child_weight': 4, 'gamma': 3.1123766596037785, 'reg_alpha': 0.07078446492033552, 'reg_lambda': 0.2428707816539928}. Best is trial 11 with value: 0.056360288684976986.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   6%|██▊                                           | 12/200 [01:17<26:56,  8.60s/it][I 2025-01-27 11:37:35,025] Trial 12 finished with value: 0.05696678108327702 and parameters: {'n_estimators': 716, 'learning_rate': 0.016938577564540647, 'max_depth': 15, 'subsample': 0.7777256031758841, 'colsample_bytree': 0.7805224349791671, 'min_child_weight': 4, 'gamma': 3.0997082746505487, 'reg_alpha': 0.21849613708908078, 'reg_lambda': 3.5521160160927447}. Best is trial 11 with value: 0.056360288684976986.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   6%|██▉                                           | 13/200 [01:30<31:05,  9.97s/it][I 2025-01-27 11:37:42,919] Trial 13 finished with value: 0.057383171384544865 and parameters: {'n_estimators': 721, 'learning_rate': 0.049897615978584386, 'max_depth': 15, 'subsample': 0.7311832983633155, 'colsample_bytree': 0.8731717541972785, 'min_child_weight': 4, 'gamma': 2.7615177293367346, 'reg_alpha': 0.13910485661166527, 'reg_lambda': 4.51543243585302}. Best is trial 11 with value: 0.056360288684976986.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   7%|███▏                                          | 14/200 [01:38<28:58,  9.35s/it][I 2025-01-27 11:37:56,041] Trial 14 finished with value: 0.05670668952900595 and parameters: {'n_estimators': 943, 'learning_rate': 0.0162737363721971, 'max_depth': 8, 'subsample': 0.7874899383545935, 'colsample_bytree': 0.6570539151046944, 'min_child_weight': 3, 'gamma': 3.2992976187088154, 'reg_alpha': 1.8992715815274739, 'reg_lambda': 3.706306579459607}. Best is trial 11 with value: 0.056360288684976986.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   8%|███▍                                          | 15/200 [01:51<32:19, 10.48s/it][I 2025-01-27 11:38:03,610] Trial 15 finished with value: 0.05895132226772191 and parameters: {'n_estimators': 1044, 'learning_rate': 0.20389098678015527, 'max_depth': 7, 'subsample': 0.6664776950051123, 'colsample_bytree': 0.634129201553493, 'min_child_weight': 3, 'gamma': 1.9839490706633491, 'reg_alpha': 2.5229268555769018, 'reg_lambda': 5.70570885156406}. Best is trial 11 with value: 0.056360288684976986.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   8%|███▋                                          | 16/200 [01:59<29:27,  9.61s/it][I 2025-01-27 11:38:10,829] Trial 16 finished with value: 0.06606847108084686 and parameters: {'n_estimators': 988, 'learning_rate': 0.23387344035791552, 'max_depth': 6, 'subsample': 0.5103741387993972, 'colsample_bytree': 0.6532647815464656, 'min_child_weight': 5, 'gamma': 4.280529236327731, 'reg_alpha': 4.074311940202904, 'reg_lambda': 1.210424465477095}. Best is trial 11 with value: 0.056360288684976986.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   8%|███▉                                          | 17/200 [02:06<27:06,  8.89s/it][I 2025-01-27 11:38:20,924] Trial 17 finished with value: 0.08229495723460149 and parameters: {'n_estimators': 1341, 'learning_rate': 0.6741317321180387, 'max_depth': 9, 'subsample': 0.8231224684220496, 'colsample_bytree': 0.7205422754893382, 'min_child_weight': 3, 'gamma': 0.097986262431081, 'reg_alpha': 1.4444644499603063, 'reg_lambda': 0.3513026841966604}. Best is trial 11 with value: 0.056360288684976986.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   9%|████▏                                         | 18/200 [02:16<28:03,  9.25s/it][I 2025-01-27 11:38:24,619] Trial 18 finished with value: 0.08250929993667634 and parameters: {'n_estimators': 439, 'learning_rate': 0.8638908879597086, 'max_depth': 8, 'subsample': 0.6812631296579679, 'colsample_bytree': 0.5032691644838234, 'min_child_weight': 5, 'gamma': 4.063714592466328, 'reg_alpha': 3.4081674417901353, 'reg_lambda': 7.4464035111375315}. Best is trial 11 with value: 0.056360288684976986.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  10%|████▎                                         | 19/200 [02:20<22:52,  7.58s/it][I 2025-01-27 11:38:31,930] Trial 19 finished with value: 0.05808730297875696 and parameters: {'n_estimators': 900, 'learning_rate': 0.13960173403371337, 'max_depth': 10, 'subsample': 0.7598952466226883, 'colsample_bytree': 0.6016396115719053, 'min_child_weight': 10, 'gamma': 2.1021940368472354, 'reg_alpha': 1.2377151695654827, 'reg_lambda': 5.823529043310948}. Best is trial 11 with value: 0.056360288684976986.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  10%|████▌                                         | 20/200 [02:27<22:30,  7.50s/it][I 2025-01-27 11:38:40,927] Trial 20 finished with value: 0.06832112260087966 and parameters: {'n_estimators': 1299, 'learning_rate': 0.2576672571112733, 'max_depth': 5, 'subsample': 0.7145200291458004, 'colsample_bytree': 0.8920462447482953, 'min_child_weight': 2, 'gamma': 3.668115025917654, 'reg_alpha': 2.5353795693779775, 'reg_lambda': 3.453535020675272}. Best is trial 11 with value: 0.056360288684976986.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  10%|████▊                                         | 21/200 [02:36<23:43,  7.95s/it][I 2025-01-27 11:38:51,995] Trial 21 finished with value: 0.05567389989100395 and parameters: {'n_estimators': 626, 'learning_rate': 0.02257034944922478, 'max_depth': 14, 'subsample': 0.7860989978760252, 'colsample_bytree': 0.7868930085781303, 'min_child_weight': 4, 'gamma': 2.51681712045031, 'reg_alpha': 0.6236018636943252, 'reg_lambda': 3.795687171985024}. Best is trial 21 with value: 0.05567389989100395.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  11%|█████                                         | 22/200 [02:47<26:21,  8.89s/it][I 2025-01-27 11:39:07,213] Trial 22 finished with value: 0.05992032867697483 and parameters: {'n_estimators': 508, 'learning_rate': 0.01157186537076072, 'max_depth': 14, 'subsample': 0.7944856399939016, 'colsample_bytree': 0.7564030994633275, 'min_child_weight': 6, 'gamma': 2.043854041541443, 'reg_alpha': 0.965355598850087, 'reg_lambda': 1.8142030967955742}. Best is trial 21 with value: 0.05567389989100395.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  12%|█████▎                                        | 23/200 [03:02<31:49, 10.79s/it][I 2025-01-27 11:39:12,709] Trial 23 finished with value: 0.06103156968670263 and parameters: {'n_estimators': 548, 'learning_rate': 0.1544802709045273, 'max_depth': 14, 'subsample': 0.8342338205396996, 'colsample_bytree': 0.7015407181383653, 'min_child_weight': 2, 'gamma': 1.2826250224010414, 'reg_alpha': 0.8157244658646974, 'reg_lambda': 5.138951956900814}. Best is trial 21 with value: 0.05567389989100395.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  12%|█████▌                                        | 24/200 [03:08<26:58,  9.20s/it][I 2025-01-27 11:39:19,706] Trial 24 finished with value: 0.06153085010995316 and parameters: {'n_estimators': 864, 'learning_rate': 0.08756986436397331, 'max_depth': 13, 'subsample': 0.7682197283743641, 'colsample_bytree': 0.8142677287232972, 'min_child_weight': 5, 'gamma': 5.1067591865899455, 'reg_alpha': 2.0346150061787576, 'reg_lambda': 3.2919540559172376}. Best is trial 21 with value: 0.05567389989100395.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  12%|█████▊                                        | 25/200 [03:15<24:54,  8.54s/it][I 2025-01-27 11:39:28,213] Trial 25 finished with value: 0.06389211141571563 and parameters: {'n_estimators': 1179, 'learning_rate': 0.15752538938371666, 'max_depth': 11, 'subsample': 0.6173854972724249, 'colsample_bytree': 0.6679941523473706, 'min_child_weight': 4, 'gamma': 2.6269057924033072, 'reg_alpha': 0.7942239017938442, 'reg_lambda': 6.683355101555234}. Best is trial 21 with value: 0.05567389989100395.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  13%|█████▉                                        | 26/200 [03:23<24:44,  8.53s/it][I 2025-01-27 11:39:36,354] Trial 26 finished with value: 0.05976402186972045 and parameters: {'n_estimators': 581, 'learning_rate': 0.027260223502678513, 'max_depth': 9, 'subsample': 0.6997143001512427, 'colsample_bytree': 0.7368859216367594, 'min_child_weight': 3, 'gamma': 3.6072388560193107, 'reg_alpha': 4.598951536217337, 'reg_lambda': 9.161125898781933}. Best is trial 21 with value: 0.05567389989100395.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  14%|██████▏                                       | 27/200 [03:32<24:15,  8.41s/it][I 2025-01-27 11:39:42,900] Trial 27 finished with value: 0.06108502373679968 and parameters: {'n_estimators': 865, 'learning_rate': 0.2823597749725979, 'max_depth': 14, 'subsample': 0.8777980840931279, 'colsample_bytree': 0.6216126974449274, 'min_child_weight': 2, 'gamma': 1.5594650169785207, 'reg_alpha': 3.189719817509145, 'reg_lambda': 4.223529038034251}. Best is trial 21 with value: 0.05567389989100395.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  14%|██████▍                                       | 28/200 [03:38<22:30,  7.85s/it][I 2025-01-27 11:39:53,813] Trial 28 finished with value: 0.07301962458490452 and parameters: {'n_estimators': 1617, 'learning_rate': 0.6335294000626559, 'max_depth': 7, 'subsample': 0.7519458277256483, 'colsample_bytree': 0.790130797526633, 'min_child_weight': 6, 'gamma': 9.999451277605365, 'reg_alpha': 2.0828418924280516, 'reg_lambda': 2.255713709078557}. Best is trial 21 with value: 0.05567389989100395.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  14%|██████▋                                       | 29/200 [03:49<24:59,  8.77s/it][I 2025-01-27 11:39:59,019] Trial 29 finished with value: 0.04946567449766425 and parameters: {'n_estimators': 288, 'learning_rate': 0.08562547003988896, 'max_depth': 12, 'subsample': 0.9588172892793253, 'colsample_bytree': 0.8569516685290712, 'min_child_weight': 7, 'gamma': 0.31341205198008426, 'reg_alpha': 7.293504344443303, 'reg_lambda': 4.823568292360686}. Best is trial 29 with value: 0.04946567449766425.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  15%|██████▉                                       | 30/200 [03:54<21:49,  7.70s/it][I 2025-01-27 11:40:02,255] Trial 30 finished with value: 0.05205340931692613 and parameters: {'n_estimators': 308, 'learning_rate': 0.3889786649086974, 'max_depth': 12, 'subsample': 0.9598411567729241, 'colsample_bytree': 0.8527468167078969, 'min_child_weight': 7, 'gamma': 0.23350180566976553, 'reg_alpha': 6.980324643881493, 'reg_lambda': 8.503051867475175}. Best is trial 29 with value: 0.04946567449766425.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  16%|███████▏                                      | 31/200 [03:57<17:55,  6.36s/it][I 2025-01-27 11:40:05,476] Trial 31 finished with value: 0.051069194878554026 and parameters: {'n_estimators': 302, 'learning_rate': 0.4106251361336953, 'max_depth': 12, 'subsample': 0.958811994278893, 'colsample_bytree': 0.8527703359214939, 'min_child_weight': 7, 'gamma': 0.10853150802338515, 'reg_alpha': 7.250437473931233, 'reg_lambda': 8.574024715507703}. Best is trial 29 with value: 0.04946567449766425.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  16%|███████▎                                      | 32/200 [04:01<15:10,  5.42s/it][I 2025-01-27 11:40:08,639] Trial 32 finished with value: 0.0513281902703258 and parameters: {'n_estimators': 283, 'learning_rate': 0.39156131980420805, 'max_depth': 12, 'subsample': 0.960276105070369, 'colsample_bytree': 0.8604589061663541, 'min_child_weight': 7, 'gamma': 0.154263215485767, 'reg_alpha': 7.056212219874688, 'reg_lambda': 8.500891989239287}. Best is trial 29 with value: 0.04946567449766425.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  16%|███████▌                                      | 33/200 [04:04<13:12,  4.74s/it][I 2025-01-27 11:40:11,658] Trial 33 finished with value: 0.05138927880448478 and parameters: {'n_estimators': 268, 'learning_rate': 0.3983318465334595, 'max_depth': 12, 'subsample': 0.9583771433118561, 'colsample_bytree': 0.8560741777740991, 'min_child_weight': 8, 'gamma': 0.1733287259813342, 'reg_alpha': 6.893899840965005, 'reg_lambda': 8.476837370308964}. Best is trial 29 with value: 0.04946567449766425.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  17%|███████▊                                      | 34/200 [04:07<11:41,  4.23s/it][I 2025-01-27 11:40:14,567] Trial 34 finished with value: 0.05484703108890184 and parameters: {'n_estimators': 286, 'learning_rate': 0.4183565020413418, 'max_depth': 11, 'subsample': 0.9585727482003282, 'colsample_bytree': 0.9114794728104467, 'min_child_weight': 8, 'gamma': 0.5982455743367892, 'reg_alpha': 7.833297310457941, 'reg_lambda': 8.442860206297413}. Best is trial 29 with value: 0.04946567449766425.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  18%|████████                                      | 35/200 [04:10<10:32,  3.83s/it][I 2025-01-27 11:40:17,382] Trial 35 finished with value: 0.058239271194623334 and parameters: {'n_estimators': 287, 'learning_rate': 0.5778415233236319, 'max_depth': 10, 'subsample': 0.9225436473508757, 'colsample_bytree': 0.9318316911800241, 'min_child_weight': 8, 'gamma': 0.548706928389718, 'reg_alpha': 7.351424361271107, 'reg_lambda': 6.7300510072312765}. Best is trial 29 with value: 0.04946567449766425.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  18%|████████▎                                     | 36/200 [04:13<09:38,  3.53s/it][I 2025-01-27 11:40:20,479] Trial 36 finished with value: 0.05058193687790361 and parameters: {'n_estimators': 240, 'learning_rate': 0.45788391089786207, 'max_depth': 13, 'subsample': 0.9741631389380466, 'colsample_bytree': 0.8401931658822699, 'min_child_weight': 9, 'gamma': 0.03589829306057331, 'reg_alpha': 8.757576390153275, 'reg_lambda': 8.227439202640483}. Best is trial 29 with value: 0.04946567449766425.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  18%|████████▌                                     | 37/200 [04:16<09:13,  3.40s/it][I 2025-01-27 11:40:22,854] Trial 37 finished with value: 0.058995641962766535 and parameters: {'n_estimators': 218, 'learning_rate': 0.4741298270187795, 'max_depth': 11, 'subsample': 0.983011866964866, 'colsample_bytree': 0.8367874418804683, 'min_child_weight': 9, 'gamma': 1.3848765280869717, 'reg_alpha': 8.722631774414236, 'reg_lambda': 9.901132603196686}. Best is trial 29 with value: 0.04946567449766425.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  19%|████████▋                                     | 38/200 [04:18<08:20,  3.09s/it][I 2025-01-27 11:40:26,422] Trial 38 finished with value: 0.06458875693490784 and parameters: {'n_estimators': 417, 'learning_rate': 0.7937952175332041, 'max_depth': 13, 'subsample': 0.8733295972495361, 'colsample_bytree': 0.9564866075789722, 'min_child_weight': 9, 'gamma': 0.7489068488430861, 'reg_alpha': 9.963190202943615, 'reg_lambda': 9.155899777496332}. Best is trial 29 with value: 0.04946567449766425.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  20%|████████▉                                     | 39/200 [04:22<08:40,  3.23s/it][I 2025-01-27 11:40:28,630] Trial 39 finished with value: 0.05560439239719929 and parameters: {'n_estimators': 177, 'learning_rate': 0.3417213531223837, 'max_depth': 13, 'subsample': 0.9900359460337479, 'colsample_bytree': 0.8875364492385017, 'min_child_weight': 7, 'gamma': 1.0743119371373984, 'reg_alpha': 8.550331851648533, 'reg_lambda': 6.6936436095954726}. Best is trial 29 with value: 0.04946567449766425.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  20%|█████████▏                                    | 40/200 [04:24<07:48,  2.93s/it][I 2025-01-27 11:40:32,062] Trial 40 finished with value: 0.06032479413232776 and parameters: {'n_estimators': 405, 'learning_rate': 0.48035737625377467, 'max_depth': 12, 'subsample': 0.9038979337340732, 'colsample_bytree': 0.8226726247390784, 'min_child_weight': 10, 'gamma': 1.6314011310686436, 'reg_alpha': 6.4046375151880355, 'reg_lambda': 7.910460863691669}. Best is trial 29 with value: 0.04946567449766425.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  20%|█████████▍                                    | 41/200 [04:27<08:09,  3.08s/it][I 2025-01-27 11:40:35,026] Trial 41 finished with value: 0.04859594444898534 and parameters: {'n_estimators': 205, 'learning_rate': 0.3811660166903283, 'max_depth': 12, 'subsample': 0.9496506398787813, 'colsample_bytree': 0.8598884591906639, 'min_child_weight': 8, 'gamma': 0.020851815447775347, 'reg_alpha': 7.021326332042159, 'reg_lambda': 8.214804297329774}. Best is trial 41 with value: 0.04859594444898534.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  21%|█████████▋                                    | 42/200 [04:30<08:00,  3.04s/it][I 2025-01-27 11:40:37,021] Trial 42 finished with value: 0.05272650281547873 and parameters: {'n_estimators': 119, 'learning_rate': 0.5731399945041054, 'max_depth': 12, 'subsample': 0.9283537251601578, 'colsample_bytree': 0.9050497639345008, 'min_child_weight': 9, 'gamma': 0.0720573066097221, 'reg_alpha': 8.051534686815486, 'reg_lambda': 9.328071246567834}. Best is trial 41 with value: 0.04859594444898534.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  22%|█████████▉                                    | 43/200 [04:32<07:08,  2.73s/it][I 2025-01-27 11:40:41,027] Trial 43 finished with value: 0.05477227408287381 and parameters: {'n_estimators': 463, 'learning_rate': 0.447241471580454, 'max_depth': 11, 'subsample': 0.973537002658012, 'colsample_bytree': 0.8610787140567675, 'min_child_weight': 7, 'gamma': 0.6142605334073115, 'reg_alpha': 5.770509934716701, 'reg_lambda': 8.072650187162726}. Best is trial 41 with value: 0.04859594444898534.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  22%|██████████                                    | 44/200 [04:36<08:05,  3.11s/it][I 2025-01-27 11:40:44,224] Trial 44 finished with value: 0.054331634661319586 and parameters: {'n_estimators': 327, 'learning_rate': 0.3228766702060841, 'max_depth': 13, 'subsample': 0.9378220614562485, 'colsample_bytree': 0.9637632800395038, 'min_child_weight': 7, 'gamma': 0.8279072707733961, 'reg_alpha': 7.444802633295554, 'reg_lambda': 6.992341568501555}. Best is trial 41 with value: 0.04859594444898534.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  22%|██████████▎                                   | 45/200 [04:39<08:06,  3.14s/it][I 2025-01-27 11:40:46,359] Trial 45 finished with value: 0.0690255296438628 and parameters: {'n_estimators': 189, 'learning_rate': 0.5210450560862355, 'max_depth': 10, 'subsample': 0.9981683247955502, 'colsample_bytree': 0.8317051362307678, 'min_child_weight': 8, 'gamma': 5.887285390292343, 'reg_alpha': 8.577282099819344, 'reg_lambda': 8.776465758450847}. Best is trial 41 with value: 0.04859594444898534.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  23%|██████████▌                                   | 46/200 [04:42<07:16,  2.84s/it][I 2025-01-27 11:40:49,670] Trial 46 finished with value: 0.055805332112086534 and parameters: {'n_estimators': 343, 'learning_rate': 0.3653650992343474, 'max_depth': 12, 'subsample': 0.8757388066655006, 'colsample_bytree': 0.9321528819390867, 'min_child_weight': 6, 'gamma': 1.1249015888813054, 'reg_alpha': 6.413689936047385, 'reg_lambda': 7.210633379086284}. Best is trial 41 with value: 0.04859594444898534.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  24%|██████████▊                                   | 47/200 [04:45<07:35,  2.98s/it][I 2025-01-27 11:40:51,458] Trial 47 finished with value: 0.06418578514256815 and parameters: {'n_estimators': 106, 'learning_rate': 0.29557749084586993, 'max_depth': 13, 'subsample': 0.9447205019223862, 'colsample_bytree': 0.768929507066216, 'min_child_weight': 8, 'gamma': 6.610101632142445, 'reg_alpha': 5.198720846647294, 'reg_lambda': 5.196988153515282}. Best is trial 41 with value: 0.04859594444898534.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  24%|███████████                                   | 48/200 [04:47<06:38,  2.62s/it][I 2025-01-27 11:40:54,175] Trial 48 finished with value: 0.050748897800791684 and parameters: {'n_estimators': 200, 'learning_rate': 0.43122695664733096, 'max_depth': 11, 'subsample': 0.9100292804023775, 'colsample_bytree': 0.8086045104953284, 'min_child_weight': 9, 'gamma': 0.05256054754542286, 'reg_alpha': 9.074468909573019, 'reg_lambda': 6.127679470801242}. Best is trial 41 with value: 0.04859594444898534.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  24%|███████████▎                                  | 49/200 [04:49<06:40,  2.65s/it][I 2025-01-27 11:40:56,215] Trial 49 finished with value: 0.07170917590609671 and parameters: {'n_estimators': 212, 'learning_rate': 0.9947524440407989, 'max_depth': 10, 'subsample': 0.889970215808254, 'colsample_bytree': 0.8082648676522, 'min_child_weight': 10, 'gamma': 1.8416536967822779, 'reg_alpha': 9.256460064717563, 'reg_lambda': 4.613797865286383}. Best is trial 41 with value: 0.04859594444898534.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  25%|███████████▌                                  | 50/200 [04:51<06:10,  2.47s/it][I 2025-01-27 11:41:00,518] Trial 50 finished with value: 0.05697949236075715 and parameters: {'n_estimators': 508, 'learning_rate': 0.44814999506385533, 'max_depth': 11, 'subsample': 0.8482673753339784, 'colsample_bytree': 0.8744844279953031, 'min_child_weight': 9, 'gamma': 0.5521504812308485, 'reg_alpha': 7.991557327847892, 'reg_lambda': 6.055016373932482}. Best is trial 41 with value: 0.04859594444898534.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  26%|███████████▋                                  | 51/200 [04:56<07:29,  3.02s/it][I 2025-01-27 11:41:08,378] Trial 51 finished with value: 0.047233951864693466 and parameters: {'n_estimators': 378, 'learning_rate': 0.5671993036470457, 'max_depth': 12, 'subsample': 0.9227471680145171, 'colsample_bytree': 0.8437282054957517, 'min_child_weight': 7, 'gamma': 0.0002949508683179336, 'reg_alpha': 8.912922729851019, 'reg_lambda': 7.971455285775071}. Best is trial 51 with value: 0.047233951864693466.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  26%|███████████▉                                  | 52/200 [05:04<11:01,  4.47s/it][I 2025-01-27 11:41:12,144] Trial 52 finished with value: 0.05250654721365382 and parameters: {'n_estimators': 371, 'learning_rate': 0.5630929987203859, 'max_depth': 13, 'subsample': 0.9104163374461177, 'colsample_bytree': 0.7977733765149644, 'min_child_weight': 9, 'gamma': 0.035553641262887764, 'reg_alpha': 9.879919515143696, 'reg_lambda': 6.184708104959645}. Best is trial 51 with value: 0.047233951864693466.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  26%|████████████▏                                 | 53/200 [05:07<10:26,  4.26s/it][I 2025-01-27 11:41:14,519] Trial 53 finished with value: 0.06190713163161858 and parameters: {'n_estimators': 222, 'learning_rate': 0.6475574214366627, 'max_depth': 14, 'subsample': 0.9258861158719953, 'colsample_bytree': 0.8402226646371603, 'min_child_weight': 8, 'gamma': 1.0012025410077023, 'reg_alpha': 9.106949340580131, 'reg_lambda': 7.824012054530281}. Best is trial 51 with value: 0.047233951864693466.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  27%|████████████▍                                 | 54/200 [05:10<08:59,  3.69s/it][I 2025-01-27 11:41:28,032] Trial 54 finished with value: 0.05666760579847731 and parameters: {'n_estimators': 1979, 'learning_rate': 0.6012155451088481, 'max_depth': 12, 'subsample': 0.9719793446236303, 'colsample_bytree': 0.880907930843247, 'min_child_weight': 7, 'gamma': 0.46398085755960067, 'reg_alpha': 8.34764597674835, 'reg_lambda': 9.479857747702555}. Best is trial 51 with value: 0.047233951864693466.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  28%|████████████▋                                 | 55/200 [05:23<16:02,  6.64s/it][I 2025-01-27 11:41:32,993] Trial 55 finished with value: 0.06457713413942584 and parameters: {'n_estimators': 631, 'learning_rate': 0.7522730953148163, 'max_depth': 11, 'subsample': 0.9446816710404666, 'colsample_bytree': 0.9091679151196722, 'min_child_weight': 10, 'gamma': 1.2464283177087376, 'reg_alpha': 8.961849058277561, 'reg_lambda': 7.438128033738721}. Best is trial 51 with value: 0.047233951864693466.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  28%|████████████▉                                 | 56/200 [05:28<14:43,  6.14s/it][I 2025-01-27 11:41:37,129] Trial 56 finished with value: 0.05686718245637114 and parameters: {'n_estimators': 470, 'learning_rate': 0.522643627477215, 'max_depth': 13, 'subsample': 0.9105102657169213, 'colsample_bytree': 0.767831833266028, 'min_child_weight': 9, 'gamma': 0.41692631708018446, 'reg_alpha': 9.606523331497982, 'reg_lambda': 8.146189360996184}. Best is trial 51 with value: 0.047233951864693466.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  28%|█████████████                                 | 57/200 [05:32<13:11,  5.54s/it][I 2025-01-27 11:41:44,807] Trial 57 finished with value: 0.046078972617945115 and parameters: {'n_estimators': 791, 'learning_rate': 0.2224359663249881, 'max_depth': 10, 'subsample': 0.8556098283651934, 'colsample_bytree': 0.8193388385218814, 'min_child_weight': 6, 'gamma': 0.006807443126386849, 'reg_alpha': 7.528603810747289, 'reg_lambda': 7.625727059482667}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  29%|█████████████▎                                | 58/200 [05:40<14:37,  6.18s/it][I 2025-01-27 11:41:47,113] Trial 58 finished with value: 0.053557125752825195 and parameters: {'n_estimators': 147, 'learning_rate': 0.20706621490360907, 'max_depth': 10, 'subsample': 0.892799501738529, 'colsample_bytree': 0.8049790270506508, 'min_child_weight': 6, 'gamma': 0.9946800654514297, 'reg_alpha': 7.795934983414926, 'reg_lambda': 5.496388376621168}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  30%|█████████████▌                                | 59/200 [05:42<11:47,  5.02s/it][I 2025-01-27 11:42:00,035] Trial 59 finished with value: 0.05697934580231101 and parameters: {'n_estimators': 1799, 'learning_rate': 0.07999741267061065, 'max_depth': 9, 'subsample': 0.8140637704957853, 'colsample_bytree': 0.8282807287322935, 'min_child_weight': 8, 'gamma': 2.2781833806828864, 'reg_alpha': 8.197142014247323, 'reg_lambda': 7.046116452569845}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  30%|█████████████▊                                | 60/200 [05:55<17:14,  7.39s/it][I 2025-01-27 11:42:03,509] Trial 60 finished with value: 0.05637992574653865 and parameters: {'n_estimators': 366, 'learning_rate': 0.24755799394595546, 'max_depth': 11, 'subsample': 0.8544735690776295, 'colsample_bytree': 0.7797741090871504, 'min_child_weight': 6, 'gamma': 1.696801528595103, 'reg_alpha': 5.758949812407778, 'reg_lambda': 4.829108309522296}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  30%|██████████████                                | 61/200 [05:59<14:23,  6.21s/it][I 2025-01-27 11:42:06,187] Trial 61 finished with value: 0.05409337295397619 and parameters: {'n_estimators': 254, 'learning_rate': 0.43502423445448396, 'max_depth': 12, 'subsample': 0.9804594673681964, 'colsample_bytree': 0.8466759575279328, 'min_child_weight': 7, 'gamma': 0.40237840917308726, 'reg_alpha': 7.465909173702741, 'reg_lambda': 8.897623617911984}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  31%|██████████████▎                               | 62/200 [06:01<11:51,  5.15s/it][I 2025-01-27 11:42:08,146] Trial 62 finished with value: 0.05026023267074246 and parameters: {'n_estimators': 101, 'learning_rate': 0.4875091688457229, 'max_depth': 10, 'subsample': 0.9481769683765462, 'colsample_bytree': 0.81813656222159, 'min_child_weight': 5, 'gamma': 0.0324576544141119, 'reg_alpha': 6.712870741359387, 'reg_lambda': 7.613467941312249}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  32%|██████████████▍                               | 63/200 [06:03<09:34,  4.20s/it][I 2025-01-27 11:42:12,567] Trial 63 finished with value: 0.04674510357530896 and parameters: {'n_estimators': 152, 'learning_rate': 0.46974499705795625, 'max_depth': 10, 'subsample': 0.9155453355015731, 'colsample_bytree': 0.815164486598791, 'min_child_weight': 5, 'gamma': 0.0009268754716142388, 'reg_alpha': 6.669374007837662, 'reg_lambda': 7.598788496990767}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  32%|██████████████▋                               | 64/200 [06:08<09:39,  4.26s/it][I 2025-01-27 11:42:18,169] Trial 64 finished with value: 0.05732012462128887 and parameters: {'n_estimators': 778, 'learning_rate': 0.4839527268770173, 'max_depth': 9, 'subsample': 0.9415652561943935, 'colsample_bytree': 0.7460932699058781, 'min_child_weight': 5, 'gamma': 0.8971406348756852, 'reg_alpha': 6.633357517879477, 'reg_lambda': 7.578193024037884}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  32%|██████████████▉                               | 65/200 [06:13<10:29,  4.66s/it][I 2025-01-27 11:42:20,640] Trial 65 finished with value: 0.053650236298094844 and parameters: {'n_estimators': 113, 'learning_rate': 0.11903746609576465, 'max_depth': 8, 'subsample': 0.9991738890227407, 'colsample_bytree': 0.8214457738020895, 'min_child_weight': 5, 'gamma': 1.4102186324131918, 'reg_alpha': 5.969125949372078, 'reg_lambda': 6.515873238599696}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  33%|███████████████▏                              | 66/200 [06:16<08:56,  4.01s/it][I 2025-01-27 11:42:28,663] Trial 66 finished with value: 0.058503978923418985 and parameters: {'n_estimators': 1159, 'learning_rate': 0.5444800104476173, 'max_depth': 10, 'subsample': 0.9198038293815967, 'colsample_bytree': 0.8696039485630894, 'min_child_weight': 5, 'gamma': 0.8034008834024055, 'reg_alpha': 6.690497706793195, 'reg_lambda': 8.128049876889278}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  34%|███████████████▍                              | 67/200 [06:24<11:33,  5.21s/it][I 2025-01-27 11:42:31,244] Trial 67 finished with value: 0.05069680539945378 and parameters: {'n_estimators': 155, 'learning_rate': 0.1904201169091961, 'max_depth': 9, 'subsample': 0.8541943495826501, 'colsample_bytree': 0.8945469940376816, 'min_child_weight': 6, 'gamma': 0.3978868269726587, 'reg_alpha': 4.7982975543602855, 'reg_lambda': 7.726655179028113}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  34%|███████████████▋                              | 68/200 [06:26<09:43,  4.42s/it][I 2025-01-27 11:42:35,622] Trial 68 finished with value: 0.06351582997594403 and parameters: {'n_estimators': 580, 'learning_rate': 0.35642314172557965, 'max_depth': 10, 'subsample': 0.8931331843292706, 'colsample_bytree': 0.7261832214148162, 'min_child_weight': 4, 'gamma': 4.833772270843409, 'reg_alpha': 7.616508576003438, 'reg_lambda': 7.308593240055083}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  34%|███████████████▊                              | 69/200 [06:31<09:37,  4.41s/it][I 2025-01-27 11:42:41,954] Trial 69 finished with value: 0.048241248477677266 and parameters: {'n_estimators': 789, 'learning_rate': 0.6096459639801423, 'max_depth': 9, 'subsample': 0.9419191703580931, 'colsample_bytree': 0.792719999568921, 'min_child_weight': 5, 'gamma': 0.005402245723487981, 'reg_alpha': 5.449664620185172, 'reg_lambda': 9.586485803267486}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  35%|████████████████                              | 70/200 [06:37<10:48,  4.99s/it][I 2025-01-27 11:42:49,306] Trial 70 finished with value: 0.07238776872685006 and parameters: {'n_estimators': 1088, 'learning_rate': 0.6862286808595763, 'max_depth': 8, 'subsample': 0.9496387949926645, 'colsample_bytree': 0.7917725825871644, 'min_child_weight': 5, 'gamma': 7.43258133675023, 'reg_alpha': 6.134606940304025, 'reg_lambda': 9.99603892225755}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  36%|████████████████▎                             | 71/200 [06:45<12:14,  5.70s/it][I 2025-01-27 11:42:55,037] Trial 71 finished with value: 0.05842940316329498 and parameters: {'n_estimators': 818, 'learning_rate': 0.7252261861510514, 'max_depth': 7, 'subsample': 0.9717166724862449, 'colsample_bytree': 0.7681825832871929, 'min_child_weight': 6, 'gamma': 0.45328120174309, 'reg_alpha': 5.301485017364568, 'reg_lambda': 8.886458043611967}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  36%|████████████████▌                             | 72/200 [06:50<12:10,  5.71s/it][I 2025-01-27 11:43:02,670] Trial 72 finished with value: 0.0476426845241602 and parameters: {'n_estimators': 959, 'learning_rate': 0.5034037282157604, 'max_depth': 9, 'subsample': 0.9296919684622195, 'colsample_bytree': 0.8393984714244646, 'min_child_weight': 5, 'gamma': 0.003971570880237432, 'reg_alpha': 7.139183536060583, 'reg_lambda': 9.539182189673689}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  36%|████████████████▊                             | 73/200 [06:58<13:18,  6.28s/it][I 2025-01-27 11:43:09,263] Trial 73 finished with value: 0.059492896434893805 and parameters: {'n_estimators': 968, 'learning_rate': 0.6405009142336776, 'max_depth': 9, 'subsample': 0.9256220715543881, 'colsample_bytree': 0.8174641862880783, 'min_child_weight': 5, 'gamma': 0.7421284624898392, 'reg_alpha': 6.745607484972104, 'reg_lambda': 9.618045031913942}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  37%|█████████████████                             | 74/200 [07:04<13:23,  6.38s/it][I 2025-01-27 11:43:16,128] Trial 74 finished with value: 0.055810473760947 and parameters: {'n_estimators': 1030, 'learning_rate': 0.5992255582349576, 'max_depth': 8, 'subsample': 0.8659902467194932, 'colsample_bytree': 0.8651230557808509, 'min_child_weight': 4, 'gamma': 0.28305885912422596, 'reg_alpha': 7.10575824984574, 'reg_lambda': 9.62471860117801}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  38%|█████████████████▎                            | 75/200 [07:11<13:35,  6.52s/it][I 2025-01-27 11:43:24,754] Trial 75 finished with value: 0.048713379420741484 and parameters: {'n_estimators': 1247, 'learning_rate': 0.497753557829851, 'max_depth': 9, 'subsample': 0.887380011351656, 'colsample_bytree': 0.8435861379919606, 'min_child_weight': 5, 'gamma': 0.02037723145626388, 'reg_alpha': 3.993509109071982, 'reg_lambda': 9.13508441669996}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  38%|█████████████████▍                            | 76/200 [07:20<14:47,  7.15s/it][I 2025-01-27 11:43:33,017] Trial 76 finished with value: 0.06108298657228913 and parameters: {'n_estimators': 1227, 'learning_rate': 0.6081981280688757, 'max_depth': 9, 'subsample': 0.885624615768071, 'colsample_bytree': 0.8331741354980916, 'min_child_weight': 6, 'gamma': 1.2623783868582215, 'reg_alpha': 4.090787094624184, 'reg_lambda': 9.138790465104654}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  38%|█████████████████▋                            | 77/200 [07:28<15:20,  7.49s/it][I 2025-01-27 11:43:42,188] Trial 77 finished with value: 0.05736654233062557 and parameters: {'n_estimators': 1390, 'learning_rate': 0.5435383343426634, 'max_depth': 7, 'subsample': 0.8996770439652271, 'colsample_bytree': 0.8486086952352186, 'min_child_weight': 5, 'gamma': 0.6787187558133292, 'reg_alpha': 4.363061099430555, 'reg_lambda': 8.764511337487882}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  39%|█████████████████▉                            | 78/200 [07:37<16:14,  7.99s/it][I 2025-01-27 11:43:52,504] Trial 78 finished with value: 0.05456816014429089 and parameters: {'n_estimators': 1527, 'learning_rate': 0.5081127214086507, 'max_depth': 9, 'subsample': 0.8375201111140235, 'colsample_bytree': 0.925956575719168, 'min_child_weight': 6, 'gamma': 0.3503406994623775, 'reg_alpha': 3.189516348012348, 'reg_lambda': 9.207324424733496}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  40%|██████████████████▏                           | 79/200 [07:48<17:31,  8.69s/it][I 2025-01-27 11:44:00,210] Trial 79 finished with value: 0.06524480709772437 and parameters: {'n_estimators': 924, 'learning_rate': 0.05178126496133608, 'max_depth': 8, 'subsample': 0.9329656565643261, 'colsample_bytree': 0.7822773492728288, 'min_child_weight': 4, 'gamma': 9.248426654118509, 'reg_alpha': 3.782419973521761, 'reg_lambda': 4.054065249108267}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  40%|██████████████████▍                           | 80/200 [07:55<16:47,  8.39s/it][I 2025-01-27 11:44:08,964] Trial 80 finished with value: 0.0531424961765075 and parameters: {'n_estimators': 1239, 'learning_rate': 0.28043191104506554, 'max_depth': 9, 'subsample': 0.548601825724149, 'colsample_bytree': 0.8833146826101694, 'min_child_weight': 4, 'gamma': 0.27110036820031497, 'reg_alpha': 5.631567402845692, 'reg_lambda': 9.669550439380302}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  40%|██████████████████▋                           | 81/200 [08:04<16:51,  8.50s/it][I 2025-01-27 11:44:13,896] Trial 81 finished with value: 0.05692792219309806 and parameters: {'n_estimators': 649, 'learning_rate': 0.49630954522024123, 'max_depth': 10, 'subsample': 0.9155272782078704, 'colsample_bytree': 0.8176792726718422, 'min_child_weight': 5, 'gamma': 0.7238970824783465, 'reg_alpha': 6.495330631036503, 'reg_lambda': 8.364922885678022}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  41%|██████████████████▊                           | 82/200 [08:09<14:36,  7.43s/it][I 2025-01-27 11:44:23,163] Trial 82 finished with value: 0.0472213644459064 and parameters: {'n_estimators': 1083, 'learning_rate': 0.4722640303555036, 'max_depth': 10, 'subsample': 0.9540337796993595, 'colsample_bytree': 0.7967398914251332, 'min_child_weight': 5, 'gamma': 0.0012443786277858684, 'reg_alpha': 7.672427436375448, 'reg_lambda': 7.952320852256312}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  42%|███████████████████                           | 83/200 [08:18<15:33,  7.98s/it][I 2025-01-27 11:44:30,643] Trial 83 finished with value: 0.05023481673056297 and parameters: {'n_estimators': 1031, 'learning_rate': 0.5253579760690452, 'max_depth': 10, 'subsample': 0.9646831114154794, 'colsample_bytree': 0.7568859301380653, 'min_child_weight': 5, 'gamma': 0.016438161185995, 'reg_alpha': 7.208433571110119, 'reg_lambda': 7.9138200024475855}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  42%|███████████████████▎                          | 84/200 [08:26<15:08,  7.83s/it][I 2025-01-27 11:44:38,002] Trial 84 finished with value: 0.06156932568060872 and parameters: {'n_estimators': 1087, 'learning_rate': 0.5621676740310001, 'max_depth': 4, 'subsample': 0.9316205756119204, 'colsample_bytree': 0.7997510476011579, 'min_child_weight': 6, 'gamma': 0.30542310697301644, 'reg_alpha': 7.68824154545904, 'reg_lambda': 8.98499610270936}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  42%|███████████████████▌                          | 85/200 [08:33<14:44,  7.69s/it][I 2025-01-27 11:44:44,060] Trial 85 finished with value: 0.06037098160559264 and parameters: {'n_estimators': 845, 'learning_rate': 0.6649483853611265, 'max_depth': 9, 'subsample': 0.9030231891822614, 'colsample_bytree': 0.8466783746225867, 'min_child_weight': 5, 'gamma': 0.9648383323479286, 'reg_alpha': 6.224171115598702, 'reg_lambda': 9.36610155411685}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  43%|███████████████████▊                          | 86/200 [08:39<13:40,  7.20s/it][I 2025-01-27 11:44:53,848] Trial 86 finished with value: 0.055726572675457185 and parameters: {'n_estimators': 1439, 'learning_rate': 0.47256087778848965, 'max_depth': 11, 'subsample': 0.9865357454162307, 'colsample_bytree': 0.8970026780752691, 'min_child_weight': 7, 'gamma': 0.6146160092753774, 'reg_alpha': 8.295400342405927, 'reg_lambda': 8.308704729855945}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  44%|████████████████████                          | 87/200 [08:49<15:01,  7.98s/it][I 2025-01-27 11:45:01,547] Trial 87 finished with value: 0.05593457064267239 and parameters: {'n_estimators': 1100, 'learning_rate': 0.37371806722094675, 'max_depth': 8, 'subsample': 0.9547859558864971, 'colsample_bytree': 0.8722321696146326, 'min_child_weight': 6, 'gamma': 1.4189552472046232, 'reg_alpha': 4.971623045563899, 'reg_lambda': 8.598408421249246}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  44%|████████████████████▏                         | 88/200 [08:57<14:44,  7.89s/it][I 2025-01-27 11:45:08,717] Trial 88 finished with value: 0.05157140264080549 and parameters: {'n_estimators': 989, 'learning_rate': 0.32492869055426987, 'max_depth': 11, 'subsample': 0.8792678146975396, 'colsample_bytree': 0.8320543805160993, 'min_child_weight': 4, 'gamma': 0.26097680827911734, 'reg_alpha': 6.946727201590427, 'reg_lambda': 8.703302047081731}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  44%|████████████████████▍                         | 89/200 [09:04<14:12,  7.68s/it][I 2025-01-27 11:45:14,751] Trial 89 finished with value: 0.05005875681169532 and parameters: {'n_estimators': 801, 'learning_rate': 0.623537509765386, 'max_depth': 10, 'subsample': 0.9379242387244056, 'colsample_bytree': 0.8615621966495104, 'min_child_weight': 5, 'gamma': 0.010858980627996062, 'reg_alpha': 7.585828226967781, 'reg_lambda': 9.810484573416119}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  45%|████████████████████▋                         | 90/200 [09:10<13:10,  7.18s/it][I 2025-01-27 11:45:20,253] Trial 90 finished with value: 0.05765068140522567 and parameters: {'n_estimators': 754, 'learning_rate': 0.4167986994462035, 'max_depth': 9, 'subsample': 0.867878188194971, 'colsample_bytree': 0.7795005348490692, 'min_child_weight': 7, 'gamma': 1.1292186849249881, 'reg_alpha': 8.032758339047934, 'reg_lambda': 8.024256173648256}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  46%|████████████████████▉                         | 91/200 [09:15<12:08,  6.68s/it][I 2025-01-27 11:45:28,009] Trial 91 finished with value: 0.048152195944837155 and parameters: {'n_estimators': 911, 'learning_rate': 0.6239046812937716, 'max_depth': 10, 'subsample': 0.9388314124400873, 'colsample_bytree': 0.8533597851108744, 'min_child_weight': 5, 'gamma': 0.0025739321012955728, 'reg_alpha': 7.6243795156819205, 'reg_lambda': 9.832366512424368}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  46%|█████████████████████▏                        | 92/200 [09:23<12:36,  7.00s/it][I 2025-01-27 11:45:36,308] Trial 92 finished with value: 0.057024398387923836 and parameters: {'n_estimators': 1225, 'learning_rate': 0.58643803643875, 'max_depth': 10, 'subsample': 0.9142619993892814, 'colsample_bytree': 0.7968764645390699, 'min_child_weight': 5, 'gamma': 0.4926367881278526, 'reg_alpha': 7.323985508633044, 'reg_lambda': 9.373377243258899}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  46%|█████████████████████▍                        | 93/200 [09:32<13:10,  7.39s/it][I 2025-01-27 11:45:42,816] Trial 93 finished with value: 0.05483484704676419 and parameters: {'n_estimators': 896, 'learning_rate': 0.5492230441136788, 'max_depth': 11, 'subsample': 0.9649247481020728, 'colsample_bytree': 0.8438343892898744, 'min_child_weight': 6, 'gamma': 0.20906260083605507, 'reg_alpha': 7.845295942110797, 'reg_lambda': 9.048866961539106}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  47%|█████████████████████▌                        | 94/200 [09:38<12:35,  7.13s/it][I 2025-01-27 11:45:47,973] Trial 94 finished with value: 0.060527192901293304 and parameters: {'n_estimators': 709, 'learning_rate': 0.5150210626566385, 'max_depth': 10, 'subsample': 0.6285537552341895, 'colsample_bytree': 0.8570113906152106, 'min_child_weight': 4, 'gamma': 0.8106791542810213, 'reg_alpha': 7.011449878810078, 'reg_lambda': 9.840285892394911}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  48%|█████████████████████▊                        | 95/200 [09:43<11:26,  6.54s/it][I 2025-01-27 11:45:56,771] Trial 95 finished with value: 0.055435250795670556 and parameters: {'n_estimators': 1295, 'learning_rate': 0.4574086154483245, 'max_depth': 9, 'subsample': 0.921411622237214, 'colsample_bytree': 0.8085407221851463, 'min_child_weight': 5, 'gamma': 0.5578227927229926, 'reg_alpha': 8.46932975763135, 'reg_lambda': 9.457085314422894}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  48%|██████████████████████                        | 96/200 [09:52<12:30,  7.21s/it][I 2025-01-27 11:46:03,418] Trial 96 finished with value: 0.05682109345901937 and parameters: {'n_estimators': 962, 'learning_rate': 0.7101911649288231, 'max_depth': 12, 'subsample': 0.9490659895215965, 'colsample_bytree': 0.8282547656700077, 'min_child_weight': 6, 'gamma': 0.24494639154704598, 'reg_alpha': 5.452791176995081, 'reg_lambda': 6.946135595921714}. Best is trial 57 with value: 0.046078972617945115.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  48%|██████████████████████▎                       | 97/200 [09:59<12:05,  7.04s/it][I 2025-01-27 11:46:16,857] Trial 97 finished with value: 0.04446191768465786 and parameters: {'n_estimators': 906, 'learning_rate': 0.15940394194217608, 'max_depth': 11, 'subsample': 0.8988895417097564, 'colsample_bytree': 0.8757047024834029, 'min_child_weight': 5, 'gamma': 0.0008657032593650059, 'reg_alpha': 7.504166194090255, 'reg_lambda': 9.589262492098147}. Best is trial 97 with value: 0.04446191768465786.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  49%|██████████████████████▌                       | 98/200 [10:12<15:14,  8.96s/it][I 2025-01-27 11:46:23,896] Trial 98 finished with value: 0.052187803971967164 and parameters: {'n_estimators': 906, 'learning_rate': 0.16280772703773755, 'max_depth': 11, 'subsample': 0.8995674189676796, 'colsample_bytree': 0.8793706613079322, 'min_child_weight': 5, 'gamma': 0.6328831472223659, 'reg_alpha': 5.945392983974112, 'reg_lambda': 9.980512712627522}. Best is trial 97 with value: 0.04446191768465786.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  50%|██████████████████████▊                       | 99/200 [10:19<14:06,  8.39s/it][I 2025-01-27 11:46:29,980] Trial 99 finished with value: 0.05964867400731022 and parameters: {'n_estimators': 847, 'learning_rate': 0.5832627400138327, 'max_depth': 10, 'subsample': 0.8639332355152074, 'colsample_bytree': 0.9226344493415909, 'min_child_weight': 4, 'gamma': 0.9547465844612352, 'reg_alpha': 8.174545125400666, 'reg_lambda': 9.589095240135462}. Best is trial 97 with value: 0.04446191768465786.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  50%|██████████████████████▌                      | 100/200 [10:25<12:49,  7.69s/it][I 2025-01-27 11:46:36,945] Trial 100 finished with value: 0.06765454867580564 and parameters: {'n_estimators': 1013, 'learning_rate': 0.6542852711850116, 'max_depth': 9, 'subsample': 0.8880132417040878, 'colsample_bytree': 0.6901452502137267, 'min_child_weight': 5, 'gamma': 5.405691841334438, 'reg_alpha': 7.536674955338776, 'reg_lambda': 9.279780156520232}. Best is trial 97 with value: 0.04446191768465786.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  50%|██████████████████████▋                      | 101/200 [10:32<12:20,  7.48s/it][I 2025-01-27 11:46:46,445] Trial 101 finished with value: 0.04905460267941338 and parameters: {'n_estimators': 1133, 'learning_rate': 0.11322522635877638, 'max_depth': 12, 'subsample': 0.9265209637871483, 'colsample_bytree': 0.8400854792006254, 'min_child_weight': 5, 'gamma': 0.20898043318637335, 'reg_alpha': 7.156140284934903, 'reg_lambda': 8.673914009022967}. Best is trial 97 with value: 0.04446191768465786.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  51%|██████████████████████▉                      | 102/200 [10:42<13:12,  8.08s/it][I 2025-01-27 11:46:56,879] Trial 102 finished with value: 0.045764907874942494 and parameters: {'n_estimators': 1153, 'learning_rate': 0.12688028049757638, 'max_depth': 11, 'subsample': 0.9340290454452715, 'colsample_bytree': 0.8403231861068806, 'min_child_weight': 5, 'gamma': 0.04106305010822108, 'reg_alpha': 2.81828706281025, 'reg_lambda': 8.990150524397368}. Best is trial 97 with value: 0.04446191768465786.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  52%|███████████████████████▏                     | 103/200 [10:52<14:12,  8.79s/it][I 2025-01-27 11:47:06,477] Trial 103 finished with value: 0.046515699092695796 and parameters: {'n_estimators': 1199, 'learning_rate': 0.18175590407030257, 'max_depth': 11, 'subsample': 0.9356817650929474, 'colsample_bytree': 0.8271662120519746, 'min_child_weight': 5, 'gamma': 0.058483068870374064, 'reg_alpha': 2.828336848891728, 'reg_lambda': 8.95659214811029}. Best is trial 97 with value: 0.04446191768465786.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  52%|███████████████████████▍                     | 104/200 [11:02<14:27,  9.03s/it][I 2025-01-27 11:47:14,564] Trial 104 finished with value: 0.04999261148964433 and parameters: {'n_estimators': 1072, 'learning_rate': 0.16857055231185028, 'max_depth': 11, 'subsample': 0.9387121927944383, 'colsample_bytree': 0.8246181448005976, 'min_child_weight': 5, 'gamma': 0.44556762469660843, 'reg_alpha': 3.245782552501594, 'reg_lambda': 8.276297235122966}. Best is trial 97 with value: 0.04446191768465786.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  52%|███████████████████████▋                     | 105/200 [11:10<13:51,  8.75s/it][I 2025-01-27 11:47:27,479] Trial 105 finished with value: 0.0477405279383253 and parameters: {'n_estimators': 1134, 'learning_rate': 0.2285653378360919, 'max_depth': 11, 'subsample': 0.9367775992821297, 'colsample_bytree': 0.5573756357369205, 'min_child_weight': 5, 'gamma': 0.0017091330348175272, 'reg_alpha': 2.79464716502598, 'reg_lambda': 9.688274076225929}. Best is trial 97 with value: 0.04446191768465786.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  53%|███████████████████████▊                     | 106/200 [11:23<15:39, 10.00s/it][I 2025-01-27 11:47:36,294] Trial 106 finished with value: 0.053826212607685206 and parameters: {'n_estimators': 1159, 'learning_rate': 0.2107391589017234, 'max_depth': 11, 'subsample': 0.9157123898205327, 'colsample_bytree': 0.5506579336378418, 'min_child_weight': 5, 'gamma': 0.23096128997454454, 'reg_alpha': 2.302372059361224, 'reg_lambda': 9.748342235623284}. Best is trial 97 with value: 0.04446191768465786.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  54%|████████████████████████                     | 107/200 [11:32<14:56,  9.64s/it][I 2025-01-27 11:47:44,290] Trial 107 finished with value: 0.05441077786527802 and parameters: {'n_estimators': 1119, 'learning_rate': 0.1849908988613248, 'max_depth': 10, 'subsample': 0.7334838389694033, 'colsample_bytree': 0.792750379210487, 'min_child_weight': 4, 'gamma': 1.1244905631912963, 'reg_alpha': 1.6539079365160414, 'reg_lambda': 8.902505852446247}. Best is trial 97 with value: 0.04446191768465786.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  54%|████████████████████████▎                    | 108/200 [11:40<14:01,  9.15s/it][I 2025-01-27 11:47:53,018] Trial 108 finished with value: 0.055402703607345394 and parameters: {'n_estimators': 1185, 'learning_rate': 0.23319317332335673, 'max_depth': 11, 'subsample': 0.9360027162525532, 'colsample_bytree': 0.5043032139952108, 'min_child_weight': 6, 'gamma': 0.4726832416490178, 'reg_alpha': 2.562882052093878, 'reg_lambda': 9.523960151246161}. Best is trial 97 with value: 0.04446191768465786.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  55%|████████████████████████▌                    | 109/200 [11:48<13:41,  9.02s/it][I 2025-01-27 11:48:00,500] Trial 109 finished with value: 0.05131839197564769 and parameters: {'n_estimators': 941, 'learning_rate': 0.13311144649290155, 'max_depth': 10, 'subsample': 0.9765090676841454, 'colsample_bytree': 0.8119724021567635, 'min_child_weight': 4, 'gamma': 0.8443713071053895, 'reg_alpha': 2.8609903138143133, 'reg_lambda': 9.813015158424031}. Best is trial 97 with value: 0.04446191768465786.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  55%|████████████████████████▊                    | 110/200 [11:56<12:50,  8.56s/it][I 2025-01-27 11:48:07,762] Trial 110 finished with value: 0.05216611507873291 and parameters: {'n_estimators': 995, 'learning_rate': 0.22867286629464006, 'max_depth': 11, 'subsample': 0.9048438940168201, 'colsample_bytree': 0.7569369389322091, 'min_child_weight': 5, 'gamma': 0.6530806195273515, 'reg_alpha': 3.4452490460161513, 'reg_lambda': 9.3040395100768}. Best is trial 97 with value: 0.04446191768465786.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  56%|████████████████████████▉                    | 111/200 [12:03<12:07,  8.17s/it][I 2025-01-27 11:48:15,621] Trial 111 finished with value: 0.057641312456535684 and parameters: {'n_estimators': 892, 'learning_rate': 0.26704610798171874, 'max_depth': 12, 'subsample': 0.9468760663444886, 'colsample_bytree': 0.6187950107639248, 'min_child_weight': 5, 'gamma': 0.05027596407865071, 'reg_alpha': 3.0641905427158176, 'reg_lambda': 7.515301701007927}. Best is trial 97 with value: 0.04446191768465786.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  56%|█████████████████████████▏                   | 112/200 [12:11<11:50,  8.08s/it][I 2025-01-27 11:48:29,081] Trial 112 finished with value: 0.04479926341951116 and parameters: {'n_estimators': 1283, 'learning_rate': 0.10204088347284491, 'max_depth': 10, 'subsample': 0.9550351608399311, 'colsample_bytree': 0.5323496125314605, 'min_child_weight': 5, 'gamma': 0.0068371720164305955, 'reg_alpha': 2.7960439382537112, 'reg_lambda': 8.861556476646578}. Best is trial 97 with value: 0.04446191768465786.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  56%|█████████████████████████▍                   | 113/200 [12:24<14:03,  9.69s/it][I 2025-01-27 11:48:51,090] Trial 113 finished with value: 0.04315726324915312 and parameters: {'n_estimators': 1303, 'learning_rate': 0.06703474014160671, 'max_depth': 10, 'subsample': 0.9642565419877993, 'colsample_bytree': 0.5255389686038499, 'min_child_weight': 5, 'gamma': 0.0008100852936684138, 'reg_alpha': 2.9083848782025745, 'reg_lambda': 9.00555952167471}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  57%|█████████████████████████▋                   | 114/200 [12:46<19:11, 13.39s/it][I 2025-01-27 11:49:03,243] Trial 114 finished with value: 0.048003952304848316 and parameters: {'n_estimators': 1337, 'learning_rate': 0.061676051227344326, 'max_depth': 10, 'subsample': 0.991290251109647, 'colsample_bytree': 0.5765563058960871, 'min_child_weight': 5, 'gamma': 0.3827546407188658, 'reg_alpha': 2.674964628439297, 'reg_lambda': 8.45567457862368}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  57%|█████████████████████████▊                   | 115/200 [12:58<18:26, 13.02s/it][I 2025-01-27 11:49:16,047] Trial 115 finished with value: 0.04784537160366686 and parameters: {'n_estimators': 1387, 'learning_rate': 0.058588410378534676, 'max_depth': 11, 'subsample': 0.9858528919209476, 'colsample_bytree': 0.5339635781641129, 'min_child_weight': 4, 'gamma': 0.3189377372683508, 'reg_alpha': 2.66465391508561, 'reg_lambda': 8.51899519344103}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  58%|██████████████████████████                   | 116/200 [13:11<18:08, 12.95s/it][I 2025-01-27 11:49:29,036] Trial 116 finished with value: 0.04741300669777184 and parameters: {'n_estimators': 1425, 'learning_rate': 0.06701288706063531, 'max_depth': 11, 'subsample': 0.9826184402932853, 'colsample_bytree': 0.5303998655974614, 'min_child_weight': 4, 'gamma': 0.19854250247318522, 'reg_alpha': 2.888138197447367, 'reg_lambda': 7.748948059685202}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  58%|██████████████████████████▎                  | 117/200 [13:24<17:56, 12.96s/it][I 2025-01-27 11:49:40,075] Trial 117 finished with value: 0.04879627766147302 and parameters: {'n_estimators': 1292, 'learning_rate': 0.10101980212344563, 'max_depth': 11, 'subsample': 0.9660791135462156, 'colsample_bytree': 0.5227581072695553, 'min_child_weight': 4, 'gamma': 0.2090033356162664, 'reg_alpha': 2.2410066136439437, 'reg_lambda': 7.261813775313521}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  59%|██████████████████████████▌                  | 118/200 [13:35<16:55, 12.39s/it][I 2025-01-27 11:49:51,133] Trial 118 finished with value: 0.05077910964196094 and parameters: {'n_estimators': 1536, 'learning_rate': 0.136496118846241, 'max_depth': 10, 'subsample': 0.9594372031993512, 'colsample_bytree': 0.5796530613440579, 'min_child_weight': 3, 'gamma': 0.5696166807912202, 'reg_alpha': 2.010526425314235, 'reg_lambda': 7.882776105004704}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  60%|██████████████████████████▊                  | 119/200 [13:46<16:11, 11.99s/it][I 2025-01-27 11:50:04,710] Trial 119 finished with value: 0.04988401800118473 and parameters: {'n_estimators': 1267, 'learning_rate': 0.03320480677122774, 'max_depth': 11, 'subsample': 0.9539952732175717, 'colsample_bytree': 0.5369964297928199, 'min_child_weight': 3, 'gamma': 0.8789145521430719, 'reg_alpha': 2.893877594679163, 'reg_lambda': 7.7481162987227465}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  60%|███████████████████████████                  | 120/200 [14:00<16:37, 12.46s/it][I 2025-01-27 11:50:15,340] Trial 120 finished with value: 0.050659405338614384 and parameters: {'n_estimators': 1372, 'learning_rate': 0.14383846735725372, 'max_depth': 12, 'subsample': 0.9299908904402401, 'colsample_bytree': 0.5142205730083005, 'min_child_weight': 6, 'gamma': 0.2224267516549638, 'reg_alpha': 3.5542543010282523, 'reg_lambda': 8.972176417250179}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  60%|███████████████████████████▏                 | 121/200 [14:11<15:41, 11.91s/it][I 2025-01-27 11:50:26,952] Trial 121 finished with value: 0.049106530142846196 and parameters: {'n_estimators': 1436, 'learning_rate': 0.09569847895345955, 'max_depth': 11, 'subsample': 0.9842661569715424, 'colsample_bytree': 0.5676316618425977, 'min_child_weight': 4, 'gamma': 0.3789866720765683, 'reg_alpha': 2.740866981758193, 'reg_lambda': 8.765527232462226}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  61%|███████████████████████████▍                 | 122/200 [14:22<15:22, 11.82s/it][I 2025-01-27 11:50:38,063] Trial 122 finished with value: 0.048046248623157095 and parameters: {'n_estimators': 1206, 'learning_rate': 0.08351553252204727, 'max_depth': 11, 'subsample': 0.9663173107463693, 'colsample_bytree': 0.537243563764027, 'min_child_weight': 4, 'gamma': 0.20052452151378175, 'reg_alpha': 1.7365320344574813, 'reg_lambda': 8.623376205380346}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  62%|███████████████████████████▋                 | 123/200 [14:33<14:53, 11.61s/it][I 2025-01-27 11:50:51,986] Trial 123 finished with value: 0.048769266306393014 and parameters: {'n_estimators': 1411, 'learning_rate': 0.04007416191003868, 'max_depth': 11, 'subsample': 0.9748139026348954, 'colsample_bytree': 0.5231411414605855, 'min_child_weight': 3, 'gamma': 0.6332234305029921, 'reg_alpha': 2.49283117561565, 'reg_lambda': 8.048500567497037}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  62%|███████████████████████████▉                 | 124/200 [14:47<15:35, 12.30s/it][I 2025-01-27 11:51:02,944] Trial 124 finished with value: 0.04969901279510732 and parameters: {'n_estimators': 1469, 'learning_rate': 0.11946448967586443, 'max_depth': 10, 'subsample': 0.9970367024127401, 'colsample_bytree': 0.5363456961804198, 'min_child_weight': 5, 'gamma': 0.45660840837903144, 'reg_alpha': 3.0947350466161194, 'reg_lambda': 8.413307410760417}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  62%|████████████████████████████▏                | 125/200 [14:58<14:52, 11.90s/it][I 2025-01-27 11:51:13,264] Trial 125 finished with value: 0.057637885313961856 and parameters: {'n_estimators': 1357, 'learning_rate': 0.07363492352890198, 'max_depth': 10, 'subsample': 0.9805738077396159, 'colsample_bytree': 0.5624794544411568, 'min_child_weight': 5, 'gamma': 4.3170588426893515, 'reg_alpha': 2.211008183911865, 'reg_lambda': 9.129955767713035}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  63%|████████████████████████████▎                | 126/200 [15:08<14:05, 11.43s/it][I 2025-01-27 11:51:30,414] Trial 126 finished with value: 0.04450197491494971 and parameters: {'n_estimators': 1320, 'learning_rate': 0.059773881584540646, 'max_depth': 11, 'subsample': 0.9204505177694239, 'colsample_bytree': 0.5448021585837765, 'min_child_weight': 4, 'gamma': 0.009155412529603082, 'reg_alpha': 3.7839788776779923, 'reg_lambda': 8.211024212963402}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  64%|████████████████████████████▌                | 127/200 [15:26<15:59, 13.14s/it][I 2025-01-27 11:51:40,539] Trial 127 finished with value: 0.04998974175094078 and parameters: {'n_estimators': 1169, 'learning_rate': 0.17475548549846875, 'max_depth': 12, 'subsample': 0.9102358814191557, 'colsample_bytree': 0.555864887174948, 'min_child_weight': 4, 'gamma': 0.0325122156714288, 'reg_alpha': 3.6578047979684816, 'reg_lambda': 7.705800771574095}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  64%|████████████████████████████▊                | 128/200 [15:36<14:41, 12.24s/it][I 2025-01-27 11:51:49,886] Trial 128 finished with value: 0.05564111934121163 and parameters: {'n_estimators': 1268, 'learning_rate': 0.1109882801558712, 'max_depth': 10, 'subsample': 0.9239349128960089, 'colsample_bytree': 0.5902407710587579, 'min_child_weight': 6, 'gamma': 2.8742239853511102, 'reg_alpha': 2.9568768545053277, 'reg_lambda': 8.140278752284704}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  64%|█████████████████████████████                | 129/200 [15:45<13:27, 11.37s/it][I 2025-01-27 11:52:00,335] Trial 129 finished with value: 0.054618267067635874 and parameters: {'n_estimators': 1485, 'learning_rate': 0.19322390929123762, 'max_depth': 11, 'subsample': 0.8988493790252243, 'colsample_bytree': 0.5124319207116551, 'min_child_weight': 1, 'gamma': 0.7821667627875872, 'reg_alpha': 3.256259160501475, 'reg_lambda': 7.396456299113265}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  65%|█████████████████████████████▎               | 130/200 [15:56<12:56, 11.09s/it][I 2025-01-27 11:52:28,416] Trial 130 finished with value: 0.0490265607621616 and parameters: {'n_estimators': 1056, 'learning_rate': 0.010119566459886986, 'max_depth': 10, 'subsample': 0.955805666819962, 'colsample_bytree': 0.5233818667497467, 'min_child_weight': 5, 'gamma': 0.17263584063037452, 'reg_alpha': 3.4132916038760275, 'reg_lambda': 8.873771343222417}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  66%|█████████████████████████████▍               | 131/200 [16:24<18:37, 16.19s/it][I 2025-01-27 11:52:40,567] Trial 131 finished with value: 0.04815883516663048 and parameters: {'n_estimators': 1295, 'learning_rate': 0.06013276300391653, 'max_depth': 11, 'subsample': 0.9873269175590729, 'colsample_bytree': 0.5404526051668488, 'min_child_weight': 4, 'gamma': 0.37597461662782744, 'reg_alpha': 2.8116861018447548, 'reg_lambda': 8.504304474849917}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  66%|█████████████████████████████▋               | 132/200 [16:36<16:58, 14.98s/it][I 2025-01-27 11:52:52,830] Trial 132 finished with value: 0.05309843816235427 and parameters: {'n_estimators': 1653, 'learning_rate': 0.15120001001400135, 'max_depth': 12, 'subsample': 0.9211750540770183, 'colsample_bytree': 0.5462766609822941, 'min_child_weight': 4, 'gamma': 0.30139109290826444, 'reg_alpha': 2.454831486967007, 'reg_lambda': 3.0141529812712067}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  66%|█████████████████████████████▉               | 133/200 [16:48<15:48, 14.16s/it][I 2025-01-27 11:53:18,248] Trial 133 finished with value: 0.04353168609618339 and parameters: {'n_estimators': 1362, 'learning_rate': 0.04059467681136614, 'max_depth': 11, 'subsample': 0.968850177930612, 'colsample_bytree': 0.5291541763860772, 'min_child_weight': 5, 'gamma': 0.0043528031977667515, 'reg_alpha': 1.8784473472381136, 'reg_lambda': 7.919651521600077}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  67%|██████████████████████████████▏              | 134/200 [17:13<19:17, 17.54s/it][I 2025-01-27 11:53:29,893] Trial 134 finished with value: 0.047458907265509095 and parameters: {'n_estimators': 1137, 'learning_rate': 0.07379943768074887, 'max_depth': 11, 'subsample': 0.9517789334438997, 'colsample_bytree': 0.5160245927518469, 'min_child_weight': 5, 'gamma': 0.13620736017048773, 'reg_alpha': 1.219475278991232, 'reg_lambda': 7.582371305063318}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  68%|██████████████████████████████▍              | 135/200 [17:25<17:05, 15.77s/it][I 2025-01-27 11:53:41,266] Trial 135 finished with value: 0.04940405255944086 and parameters: {'n_estimators': 1323, 'learning_rate': 0.07157640647162311, 'max_depth': 11, 'subsample': 0.9687324469264901, 'colsample_bytree': 0.5008906905456415, 'min_child_weight': 5, 'gamma': 0.5673063599895131, 'reg_alpha': 3.924466940124039, 'reg_lambda': 7.104380149145143}. Best is trial 113 with value: 0.04315726324915312.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  68%|██████████████████████████████▌              | 136/200 [17:36<15:24, 14.45s/it][I 2025-01-27 11:54:10,556] Trial 136 finished with value: 0.04306358696907869 and parameters: {'n_estimators': 1205, 'learning_rate': 0.030691982149738693, 'max_depth': 10, 'subsample': 0.9489569259831769, 'colsample_bytree': 0.5135054255270579, 'min_child_weight': 5, 'gamma': 0.004102145036812915, 'reg_alpha': 1.215433464182811, 'reg_lambda': 7.953439442247487}. Best is trial 136 with value: 0.04306358696907869.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  68%|██████████████████████████████▊              | 137/200 [18:06<19:50, 18.90s/it][I 2025-01-27 11:54:21,643] Trial 137 finished with value: 0.06079324622080999 and parameters: {'n_estimators': 1211, 'learning_rate': 0.03122417633968494, 'max_depth': 10, 'subsample': 0.9504805379292487, 'colsample_bytree': 0.5129914807282491, 'min_child_weight': 6, 'gamma': 6.7396717427494846, 'reg_alpha': 1.251577019520317, 'reg_lambda': 7.919443323008185}. Best is trial 136 with value: 0.04306358696907869.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  69%|███████████████████████████████              | 138/200 [18:17<17:06, 16.56s/it][I 2025-01-27 11:54:35,799] Trial 138 finished with value: 0.04677408361859757 and parameters: {'n_estimators': 1326, 'learning_rate': 0.04604748317729465, 'max_depth': 10, 'subsample': 0.9451881864693419, 'colsample_bytree': 0.526940287068471, 'min_child_weight': 5, 'gamma': 0.20168946984202835, 'reg_alpha': 1.4023743438585832, 'reg_lambda': 6.87784049026609}. Best is trial 136 with value: 0.04306358696907869.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  70%|███████████████████████████████▎             | 139/200 [18:31<16:06, 15.84s/it][I 2025-01-27 11:54:46,611] Trial 139 finished with value: 0.04938953989617119 and parameters: {'n_estimators': 1329, 'learning_rate': 0.09351581943779286, 'max_depth': 10, 'subsample': 0.9629618046819217, 'colsample_bytree': 0.5300199611428651, 'min_child_weight': 5, 'gamma': 0.4594863905056667, 'reg_alpha': 1.4504475916145605, 'reg_lambda': 6.833341907241859}. Best is trial 136 with value: 0.04306358696907869.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  70%|███████████████████████████████▍             | 140/200 [18:42<14:19, 14.33s/it][I 2025-01-27 11:54:58,157] Trial 140 finished with value: 0.04925406521146838 and parameters: {'n_estimators': 1190, 'learning_rate': 0.048105372944062044, 'max_depth': 10, 'subsample': 0.943983566115846, 'colsample_bytree': 0.5501712482280645, 'min_child_weight': 6, 'gamma': 0.732156716820698, 'reg_alpha': 1.1969830441500633, 'reg_lambda': 6.3979478640664365}. Best is trial 136 with value: 0.04306358696907869.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  70%|███████████████████████████████▋             | 141/200 [18:53<13:16, 13.49s/it][I 2025-01-27 11:55:18,441] Trial 141 finished with value: 0.0466567892417193 and parameters: {'n_estimators': 1288, 'learning_rate': 0.023679148311528217, 'max_depth': 11, 'subsample': 0.9561326819282668, 'colsample_bytree': 0.5180260146785621, 'min_child_weight': 5, 'gamma': 0.21104800448075184, 'reg_alpha': 0.6873267460202285, 'reg_lambda': 7.608950023644884}. Best is trial 136 with value: 0.04306358696907869.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  71%|███████████████████████████████▉             | 142/200 [19:14<15:00, 15.53s/it][I 2025-01-27 11:55:39,202] Trial 142 finished with value: 0.04620970845289267 and parameters: {'n_estimators': 1284, 'learning_rate': 0.021926713593760288, 'max_depth': 10, 'subsample': 0.9718282997649099, 'colsample_bytree': 0.5270438831394435, 'min_child_weight': 5, 'gamma': 0.19414123364229427, 'reg_alpha': 0.31731010742218035, 'reg_lambda': 7.304243881120854}. Best is trial 136 with value: 0.04306358696907869.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  72%|████████████████████████████████▏            | 143/200 [19:34<16:14, 17.10s/it][I 2025-01-27 11:55:57,097] Trial 143 finished with value: 0.04769951599858214 and parameters: {'n_estimators': 1257, 'learning_rate': 0.022449219366962373, 'max_depth': 10, 'subsample': 0.9311356140497469, 'colsample_bytree': 0.5233685592055116, 'min_child_weight': 5, 'gamma': 0.44811050597159946, 'reg_alpha': 0.378377850637746, 'reg_lambda': 7.243473101851789}. Best is trial 136 with value: 0.04306358696907869.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  72%|████████████████████████████████▍            | 144/200 [19:52<16:10, 17.34s/it][I 2025-01-27 11:56:19,214] Trial 144 finished with value: 0.04382500928867586 and parameters: {'n_estimators': 1362, 'learning_rate': 0.038019067873464, 'max_depth': 10, 'subsample': 0.972278028389489, 'colsample_bytree': 0.5048189629411276, 'min_child_weight': 5, 'gamma': 0.015641390127605556, 'reg_alpha': 0.2963652049051769, 'reg_lambda': 7.541721472479304}. Best is trial 136 with value: 0.04306358696907869.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  72%|████████████████████████████████▋            | 145/200 [20:14<17:12, 18.77s/it][I 2025-01-27 11:56:34,775] Trial 145 finished with value: 0.04663012001371457 and parameters: {'n_estimators': 1350, 'learning_rate': 0.039142395045038345, 'max_depth': 10, 'subsample': 0.9712382521798306, 'colsample_bytree': 0.5060626519739282, 'min_child_weight': 5, 'gamma': 0.2169903115881536, 'reg_alpha': 0.5489378579417722, 'reg_lambda': 7.436932501821174}. Best is trial 136 with value: 0.04306358696907869.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  73%|████████████████████████████████▊            | 146/200 [20:30<16:01, 17.81s/it][I 2025-01-27 11:56:49,060] Trial 146 finished with value: 0.046981594405781556 and parameters: {'n_estimators': 1352, 'learning_rate': 0.04430054476193235, 'max_depth': 10, 'subsample': 0.9759000188102788, 'colsample_bytree': 0.5032255810498982, 'min_child_weight': 5, 'gamma': 0.26099484157691055, 'reg_alpha': 0.5295269843689563, 'reg_lambda': 7.497512522981542}. Best is trial 136 with value: 0.04306358696907869.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  74%|█████████████████████████████████            | 147/200 [20:44<14:47, 16.75s/it][I 2025-01-27 11:57:10,089] Trial 147 finished with value: 0.048061317007021556 and parameters: {'n_estimators': 1282, 'learning_rate': 0.01620868922618654, 'max_depth': 10, 'subsample': 0.9720079577010747, 'colsample_bytree': 0.5104321289427832, 'min_child_weight': 5, 'gamma': 0.6123880340334837, 'reg_alpha': 0.0013705959038914362, 'reg_lambda': 7.094326524040718}. Best is trial 136 with value: 0.04306358696907869.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  74%|█████████████████████████████████▎           | 148/200 [21:05<15:37, 18.03s/it][I 2025-01-27 11:57:22,979] Trial 148 finished with value: 0.05159356898846632 and parameters: {'n_estimators': 1309, 'learning_rate': 0.036823677779564114, 'max_depth': 10, 'subsample': 0.6721054954999505, 'colsample_bytree': 0.5001832195613495, 'min_child_weight': 5, 'gamma': 1.0589449659533325, 'reg_alpha': 0.7910841573997458, 'reg_lambda': 7.3692095633687185}. Best is trial 136 with value: 0.04306358696907869.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  74%|█████████████████████████████████▌           | 149/200 [21:18<14:01, 16.49s/it][I 2025-01-27 11:57:33,824] Trial 149 finished with value: 0.04983391389757415 and parameters: {'n_estimators': 1240, 'learning_rate': 0.0900297586635457, 'max_depth': 11, 'subsample': 0.964968077595699, 'colsample_bytree': 0.5449928274992949, 'min_child_weight': 6, 'gamma': 0.3490650689497131, 'reg_alpha': 0.31941123188605336, 'reg_lambda': 6.817521439087716}. Best is trial 136 with value: 0.04306358696907869.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  75%|█████████████████████████████████▊           | 150/200 [21:29<12:19, 14.80s/it][I 2025-01-27 11:57:54,928] Trial 150 finished with value: 0.054997772093582156 and parameters: {'n_estimators': 1388, 'learning_rate': 0.01008894074326133, 'max_depth': 9, 'subsample': 0.9428771611864418, 'colsample_bytree': 0.5235297050830899, 'min_child_weight': 5, 'gamma': 3.4010238896548617, 'reg_alpha': 1.018417734958185, 'reg_lambda': 7.670135156003931}. Best is trial 136 with value: 0.04306358696907869.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  76%|█████████████████████████████████▉           | 151/200 [21:50<13:37, 16.69s/it][I 2025-01-27 11:58:08,534] Trial 151 finished with value: 0.046768496769814316 and parameters: {'n_estimators': 1336, 'learning_rate': 0.0513937826704786, 'max_depth': 10, 'subsample': 0.9947870262572162, 'colsample_bytree': 0.5068815814343154, 'min_child_weight': 5, 'gamma': 0.20571769636631937, 'reg_alpha': 0.8548656233769754, 'reg_lambda': 7.471540108700438}. Best is trial 136 with value: 0.04306358696907869.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  76%|██████████████████████████████████▏          | 152/200 [22:04<12:36, 15.76s/it][I 2025-01-27 11:58:19,374] Trial 152 finished with value: 0.04855238170698532 and parameters: {'n_estimators': 1337, 'learning_rate': 0.12604753409473457, 'max_depth': 10, 'subsample': 0.9969114730145638, 'colsample_bytree': 0.5167810117194471, 'min_child_weight': 5, 'gamma': 0.14792291191029125, 'reg_alpha': 0.7251838983298983, 'reg_lambda': 8.198250041343778}. Best is trial 136 with value: 0.04306358696907869.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  76%|██████████████████████████████████▍          | 153/200 [22:15<11:11, 14.29s/it][I 2025-01-27 11:58:32,913] Trial 153 finished with value: 0.04838408689169047 and parameters: {'n_estimators': 1474, 'learning_rate': 0.05049722315309725, 'max_depth': 10, 'subsample': 0.9737496943829275, 'colsample_bytree': 0.5301686207214308, 'min_child_weight': 5, 'gamma': 0.5216012571783701, 'reg_alpha': 0.49378414791319414, 'reg_lambda': 6.499178593430884}. Best is trial 136 with value: 0.04306358696907869.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  77%|██████████████████████████████████▋          | 154/200 [22:28<10:46, 14.06s/it][I 2025-01-27 11:59:18,844] Trial 154 finished with value: 0.04253985109234789 and parameters: {'n_estimators': 1368, 'learning_rate': 0.030161369686668077, 'max_depth': 10, 'subsample': 0.958581405196935, 'colsample_bytree': 0.5076047061002801, 'min_child_weight': 5, 'gamma': 0.0016039606583165278, 'reg_alpha': 0.15452489430967065, 'reg_lambda': 7.196112221853119}. Best is trial 154 with value: 0.04253985109234789.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  78%|██████████████████████████████████▉          | 155/200 [23:14<17:43, 23.62s/it][I 2025-01-27 12:00:07,206] Trial 155 finished with value: 0.04274236142642908 and parameters: {'n_estimators': 1374, 'learning_rate': 0.10007930004427254, 'max_depth': 10, 'subsample': 0.9584610492567274, 'colsample_bytree': 0.5087762461991235, 'min_child_weight': 5, 'gamma': 0.00019068309827752206, 'reg_alpha': 0.9179732728694, 'reg_lambda': 7.157053245235111}. Best is trial 154 with value: 0.04253985109234789.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  78%|███████████████████████████████████          | 156/200 [24:02<22:45, 31.04s/it][I 2025-01-27 12:00:21,866] Trial 156 finished with value: 0.04807448430185063 and parameters: {'n_estimators': 1533, 'learning_rate': 0.10991711920080253, 'max_depth': 11, 'subsample': 0.9585351396542595, 'colsample_bytree': 0.517287819450282, 'min_child_weight': 5, 'gamma': 0.03157446474087681, 'reg_alpha': 0.19431019489550372, 'reg_lambda': 7.22251768544312}. Best is trial 154 with value: 0.04253985109234789.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  78%|███████████████████████████████████▎         | 157/200 [24:17<18:43, 26.13s/it][I 2025-01-27 12:00:40,175] Trial 157 finished with value: 0.04376990323572496 and parameters: {'n_estimators': 1400, 'learning_rate': 0.08484070260272578, 'max_depth': 9, 'subsample': 0.7754254921323205, 'colsample_bytree': 0.5093536063735644, 'min_child_weight': 6, 'gamma': 0.005008611677961411, 'reg_alpha': 0.6512947647558612, 'reg_lambda': 7.734406725167519}. Best is trial 154 with value: 0.04253985109234789.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  79%|███████████████████████████████████▌         | 158/200 [24:35<16:38, 23.78s/it][I 2025-01-27 12:00:51,567] Trial 158 finished with value: 0.049235978512035615 and parameters: {'n_estimators': 1417, 'learning_rate': 0.08804501055211089, 'max_depth': 9, 'subsample': 0.8168814471838906, 'colsample_bytree': 0.5109630273066633, 'min_child_weight': 6, 'gamma': 0.3700767473258765, 'reg_alpha': 0.6231293493243523, 'reg_lambda': 7.824226512393278}. Best is trial 154 with value: 0.04253985109234789.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  80%|███████████████████████████████████▊         | 159/200 [24:47<13:42, 20.07s/it][I 2025-01-27 12:01:06,974] Trial 159 finished with value: 0.04930628089633766 and parameters: {'n_estimators': 1378, 'learning_rate': 0.026797782896359302, 'max_depth': 9, 'subsample': 0.7540260204330025, 'colsample_bytree': 0.5430558117914911, 'min_child_weight': 6, 'gamma': 0.6891290985225922, 'reg_alpha': 0.189963001427628, 'reg_lambda': 8.242857466926413}. Best is trial 154 with value: 0.04253985109234789.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  80%|████████████████████████████████████         | 160/200 [25:02<12:26, 18.67s/it][I 2025-01-27 12:01:18,384] Trial 160 finished with value: 0.05118881362927448 and parameters: {'n_estimators': 1267, 'learning_rate': 0.06872828556722173, 'max_depth': 11, 'subsample': 0.703167655353175, 'colsample_bytree': 0.5003006342185673, 'min_child_weight': 6, 'gamma': 0.4445554364707317, 'reg_alpha': 0.9692102159560004, 'reg_lambda': 7.08663034240026}. Best is trial 154 with value: 0.04253985109234789.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  80%|████████████████████████████████████▏        | 161/200 [25:14<10:43, 16.49s/it][I 2025-01-27 12:01:33,284] Trial 161 finished with value: 0.047390153796415244 and parameters: {'n_estimators': 1218, 'learning_rate': 0.14227793174532305, 'max_depth': 10, 'subsample': 0.7408000344883122, 'colsample_bytree': 0.515650135919864, 'min_child_weight': 5, 'gamma': 0.0074196527862776555, 'reg_alpha': 0.40764025164263473, 'reg_lambda': 7.354193533524761}. Best is trial 154 with value: 0.04253985109234789.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  81%|████████████████████████████████████▍        | 162/200 [25:29<10:08, 16.01s/it][I 2025-01-27 12:01:45,024] Trial 162 finished with value: 0.04959311740542974 and parameters: {'n_estimators': 1459, 'learning_rate': 0.102983322019781, 'max_depth': 10, 'subsample': 0.8008309638959429, 'colsample_bytree': 0.5277229846047614, 'min_child_weight': 5, 'gamma': 0.2014090337800331, 'reg_alpha': 1.8323738909141547, 'reg_lambda': 7.587209003305209}. Best is trial 154 with value: 0.04253985109234789.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  82%|████████████████████████████████████▋        | 163/200 [25:40<09:05, 14.73s/it][I 2025-01-27 12:02:00,414] Trial 163 finished with value: 0.04653247719225518 and parameters: {'n_estimators': 1374, 'learning_rate': 0.08196489106125986, 'max_depth': 11, 'subsample': 0.8335054444581813, 'colsample_bytree': 0.5368745745222402, 'min_child_weight': 5, 'gamma': 0.02039736946037343, 'reg_alpha': 0.5975656400225189, 'reg_lambda': 8.02281534929488}. Best is trial 154 with value: 0.04253985109234789.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  82%|████████████████████████████████████▉        | 164/200 [25:56<08:57, 14.93s/it][I 2025-01-27 12:02:12,565] Trial 164 finished with value: 0.050478620499300395 and parameters: {'n_estimators': 1399, 'learning_rate': 0.08074054196528675, 'max_depth': 11, 'subsample': 0.7840691378219754, 'colsample_bytree': 0.5381019509540124, 'min_child_weight': 5, 'gamma': 0.32161873147902154, 'reg_alpha': 0.6502568521864942, 'reg_lambda': 7.935572205721084}. Best is trial 154 with value: 0.04253985109234789.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  82%|█████████████████████████████████████▏       | 165/200 [26:08<08:13, 14.10s/it][I 2025-01-27 12:02:34,180] Trial 165 finished with value: 0.04484753992057454 and parameters: {'n_estimators': 1371, 'learning_rate': 0.03758660481479868, 'max_depth': 11, 'subsample': 0.8420604117857078, 'colsample_bytree': 0.5099720831471221, 'min_child_weight': 6, 'gamma': 0.022753319071158053, 'reg_alpha': 0.9847098022294948, 'reg_lambda': 8.062861712945882}. Best is trial 154 with value: 0.04253985109234789.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  83%|█████████████████████████████████████▎       | 166/200 [26:29<09:15, 16.35s/it][I 2025-01-27 12:02:50,277] Trial 166 finished with value: 0.053531960183979044 and parameters: {'n_estimators': 1498, 'learning_rate': 0.12918724834030187, 'max_depth': 11, 'subsample': 0.8345587906379784, 'colsample_bytree': 0.5667533249638662, 'min_child_weight': 6, 'gamma': 0.01916828842643549, 'reg_alpha': 0.0015334170377538925, 'reg_lambda': 0.8014928291420107}. Best is trial 154 with value: 0.04253985109234789.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  84%|█████████████████████████████████████▌       | 167/200 [26:46<08:57, 16.28s/it][I 2025-01-27 12:03:09,926] Trial 167 finished with value: 0.045007086669206685 and parameters: {'n_estimators': 1363, 'learning_rate': 0.06640773697688038, 'max_depth': 11, 'subsample': 0.7743571549753896, 'colsample_bytree': 0.5100632052261684, 'min_child_weight': 6, 'gamma': 0.007645184828898768, 'reg_alpha': 1.0019282306012725, 'reg_lambda': 8.224385836334992}. Best is trial 154 with value: 0.04253985109234789.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  84%|█████████████████████████████████████▊       | 168/200 [27:05<09:13, 17.29s/it][I 2025-01-27 12:03:28,936] Trial 168 finished with value: 0.04506607452179622 and parameters: {'n_estimators': 1572, 'learning_rate': 0.06557996601209945, 'max_depth': 11, 'subsample': 0.8429086223791751, 'colsample_bytree': 0.5512409263656437, 'min_child_weight': 6, 'gamma': 0.01132243658062436, 'reg_alpha': 1.0758106695244942, 'reg_lambda': 8.153685828174874}. Best is trial 154 with value: 0.04253985109234789.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  84%|██████████████████████████████████████       | 169/200 [27:24<09:11, 17.80s/it][I 2025-01-27 12:03:40,829] Trial 169 finished with value: 0.05647506478006366 and parameters: {'n_estimators': 1606, 'learning_rate': 0.15797098607694968, 'max_depth': 12, 'subsample': 0.841679387462226, 'colsample_bytree': 0.5486609855977785, 'min_child_weight': 6, 'gamma': 0.48974053140445906, 'reg_alpha': 0.9331178386787979, 'reg_lambda': 8.34600150563979}. Best is trial 154 with value: 0.04253985109234789.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  85%|██████████████████████████████████████▎      | 170/200 [27:36<08:00, 16.03s/it][I 2025-01-27 12:03:53,467] Trial 170 finished with value: 0.05259115842434033 and parameters: {'n_estimators': 1707, 'learning_rate': 0.10436617625178993, 'max_depth': 11, 'subsample': 0.8666257922400032, 'colsample_bytree': 0.6435440005748718, 'min_child_weight': 6, 'gamma': 0.7419981127482491, 'reg_alpha': 1.4964259660589263, 'reg_lambda': 8.695518153655625}. Best is trial 154 with value: 0.04253985109234789.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  86%|██████████████████████████████████████▍      | 171/200 [27:49<07:15, 15.01s/it][I 2025-01-27 12:04:08,916] Trial 171 finished with value: 0.04609351869886565 and parameters: {'n_estimators': 1377, 'learning_rate': 0.07147635749697434, 'max_depth': 11, 'subsample': 0.8271665818530466, 'colsample_bytree': 0.5368644548957783, 'min_child_weight': 6, 'gamma': 0.02402528946044204, 'reg_alpha': 1.0252408247916789, 'reg_lambda': 8.122367740136987}. Best is trial 154 with value: 0.04253985109234789.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  86%|██████████████████████████████████████▋      | 172/200 [28:04<07:04, 15.14s/it][I 2025-01-27 12:04:24,531] Trial 172 finished with value: 0.04864130009980179 and parameters: {'n_estimators': 1813, 'learning_rate': 0.06267303935319571, 'max_depth': 11, 'subsample': 0.7790301558973359, 'colsample_bytree': 0.5560889138838155, 'min_child_weight': 6, 'gamma': 0.2137062514668668, 'reg_alpha': 1.0848537644661347, 'reg_lambda': 8.170546104387785}. Best is trial 154 with value: 0.04253985109234789.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  86%|██████████████████████████████████████▉      | 173/200 [28:20<06:52, 15.29s/it][I 2025-01-27 12:05:33,436] Trial 173 finished with value: 0.042281751825234457 and parameters: {'n_estimators': 1433, 'learning_rate': 0.06577429086290515, 'max_depth': 11, 'subsample': 0.7623970628578274, 'colsample_bytree': 0.9807525044569172, 'min_child_weight': 6, 'gamma': 0.0007222076305085732, 'reg_alpha': 1.1191881067061473, 'reg_lambda': 8.375651254942353}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  87%|███████████████████████████████████████▏     | 174/200 [29:29<13:35, 31.37s/it][I 2025-01-27 12:05:46,228] Trial 174 finished with value: 0.049160672137214007 and parameters: {'n_estimators': 1420, 'learning_rate': 0.06167132173138029, 'max_depth': 11, 'subsample': 0.7605292237062816, 'colsample_bytree': 0.9512004984446968, 'min_child_weight': 6, 'gamma': 0.35848986348487966, 'reg_alpha': 1.3135249801092364, 'reg_lambda': 8.38815847080503}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  88%|███████████████████████████████████████▍     | 175/200 [29:41<10:44, 25.80s/it][I 2025-01-27 12:06:16,740] Trial 175 finished with value: 0.04978857228126309 and parameters: {'n_estimators': 1509, 'learning_rate': 0.010577078429732302, 'max_depth': 11, 'subsample': 0.8208856509321522, 'colsample_bytree': 0.9719572073945276, 'min_child_weight': 6, 'gamma': 0.5306727402398671, 'reg_alpha': 1.0313477011398877, 'reg_lambda': 7.827636760562137}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  88%|███████████████████████████████████████▌     | 176/200 [30:12<10:53, 27.21s/it][I 2025-01-27 12:06:40,789] Trial 176 finished with value: 0.04281681465391331 and parameters: {'n_estimators': 1555, 'learning_rate': 0.09110970966287221, 'max_depth': 12, 'subsample': 0.7982410181225457, 'colsample_bytree': 0.9961148969019703, 'min_child_weight': 6, 'gamma': 0.0053001558267693795, 'reg_alpha': 0.24572284109518486, 'reg_lambda': 8.268425742147645}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  88%|███████████████████████████████████████▊     | 177/200 [30:36<10:04, 26.26s/it][I 2025-01-27 12:06:55,853] Trial 177 finished with value: 0.0443822553620305 and parameters: {'n_estimators': 1445, 'learning_rate': 0.09897139198757089, 'max_depth': 12, 'subsample': 0.8033178629645702, 'colsample_bytree': 0.9868890246450285, 'min_child_weight': 6, 'gamma': 0.0173097790160043, 'reg_alpha': 1.6350041552135304, 'reg_lambda': 8.099249735665778}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  89%|████████████████████████████████████████     | 178/200 [30:51<08:23, 22.90s/it][I 2025-01-27 12:07:11,837] Trial 178 finished with value: 0.04384085619817278 and parameters: {'n_estimators': 1570, 'learning_rate': 0.12020635383702405, 'max_depth': 12, 'subsample': 0.7983848945350301, 'colsample_bytree': 0.9841814873292539, 'min_child_weight': 6, 'gamma': 0.009955767999074425, 'reg_alpha': 1.5669481272152934, 'reg_lambda': 8.577339643720913}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  90%|████████████████████████████████████████▎    | 179/200 [31:07<07:17, 20.83s/it][I 2025-01-27 12:07:23,735] Trial 179 finished with value: 0.04954888716914689 and parameters: {'n_estimators': 1568, 'learning_rate': 0.11785905603212626, 'max_depth': 12, 'subsample': 0.7713589466105546, 'colsample_bytree': 0.9999539276428204, 'min_child_weight': 6, 'gamma': 0.368576214378551, 'reg_alpha': 1.699475369522174, 'reg_lambda': 8.578239100869645}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  90%|████████████████████████████████████████▌    | 180/200 [31:19<06:02, 18.15s/it][I 2025-01-27 12:07:39,099] Trial 180 finished with value: 0.04432583146322818 and parameters: {'n_estimators': 1445, 'learning_rate': 0.09922187629707016, 'max_depth': 12, 'subsample': 0.795526120788312, 'colsample_bytree': 0.9815716129171387, 'min_child_weight': 6, 'gamma': 0.014444703952638527, 'reg_alpha': 2.033583132625971, 'reg_lambda': 8.377313188579768}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  90%|████████████████████████████████████████▋    | 181/200 [31:34<05:28, 17.31s/it][I 2025-01-27 12:07:54,189] Trial 181 finished with value: 0.04463986498510595 and parameters: {'n_estimators': 1577, 'learning_rate': 0.1059076533629462, 'max_depth': 12, 'subsample': 0.8019204009242414, 'colsample_bytree': 0.9864573710933005, 'min_child_weight': 6, 'gamma': 0.02075040171389699, 'reg_alpha': 1.9509747275678977, 'reg_lambda': 8.325814446272151}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  91%|████████████████████████████████████████▉    | 182/200 [31:49<04:59, 16.65s/it][I 2025-01-27 12:08:07,613] Trial 182 finished with value: 0.048215785971811004 and parameters: {'n_estimators': 1622, 'learning_rate': 0.09425274080362588, 'max_depth': 13, 'subsample': 0.8010105014218049, 'colsample_bytree': 0.9774260537882601, 'min_child_weight': 6, 'gamma': 0.21589377432059326, 'reg_alpha': 2.048414127176766, 'reg_lambda': 8.321884413680106}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  92%|█████████████████████████████████████████▏   | 183/200 [32:03<04:26, 15.68s/it][I 2025-01-27 12:08:20,118] Trial 183 finished with value: 0.04928268060617437 and parameters: {'n_estimators': 1579, 'learning_rate': 0.10009007028417308, 'max_depth': 12, 'subsample': 0.7919030390215206, 'colsample_bytree': 0.9879546055830617, 'min_child_weight': 6, 'gamma': 0.3702350223546991, 'reg_alpha': 1.590657092078608, 'reg_lambda': 8.485502558079492}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  92%|█████████████████████████████████████████▍   | 184/200 [32:15<03:55, 14.73s/it][I 2025-01-27 12:08:31,142] Trial 184 finished with value: 0.06723498387036836 and parameters: {'n_estimators': 1552, 'learning_rate': 0.08168833529209085, 'max_depth': 12, 'subsample': 0.7702336419740685, 'colsample_bytree': 0.9750168599454361, 'min_child_weight': 7, 'gamma': 8.687415480933762, 'reg_alpha': 1.9009763645959576, 'reg_lambda': 8.092350151692287}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  92%|█████████████████████████████████████████▋   | 185/200 [32:26<03:24, 13.62s/it][I 2025-01-27 12:08:53,942] Trial 185 finished with value: 0.043835861699091275 and parameters: {'n_estimators': 1444, 'learning_rate': 0.04924726910180309, 'max_depth': 12, 'subsample': 0.8110047715164819, 'colsample_bytree': 0.994639490596305, 'min_child_weight': 6, 'gamma': 0.011488317809542764, 'reg_alpha': 1.481421242613476, 'reg_lambda': 8.78093045508671}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  93%|█████████████████████████████████████████▊   | 186/200 [32:49<03:49, 16.37s/it][I 2025-01-27 12:09:09,931] Trial 186 finished with value: 0.047764089311936056 and parameters: {'n_estimators': 1457, 'learning_rate': 0.04382896483553201, 'max_depth': 12, 'subsample': 0.7983942868149562, 'colsample_bytree': 0.9981246780152837, 'min_child_weight': 6, 'gamma': 0.19980105786371086, 'reg_alpha': 1.5241068309553416, 'reg_lambda': 8.697004819003118}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  94%|██████████████████████████████████████████   | 187/200 [33:05<03:31, 16.26s/it][I 2025-01-27 12:10:02,116] Trial 187 finished with value: 0.0425488280890031 and parameters: {'n_estimators': 1429, 'learning_rate': 0.10259369036935209, 'max_depth': 13, 'subsample': 0.8123902083997159, 'colsample_bytree': 0.980662238131758, 'min_child_weight': 6, 'gamma': 0.0007210560319459527, 'reg_alpha': 1.967090179358751, 'reg_lambda': 8.807904131718196}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  94%|██████████████████████████████████████████▎  | 188/200 [33:57<05:24, 27.04s/it][I 2025-01-27 12:10:13,408] Trial 188 finished with value: 0.05079125901384218 and parameters: {'n_estimators': 1499, 'learning_rate': 0.11595424099547902, 'max_depth': 13, 'subsample': 0.8087697574887197, 'colsample_bytree': 0.9642949800945861, 'min_child_weight': 6, 'gamma': 0.5960583218752996, 'reg_alpha': 1.8099490381426953, 'reg_lambda': 8.842683150832869}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  94%|██████████████████████████████████████████▌  | 189/200 [34:09<04:05, 22.31s/it][I 2025-01-27 12:10:26,551] Trial 189 finished with value: 0.04942647011399211 and parameters: {'n_estimators': 1649, 'learning_rate': 0.09401279002061483, 'max_depth': 13, 'subsample': 0.8107055799297718, 'colsample_bytree': 0.9862949259670696, 'min_child_weight': 7, 'gamma': 0.3643960214679863, 'reg_alpha': 2.025078565178445, 'reg_lambda': 8.524720579250003}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  95%|██████████████████████████████████████████▊  | 190/200 [34:22<03:15, 19.56s/it][I 2025-01-27 12:10:37,809] Trial 190 finished with value: 0.0479772862063684 and parameters: {'n_estimators': 1451, 'learning_rate': 0.14438117756037677, 'max_depth': 14, 'subsample': 0.7885263275451463, 'colsample_bytree': 0.9841840430416315, 'min_child_weight': 6, 'gamma': 0.20353474869124744, 'reg_alpha': 1.3787970205306241, 'reg_lambda': 8.735443625834817}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  96%|██████████████████████████████████████████▉  | 191/200 [34:33<02:33, 17.07s/it][I 2025-01-27 12:10:55,896] Trial 191 finished with value: 0.0450151504107087 and parameters: {'n_estimators': 1421, 'learning_rate': 0.05329488495531066, 'max_depth': 12, 'subsample': 0.7765596935496171, 'colsample_bytree': 0.9414374818356619, 'min_child_weight': 6, 'gamma': 0.03258492039797685, 'reg_alpha': 1.692131286013273, 'reg_lambda': 8.329407458834954}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  96%|███████████████████████████████████████████▏ | 192/200 [34:51<02:19, 17.38s/it][I 2025-01-27 12:11:29,917] Trial 192 finished with value: 0.043214665018978034 and parameters: {'n_estimators': 1439, 'learning_rate': 0.0363831471142408, 'max_depth': 12, 'subsample': 0.7919455822303034, 'colsample_bytree': 0.9652036753158455, 'min_child_weight': 6, 'gamma': 0.00446748722450358, 'reg_alpha': 2.2602207775923024, 'reg_lambda': 7.946192285066791}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  96%|███████████████████████████████████████████▍ | 193/200 [35:25<02:36, 22.37s/it][I 2025-01-27 12:11:45,500] Trial 193 finished with value: 0.04885767332282244 and parameters: {'n_estimators': 1438, 'learning_rate': 0.03996989077648429, 'max_depth': 12, 'subsample': 0.8053879708872879, 'colsample_bytree': 0.9627951737737956, 'min_child_weight': 6, 'gamma': 0.3161811527168717, 'reg_alpha': 2.1953761198494166, 'reg_lambda': 7.8913257134548385}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  97%|███████████████████████████████████████████▋ | 194/200 [35:41<02:01, 20.33s/it][I 2025-01-27 12:11:58,727] Trial 194 finished with value: 0.04814285559415733 and parameters: {'n_estimators': 1495, 'learning_rate': 0.0810184530294677, 'max_depth': 13, 'subsample': 0.7888793750257508, 'colsample_bytree': 0.9926937173545833, 'min_child_weight': 6, 'gamma': 0.19108937066503218, 'reg_alpha': 2.4491619342633864, 'reg_lambda': 7.963898473386839}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  98%|███████████████████████████████████████████▉ | 195/200 [35:54<01:31, 18.20s/it][I 2025-01-27 12:13:08,914] Trial 195 finished with value: 0.04240483269184374 and parameters: {'n_estimators': 1403, 'learning_rate': 0.032755038238517366, 'max_depth': 12, 'subsample': 0.8245908706794673, 'colsample_bytree': 0.9781674583798169, 'min_child_weight': 6, 'gamma': 0.0007453699318637431, 'reg_alpha': 2.054616014994707, 'reg_lambda': 9.135295511354165}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  98%|████████████████████████████████████████████ | 196/200 [37:04<02:15, 33.80s/it][I 2025-01-27 12:13:20,177] Trial 196 finished with value: 0.050239777382929805 and parameters: {'n_estimators': 1461, 'learning_rate': 0.11401998211025055, 'max_depth': 12, 'subsample': 0.8219066391962196, 'colsample_bytree': 0.9813935700342306, 'min_child_weight': 6, 'gamma': 0.5131004617784153, 'reg_alpha': 2.134206346169289, 'reg_lambda': 9.068783272720356}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  98%|████████████████████████████████████████████▎| 197/200 [37:15<01:21, 27.04s/it][I 2025-01-27 12:13:40,099] Trial 197 finished with value: 0.04360784341537387 and parameters: {'n_estimators': 1700, 'learning_rate': 0.09855209060111976, 'max_depth': 12, 'subsample': 0.7643476038426363, 'colsample_bytree': 0.9696207593902717, 'min_child_weight': 6, 'gamma': 0.006020907741296631, 'reg_alpha': 2.377260303125751, 'reg_lambda': 9.243998461081421}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  99%|████████████████████████████████████████████▌| 198/200 [37:35<00:49, 24.90s/it][I 2025-01-27 12:13:54,315] Trial 198 finished with value: 0.04931498064260518 and parameters: {'n_estimators': 1525, 'learning_rate': 0.05514396385184846, 'max_depth': 13, 'subsample': 0.7630291332913008, 'colsample_bytree': 0.9688880244809862, 'min_child_weight': 6, 'gamma': 0.3379804044480639, 'reg_alpha': 2.3251989269885893, 'reg_lambda': 9.202385936385522}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...: 100%|████████████████████████████████████████████▊| 199/200 [37:50<00:21, 21.70s/it][I 2025-01-27 12:14:05,722] Trial 199 finished with value: 0.058826408180336985 and parameters: {'n_estimators': 1718, 'learning_rate': 0.8921862964914595, 'max_depth': 12, 'subsample': 0.7437684842472011, 'colsample_bytree': 0.957733880568644, 'min_child_weight': 7, 'gamma': 0.21417201153753165, 'reg_alpha': 1.9138902885072209, 'reg_lambda': 9.429580310336448}. Best is trial 173 with value: 0.042281751825234457.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...: 100%|█████████████████████████████████████████████| 200/200 [38:01<00:00, 11.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최고의 MAPE값 0.042281751825234457 \n",
      "\n",
      "최고의 하이퍼 파라미터 {'n_estimators': 1433, 'learning_rate': 0.06577429086290515, 'max_depth': 11, 'subsample': 0.7623970628578274, 'colsample_bytree': 0.9807525044569172, 'min_child_weight': 6, 'gamma': 0.0007222076305085732, 'reg_alpha': 1.1191881067061473, 'reg_lambda': 8.375651254942353} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# --------------------------------------------- 가중치 변수 삭제하고 학습  ---------------------------------------------------\n",
    "\n",
    "# ----------------------------------------------------- 데이터 학습 --------------------------------------------------------------\n",
    "\n",
    "# 목적함수 생성\n",
    "def objective(trial):\n",
    "    params = {\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 100, 2000),  # 트리 개수\n",
    "    'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),  # 학습률\n",
    "    'max_depth': trial.suggest_int('max_depth', 3, 15),  # 트리 최대 깊이\n",
    "    'subsample': trial.suggest_float('subsample', 0.5, 1.0),  # 샘플링 비율\n",
    "    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),  # 특성 샘플링 비율\n",
    "    'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),  # 리프 노드 최소 가중치\n",
    "    'gamma': trial.suggest_float('gamma', 0, 10),  # 최소 손실 감소\n",
    "    'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),  # L1 정규화\n",
    "    'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),  # L2 정규화\n",
    "    \"tree_method\": \"hist\",  # 트리 방법\n",
    "    \"device\": \"cuda\",       # GPU 사용\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    'random_state': 1\n",
    "}\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    xgb_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(train):\n",
    "        x_train, x_val = train.iloc[train_index], train.iloc[val_index]\n",
    "        y_train, y_val = log_y_df[train_index], log_y_df[val_index]\n",
    "\n",
    "        # XGBoost 모델 생성\n",
    "        xgb_model = xgb.XGBRegressor(**params)\n",
    "        xgb_model.fit(x_train, y_train)\n",
    "\n",
    "        # 예측 및 RMSLE 계산\n",
    "        y_pred = np.exp(xgb_model.predict(x_val))\n",
    "        mape = mean_absolute_percentage_error(np.exp(y_val), y_pred)\n",
    "        xgb_scores.append(mape)\n",
    "\n",
    "    return np.mean(xgb_scores)\n",
    "\n",
    "# Optuna 하이퍼파라미터 최적화\n",
    "n_trials = 200\n",
    "xgb_study = optuna.create_study(direction='minimize')\n",
    "\n",
    "for _ in tqdm(range(n_trials), desc='XGBoost 하이퍼파라미터 튜닝 중...'):\n",
    "    xgb_study.optimize(objective, n_trials=1, catch=(Exception,))\n",
    "\n",
    "print('최고의 MAPE값', xgb_study.best_value, '\\n')\n",
    "print('최고의 하이퍼 파라미터', xgb_study.best_params, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0200940-2c83-46df-8b59-fc6653a27fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "         Feature  Importance\n",
      "0        country    0.669586\n",
      "2        product    0.180445\n",
      "1          store    0.134637\n",
      "13      year_cos    0.005076\n",
      "3           year    0.001982\n",
      "10     month_sin    0.001923\n",
      "5        weekday    0.001649\n",
      "7   week_of_year    0.001284\n",
      "11     month_cos    0.001045\n",
      "4          month    0.000954\n",
      "14         group    0.000876\n",
      "12      year_sin    0.000434\n",
      "6            day    0.000078\n",
      "8        day_sin    0.000032\n",
      "9        day_cos    0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 최적의 하이퍼파라미터 가져오기\n",
    "best_params = {  \n",
    "    'n_estimators': 1433,\n",
    "    'learning_rate': 0.06577429086290515,\n",
    "    'max_depth': 11,\n",
    "    'subsample': 0.7623970628578274,\n",
    "    'colsample_bytree': 0.9807525044569172,\n",
    "    'min_child_weight': 6,\n",
    "    'gamma': 0.0007222076305085732,\n",
    "    'reg_alpha': 1.1191881067061473,\n",
    "    'reg_lambda': 8.375651254942353,\n",
    "    \"tree_method\": \"hist\",  # 트리 방법\n",
    "    \"device\": \"cuda\",       # GPU 사용\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    'random_state': 1\n",
    "} \n",
    "\n",
    "# 로그 변환된 타겟 값 사용\n",
    "log_y_df = np.log(y_df)\n",
    "\n",
    "# 최적의 파라미터로 최종 모델 학습\n",
    "final_xgb_model = xgb.XGBRegressor(**best_params)\n",
    "final_xgb_model.fit(train, log_y_df)\n",
    "\n",
    "# 예측 및 지수 함수로 변환\n",
    "y_pred_log = final_xgb_model.predict(test)\n",
    "y_pred = np.exp(y_pred_log)  # 로그 변환된 값을 지수 함수로 복원\n",
    "\n",
    "# 변수 중요도 추출\n",
    "feature_importances = final_xgb_model.feature_importances_\n",
    "features = train.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 변수 중요도 출력\n",
    "print(\"Feature Importances:\")\n",
    "print(importance_df)\n",
    "\n",
    "# 변수 중요도 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance (XGBoost)')\n",
    "plt.gca().invert_yaxis()  # 중요도가 높은 순서로 표시\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b884348-ebde-4b2f-9501-35e0fc21973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_8 = sub.copy()\n",
    "sub_8['num_sold'] = y_pred\n",
    "\n",
    "sub_8.to_csv('sub_8.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df781e8-523a-471a-9b24-56106b77d66c",
   "metadata": {},
   "source": [
    "<div style=\"background-color:red; padding:10px; border-radius:10px; font-size:18px;\">\n",
    "(시도 9)<br><br>\n",
    "가중치 변수 삭제 후 반년 주기 다시 추가\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1ec9560-0297-4376-bf71-a10d423c222e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-27 12:34:16,143] A new study created in memory with name: no-name-35273719-2888-47c3-8bf8-c65fd147154b\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   0%|                                                       | 0/200 [00:00<?, ?it/s][I 2025-01-27 12:34:27,271] Trial 0 finished with value: 0.0546418488652189 and parameters: {'n_estimators': 1252, 'learning_rate': 0.05786759481182859, 'max_depth': 13, 'subsample': 0.9587480899199018, 'colsample_bytree': 0.7792365830704191, 'min_child_weight': 5, 'gamma': 2.41145177234968, 'reg_alpha': 1.5045200702123573, 'reg_lambda': 6.381243550101465}. Best is trial 0 with value: 0.0546418488652189.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   0%|▏                                              | 1/200 [00:11<36:53, 11.13s/it][I 2025-01-27 12:34:32,077] Trial 1 finished with value: 0.06479333600758863 and parameters: {'n_estimators': 525, 'learning_rate': 0.4340226301361819, 'max_depth': 7, 'subsample': 0.8841870599357164, 'colsample_bytree': 0.511398465017056, 'min_child_weight': 3, 'gamma': 6.811223110050859, 'reg_alpha': 7.069654316268626, 'reg_lambda': 3.049492906016158}. Best is trial 0 with value: 0.0546418488652189.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   1%|▍                                              | 2/200 [00:15<24:27,  7.41s/it][I 2025-01-27 12:34:42,964] Trial 2 finished with value: 0.052473330005744515 and parameters: {'n_estimators': 1448, 'learning_rate': 0.2764326757315937, 'max_depth': 9, 'subsample': 0.9004358486623054, 'colsample_bytree': 0.9165090768912685, 'min_child_weight': 10, 'gamma': 0.6814591170788631, 'reg_alpha': 6.4643441148199585, 'reg_lambda': 2.7136602506640073}. Best is trial 2 with value: 0.052473330005744515.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   2%|▋                                              | 3/200 [00:26<29:32,  9.00s/it][I 2025-01-27 12:34:51,598] Trial 3 finished with value: 0.05094383749363209 and parameters: {'n_estimators': 1047, 'learning_rate': 0.1383734095616365, 'max_depth': 10, 'subsample': 0.9218796420741526, 'colsample_bytree': 0.5504023129222837, 'min_child_weight': 1, 'gamma': 0.6970396176716553, 'reg_alpha': 9.194139365471992, 'reg_lambda': 0.22984603022002892}. Best is trial 3 with value: 0.05094383749363209.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   2%|▉                                              | 4/200 [00:35<28:55,  8.85s/it][I 2025-01-27 12:34:54,096] Trial 4 finished with value: 0.07920918083236997 and parameters: {'n_estimators': 269, 'learning_rate': 0.692708954772312, 'max_depth': 4, 'subsample': 0.8242228605543025, 'colsample_bytree': 0.5225103511121305, 'min_child_weight': 6, 'gamma': 6.6606919298688805, 'reg_alpha': 2.3471407126509805, 'reg_lambda': 8.487472740630409}. Best is trial 3 with value: 0.05094383749363209.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   2%|█▏                                             | 5/200 [00:37<21:19,  6.56s/it][I 2025-01-27 12:35:06,657] Trial 5 finished with value: 0.06762280892387934 and parameters: {'n_estimators': 1764, 'learning_rate': 0.6903928203400229, 'max_depth': 7, 'subsample': 0.8440940221403648, 'colsample_bytree': 0.979657125442844, 'min_child_weight': 3, 'gamma': 1.9767067354369117, 'reg_alpha': 5.760216180609204, 'reg_lambda': 7.023389711427606}. Best is trial 3 with value: 0.05094383749363209.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   3%|█▍                                             | 6/200 [00:50<27:48,  8.60s/it][I 2025-01-27 12:35:13,895] Trial 6 finished with value: 0.06243264280706762 and parameters: {'n_estimators': 876, 'learning_rate': 0.07997504920132911, 'max_depth': 5, 'subsample': 0.8061513046715101, 'colsample_bytree': 0.7297080918483847, 'min_child_weight': 3, 'gamma': 4.735436688451396, 'reg_alpha': 0.8563808286389063, 'reg_lambda': 4.477897410478123}. Best is trial 3 with value: 0.05094383749363209.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   4%|█▋                                             | 7/200 [00:57<26:14,  8.16s/it][I 2025-01-27 12:35:27,232] Trial 7 finished with value: 0.06715309680606517 and parameters: {'n_estimators': 1921, 'learning_rate': 0.5510134748428558, 'max_depth': 8, 'subsample': 0.619880051381485, 'colsample_bytree': 0.9325678884473159, 'min_child_weight': 3, 'gamma': 3.1906852124642713, 'reg_alpha': 5.265282038146781, 'reg_lambda': 5.17801624745573}. Best is trial 3 with value: 0.05094383749363209.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   4%|█▉                                             | 8/200 [01:11<31:22,  9.81s/it][I 2025-01-27 12:35:36,873] Trial 8 finished with value: 0.06291443941783394 and parameters: {'n_estimators': 1388, 'learning_rate': 0.29191602268450895, 'max_depth': 6, 'subsample': 0.7827760036923227, 'colsample_bytree': 0.748802936785957, 'min_child_weight': 5, 'gamma': 4.0749105573305, 'reg_alpha': 4.109567975738797, 'reg_lambda': 6.22987966829948}. Best is trial 3 with value: 0.05094383749363209.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   4%|██                                             | 9/200 [01:20<31:02,  9.75s/it][I 2025-01-27 12:35:48,505] Trial 9 finished with value: 0.08816165137663223 and parameters: {'n_estimators': 1746, 'learning_rate': 0.9807513402226159, 'max_depth': 6, 'subsample': 0.6025035035739252, 'colsample_bytree': 0.7248841308871365, 'min_child_weight': 6, 'gamma': 7.7914110708412725, 'reg_alpha': 5.591312323624676, 'reg_lambda': 8.405541818147116}. Best is trial 3 with value: 0.05094383749363209.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   5%|██▎                                           | 10/200 [01:32<32:43, 10.33s/it][I 2025-01-27 12:35:56,713] Trial 10 finished with value: 0.0474584122712393 and parameters: {'n_estimators': 849, 'learning_rate': 0.20084243901414153, 'max_depth': 12, 'subsample': 0.9939502448199456, 'colsample_bytree': 0.593115511856936, 'min_child_weight': 1, 'gamma': 0.03277136545289405, 'reg_alpha': 9.861180380251199, 'reg_lambda': 0.33141376517562193}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   6%|██▌                                           | 11/200 [01:40<30:30,  9.68s/it][I 2025-01-27 12:36:04,414] Trial 11 finished with value: 0.04936017849310924 and parameters: {'n_estimators': 843, 'learning_rate': 0.22265071868852032, 'max_depth': 12, 'subsample': 0.9996689603744497, 'colsample_bytree': 0.6236820682471135, 'min_child_weight': 1, 'gamma': 0.1866489825630775, 'reg_alpha': 9.9736687071568, 'reg_lambda': 0.1086591042649056}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   6%|██▊                                           | 12/200 [01:48<28:27,  9.08s/it][I 2025-01-27 12:36:10,926] Trial 12 finished with value: 0.05175669238487559 and parameters: {'n_estimators': 715, 'learning_rate': 0.29529765595289204, 'max_depth': 15, 'subsample': 0.9947317062336237, 'colsample_bytree': 0.6199579382428149, 'min_child_weight': 1, 'gamma': 0.44886625754330106, 'reg_alpha': 9.718806593464825, 'reg_lambda': 0.5111994239725037}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   6%|██▉                                           | 13/200 [01:54<25:52,  8.30s/it][I 2025-01-27 12:36:15,549] Trial 13 finished with value: 0.06678323894039732 and parameters: {'n_estimators': 532, 'learning_rate': 0.2135471433324096, 'max_depth': 12, 'subsample': 0.7331151924634988, 'colsample_bytree': 0.6352903230913173, 'min_child_weight': 1, 'gamma': 9.394361317791127, 'reg_alpha': 8.10916510081978, 'reg_lambda': 1.6101148914443915}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   7%|███▏                                          | 14/200 [01:59<22:17,  7.19s/it][I 2025-01-27 12:36:17,555] Trial 14 finished with value: 0.060846365809055905 and parameters: {'n_estimators': 138, 'learning_rate': 0.4188451556171728, 'max_depth': 11, 'subsample': 0.7019555295984183, 'colsample_bytree': 0.634045366218367, 'min_child_weight': 9, 'gamma': 1.7931503247249994, 'reg_alpha': 8.206502975824609, 'reg_lambda': 1.6852981124130895}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   8%|███▍                                          | 15/200 [02:01<17:21,  5.63s/it][I 2025-01-27 12:36:36,358] Trial 15 finished with value: 0.04974739805100477 and parameters: {'n_estimators': 990, 'learning_rate': 0.022774621752815166, 'max_depth': 14, 'subsample': 0.5197287614145397, 'colsample_bytree': 0.5917909766872251, 'min_child_weight': 2, 'gamma': 0.1616755306721842, 'reg_alpha': 9.994855940948986, 'reg_lambda': 3.5341175331291526}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   8%|███▋                                          | 16/200 [02:20<29:25,  9.59s/it][I 2025-01-27 12:36:42,266] Trial 16 finished with value: 0.05786391341839259 and parameters: {'n_estimators': 703, 'learning_rate': 0.18781713855481857, 'max_depth': 12, 'subsample': 0.9946060281790898, 'colsample_bytree': 0.6955293383225902, 'min_child_weight': 8, 'gamma': 3.564115455599242, 'reg_alpha': 8.215035902425747, 'reg_lambda': 1.7145404145513183}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   8%|███▉                                          | 17/200 [02:26<25:52,  8.49s/it][I 2025-01-27 12:36:51,625] Trial 17 finished with value: 0.058294925318875576 and parameters: {'n_estimators': 1222, 'learning_rate': 0.42050806872537505, 'max_depth': 10, 'subsample': 0.9421517670217705, 'colsample_bytree': 0.8212377506050496, 'min_child_weight': 4, 'gamma': 1.622844629889554, 'reg_alpha': 3.5896045689621934, 'reg_lambda': 0.39259913190470647}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   9%|████▏                                         | 18/200 [02:35<26:32,  8.75s/it][I 2025-01-27 12:36:58,057] Trial 18 finished with value: 0.06769136675929405 and parameters: {'n_estimators': 800, 'learning_rate': 0.5739197552176472, 'max_depth': 15, 'subsample': 0.8889827595220514, 'colsample_bytree': 0.6618170361487405, 'min_child_weight': 7, 'gamma': 6.077799406030998, 'reg_alpha': 8.903623356910689, 'reg_lambda': 0.014320798539996987}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  10%|████▎                                         | 19/200 [02:41<24:17,  8.05s/it][I 2025-01-27 12:37:02,349] Trial 19 finished with value: 0.06578449674920038 and parameters: {'n_estimators': 517, 'learning_rate': 0.8841154342556148, 'max_depth': 12, 'subsample': 0.9985725257376186, 'colsample_bytree': 0.5686834941010349, 'min_child_weight': 2, 'gamma': 2.90007824709292, 'reg_alpha': 7.972657890542241, 'reg_lambda': 1.391227290827286}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  10%|████▌                                         | 20/200 [02:46<20:46,  6.92s/it][I 2025-01-27 12:37:06,268] Trial 20 finished with value: 0.05943443635443226 and parameters: {'n_estimators': 412, 'learning_rate': 0.33300635976997356, 'max_depth': 13, 'subsample': 0.6795259831132495, 'colsample_bytree': 0.8183590860154363, 'min_child_weight': 2, 'gamma': 1.227008660162523, 'reg_alpha': 6.927267640769196, 'reg_lambda': 9.85971648635792}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  10%|████▊                                         | 21/200 [02:50<17:57,  6.02s/it][I 2025-01-27 12:37:19,356] Trial 21 finished with value: 0.050256943996646944 and parameters: {'n_estimators': 979, 'learning_rate': 0.03807146491592381, 'max_depth': 14, 'subsample': 0.5169069436727433, 'colsample_bytree': 0.5883999051527284, 'min_child_weight': 2, 'gamma': 0.18113148659296208, 'reg_alpha': 9.997882615849477, 'reg_lambda': 3.3786831710193583}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  11%|█████                                         | 22/200 [03:03<24:09,  8.14s/it][I 2025-01-27 12:37:29,175] Trial 22 finished with value: 0.05118377559513141 and parameters: {'n_estimators': 1158, 'learning_rate': 0.13721994297094842, 'max_depth': 14, 'subsample': 0.5108808045917537, 'colsample_bytree': 0.5873978290760516, 'min_child_weight': 1, 'gamma': 0.11449679562468967, 'reg_alpha': 9.96372145160952, 'reg_lambda': 4.113682240811919}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  12%|█████▎                                        | 23/200 [03:13<25:30,  8.65s/it][I 2025-01-27 12:37:41,769] Trial 23 finished with value: 0.055685766211594476 and parameters: {'n_estimators': 904, 'learning_rate': 0.023677360604990743, 'max_depth': 11, 'subsample': 0.55637267039618, 'colsample_bytree': 0.6797927558025767, 'min_child_weight': 2, 'gamma': 1.241950140893361, 'reg_alpha': 8.937638489973432, 'reg_lambda': 2.405382651196049}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  12%|█████▌                                        | 24/200 [03:25<28:50,  9.83s/it][I 2025-01-27 12:37:47,434] Trial 24 finished with value: 0.055805856045321456 and parameters: {'n_estimators': 681, 'learning_rate': 0.18736026158102828, 'max_depth': 14, 'subsample': 0.8516882171961419, 'colsample_bytree': 0.5986375838816975, 'min_child_weight': 4, 'gamma': 2.4971647277654587, 'reg_alpha': 7.421729721620171, 'reg_lambda': 1.0810400947646615}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  12%|█████▊                                        | 25/200 [03:31<25:01,  8.58s/it][I 2025-01-27 12:37:57,532] Trial 25 finished with value: 0.04865498659075521 and parameters: {'n_estimators': 1078, 'learning_rate': 0.11440720753345483, 'max_depth': 13, 'subsample': 0.6550938767866651, 'colsample_bytree': 0.5495800779410706, 'min_child_weight': 1, 'gamma': 0.07877583514598349, 'reg_alpha': 8.991268733839412, 'reg_lambda': 3.7089507085706517}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  13%|█████▉                                        | 26/200 [03:41<26:12,  9.04s/it][I 2025-01-27 12:38:07,863] Trial 26 finished with value: 0.05824380761752686 and parameters: {'n_estimators': 1490, 'learning_rate': 0.35737210061320346, 'max_depth': 10, 'subsample': 0.6533084965814154, 'colsample_bytree': 0.5418036790484001, 'min_child_weight': 1, 'gamma': 1.1567320752062837, 'reg_alpha': 8.965000602469917, 'reg_lambda': 2.151193225993243}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  14%|██████▏                                       | 27/200 [03:51<27:10,  9.42s/it][I 2025-01-27 12:38:16,217] Trial 27 finished with value: 0.0598801033398738 and parameters: {'n_estimators': 1113, 'learning_rate': 0.2240771722944504, 'max_depth': 11, 'subsample': 0.7591493555353986, 'colsample_bytree': 0.501385204706938, 'min_child_weight': 4, 'gamma': 4.092730902090507, 'reg_alpha': 9.114195527222384, 'reg_lambda': 0.8420843657643002}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  14%|██████▍                                       | 28/200 [04:00<26:05,  9.10s/it][I 2025-01-27 12:38:25,755] Trial 28 finished with value: 0.05978743185582931 and parameters: {'n_estimators': 1270, 'learning_rate': 0.12696445409174928, 'max_depth': 13, 'subsample': 0.9542651254712767, 'colsample_bytree': 0.5522495030312196, 'min_child_weight': 1, 'gamma': 5.432081271279475, 'reg_alpha': 7.568183921915973, 'reg_lambda': 4.523855274337994}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  14%|██████▋                                       | 29/200 [04:09<26:18,  9.23s/it][I 2025-01-27 12:38:32,883] Trial 29 finished with value: 0.05728426289541653 and parameters: {'n_estimators': 791, 'learning_rate': 0.10231601440675339, 'max_depth': 12, 'subsample': 0.597538107062658, 'colsample_bytree': 0.659084200856659, 'min_child_weight': 2, 'gamma': 2.2716954890888665, 'reg_alpha': 2.2651350829859638, 'reg_lambda': 5.594293806693429}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  15%|██████▉                                       | 30/200 [04:16<24:22,  8.60s/it][I 2025-01-27 12:38:42,653] Trial 30 finished with value: 0.05858263460213743 and parameters: {'n_estimators': 1289, 'learning_rate': 0.2162174001991205, 'max_depth': 13, 'subsample': 0.7303386458236788, 'colsample_bytree': 0.802550586132862, 'min_child_weight': 4, 'gamma': 0.908550411025232, 'reg_alpha': 0.1565515711237344, 'reg_lambda': 3.8077232956332003}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  16%|███████▏                                      | 31/200 [04:26<25:12,  8.95s/it][I 2025-01-27 12:39:13,961] Trial 31 finished with value: 0.048591820655109766 and parameters: {'n_estimators': 1044, 'learning_rate': 0.011623467930520853, 'max_depth': 14, 'subsample': 0.565542568565417, 'colsample_bytree': 0.6021743404909251, 'min_child_weight': 2, 'gamma': 0.07585216416896617, 'reg_alpha': 9.488893979435549, 'reg_lambda': 3.5315454836047584}. Best is trial 10 with value: 0.0474584122712393.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  16%|███████▎                                      | 32/200 [04:57<43:50, 15.66s/it][I 2025-01-27 12:39:29,690] Trial 32 finished with value: 0.04643977117165235 and parameters: {'n_estimators': 918, 'learning_rate': 0.08388028112486379, 'max_depth': 15, 'subsample': 0.5658076094043429, 'colsample_bytree': 0.5335735801775785, 'min_child_weight': 1, 'gamma': 0.004839284986923355, 'reg_alpha': 9.42313321003953, 'reg_lambda': 2.998817990150485}. Best is trial 32 with value: 0.04643977117165235.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  16%|███████▌                                      | 33/200 [05:13<43:38, 15.68s/it][I 2025-01-27 12:39:39,839] Trial 33 finished with value: 0.055703210950349524 and parameters: {'n_estimators': 1089, 'learning_rate': 0.08245541877536508, 'max_depth': 15, 'subsample': 0.5569966674470614, 'colsample_bytree': 0.519560041761407, 'min_child_weight': 3, 'gamma': 1.4302591205741682, 'reg_alpha': 8.468892992157716, 'reg_lambda': 2.844144200194027}. Best is trial 32 with value: 0.04643977117165235.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  17%|███████▊                                      | 34/200 [05:23<38:47, 14.02s/it][I 2025-01-27 12:39:52,217] Trial 34 finished with value: 0.0535829294386426 and parameters: {'n_estimators': 1549, 'learning_rate': 0.14789410729446711, 'max_depth': 15, 'subsample': 0.6374545714299928, 'colsample_bytree': 0.5658439677549504, 'min_child_weight': 2, 'gamma': 0.7523889885126508, 'reg_alpha': 6.547371966976904, 'reg_lambda': 2.9197013471343207}. Best is trial 32 with value: 0.04643977117165235.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  18%|████████                                      | 35/200 [05:36<37:12, 13.53s/it][I 2025-01-27 12:40:27,997] Trial 35 finished with value: 0.04586367756389986 and parameters: {'n_estimators': 1008, 'learning_rate': 0.01986326021548858, 'max_depth': 14, 'subsample': 0.5704652668620208, 'colsample_bytree': 0.5313020461259917, 'min_child_weight': 1, 'gamma': 0.0029956605312483064, 'reg_alpha': 9.417100664915562, 'reg_lambda': 4.957884921804181}. Best is trial 35 with value: 0.04586367756389986.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  18%|████████▎                                     | 36/200 [06:11<55:13, 20.20s/it][I 2025-01-27 12:40:42,182] Trial 36 finished with value: 0.056663933929031726 and parameters: {'n_estimators': 568, 'learning_rate': 0.016036818854497134, 'max_depth': 14, 'subsample': 0.5681570093609914, 'colsample_bytree': 0.5291471776516063, 'min_child_weight': 3, 'gamma': 0.7820004246044671, 'reg_alpha': 7.594822774033498, 'reg_lambda': 5.808708819327743}. Best is trial 35 with value: 0.04586367756389986.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  18%|████████▌                                     | 37/200 [06:26<49:58, 18.40s/it][I 2025-01-27 12:40:49,790] Trial 37 finished with value: 0.08481099094017346 and parameters: {'n_estimators': 948, 'learning_rate': 0.07419598730292046, 'max_depth': 3, 'subsample': 0.5789037755599917, 'colsample_bytree': 0.8711909408541919, 'min_child_weight': 2, 'gamma': 2.204560974138662, 'reg_alpha': 9.485706137350546, 'reg_lambda': 7.159717983490887}. Best is trial 35 with value: 0.04586367756389986.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  19%|████████▋                                     | 38/200 [06:33<40:56, 15.16s/it][I 2025-01-27 12:40:56,323] Trial 38 finished with value: 0.059518411353036725 and parameters: {'n_estimators': 619, 'learning_rate': 0.06106368833675433, 'max_depth': 15, 'subsample': 0.5514840185116527, 'colsample_bytree': 0.5289310450550146, 'min_child_weight': 5, 'gamma': 2.7955569412881824, 'reg_alpha': 8.517409652103513, 'reg_lambda': 4.894751608300143}. Best is trial 35 with value: 0.04586367756389986.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  20%|████████▉                                     | 39/200 [06:40<33:44, 12.57s/it][I 2025-01-27 12:41:04,988] Trial 39 finished with value: 0.06726152480828719 and parameters: {'n_estimators': 1187, 'learning_rate': 0.152003396527482, 'max_depth': 9, 'subsample': 0.5358310556876104, 'colsample_bytree': 0.5077604622596708, 'min_child_weight': 3, 'gamma': 7.719355494320864, 'reg_alpha': 6.199840688921431, 'reg_lambda': 2.240673980758871}. Best is trial 35 with value: 0.04586367756389986.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  20%|█████████▏                                    | 40/200 [06:48<30:24, 11.40s/it][I 2025-01-27 12:41:08,848] Trial 40 finished with value: 0.05858336967463925 and parameters: {'n_estimators': 397, 'learning_rate': 0.25397958780823415, 'max_depth': 14, 'subsample': 0.5959186237821497, 'colsample_bytree': 0.6091084972091969, 'min_child_weight': 10, 'gamma': 1.7873753864146527, 'reg_alpha': 9.329021356597892, 'reg_lambda': 6.558351873452214}. Best is trial 35 with value: 0.04586367756389986.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  20%|█████████▍                                    | 41/200 [06:52<24:12,  9.14s/it][I 2025-01-27 12:41:17,972] Trial 41 finished with value: 0.05197368220065947 and parameters: {'n_estimators': 1031, 'learning_rate': 0.09410008375387906, 'max_depth': 13, 'subsample': 0.6369657038698545, 'colsample_bytree': 0.5673383667708596, 'min_child_weight': 1, 'gamma': 0.6055798230196512, 'reg_alpha': 9.410301485205196, 'reg_lambda': 4.243764785357287}. Best is trial 35 with value: 0.04586367756389986.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  21%|█████████▋                                    | 42/200 [07:01<24:03,  9.13s/it][I 2025-01-27 12:41:26,165] Trial 42 finished with value: 0.04968137215571591 and parameters: {'n_estimators': 894, 'learning_rate': 0.1659465871628094, 'max_depth': 13, 'subsample': 0.6667605125550327, 'colsample_bytree': 0.552791514805115, 'min_child_weight': 1, 'gamma': 0.08373847960611953, 'reg_alpha': 8.651139035782775, 'reg_lambda': 5.133239501950981}. Best is trial 35 with value: 0.04586367756389986.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  22%|█████████▉                                    | 43/200 [07:10<23:09,  8.85s/it][I 2025-01-27 12:41:35,350] Trial 43 finished with value: 0.05291741461342993 and parameters: {'n_estimators': 1079, 'learning_rate': 0.09707332986784613, 'max_depth': 13, 'subsample': 0.613358281307979, 'colsample_bytree': 0.5712559575617919, 'min_child_weight': 1, 'gamma': 0.7697669421740698, 'reg_alpha': 9.469147077981527, 'reg_lambda': 3.1908699672528913}. Best is trial 35 with value: 0.04586367756389986.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  22%|██████████                                    | 44/200 [07:19<23:16,  8.95s/it][I 2025-01-27 12:42:31,741] Trial 44 finished with value: 0.0455191129078128 and parameters: {'n_estimators': 1359, 'learning_rate': 0.011540306312749486, 'max_depth': 15, 'subsample': 0.7102779025343999, 'colsample_bytree': 0.5006232451187373, 'min_child_weight': 1, 'gamma': 0.009156119509120729, 'reg_alpha': 4.660427343762089, 'reg_lambda': 3.7451275704919067}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  22%|██████████▎                                   | 45/200 [08:15<59:53, 23.18s/it][I 2025-01-27 12:42:46,246] Trial 45 finished with value: 0.05145877203682826 and parameters: {'n_estimators': 1686, 'learning_rate': 0.0479229901052919, 'max_depth': 15, 'subsample': 0.803247069211968, 'colsample_bytree': 0.5044113257374969, 'min_child_weight': 3, 'gamma': 1.117121109792052, 'reg_alpha': 4.392862214070886, 'reg_lambda': 4.683044518441846}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  23%|██████████▌                                   | 46/200 [08:30<52:49, 20.58s/it][I 2025-01-27 12:43:17,279] Trial 46 finished with value: 0.04917432183730559 and parameters: {'n_estimators': 1388, 'learning_rate': 0.010990594109400875, 'max_depth': 14, 'subsample': 0.6972482050528926, 'colsample_bytree': 0.5336601972531076, 'min_child_weight': 2, 'gamma': 0.43148019069098376, 'reg_alpha': 3.4717823479790253, 'reg_lambda': 5.462886915575719}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  24%|██████████▎                                 | 47/200 [09:01<1:00:28, 23.72s/it][I 2025-01-27 12:43:26,548] Trial 47 finished with value: 0.07047569540529845 and parameters: {'n_estimators': 1328, 'learning_rate': 0.526824267762117, 'max_depth': 15, 'subsample': 0.847551327945659, 'colsample_bytree': 0.6474529028054407, 'min_child_weight': 1, 'gamma': 9.56361921851665, 'reg_alpha': 4.933473226752797, 'reg_lambda': 3.954355690019866}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  24%|███████████                                   | 48/200 [09:10<49:06, 19.38s/it][I 2025-01-27 12:43:39,939] Trial 48 finished with value: 0.060991800647091365 and parameters: {'n_estimators': 1968, 'learning_rate': 0.6862994727291557, 'max_depth': 14, 'subsample': 0.9148001685354746, 'colsample_bytree': 0.6059426195404376, 'min_child_weight': 2, 'gamma': 1.714987755086172, 'reg_alpha': 2.758048841176447, 'reg_lambda': 6.254218073163457}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  24%|███████████▎                                  | 49/200 [09:23<44:15, 17.58s/it][I 2025-01-27 12:43:53,652] Trial 49 finished with value: 0.052129191674090615 and parameters: {'n_estimators': 1580, 'learning_rate': 0.05865125367556598, 'max_depth': 15, 'subsample': 0.5834453565596599, 'colsample_bytree': 0.5789030543543648, 'min_child_weight': 1, 'gamma': 0.6872482677568134, 'reg_alpha': 5.7984556622079975, 'reg_lambda': 2.7280720185204688}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  25%|███████████▌                                  | 50/200 [09:37<41:03, 16.42s/it][I 2025-01-27 12:43:59,729] Trial 50 finished with value: 0.05930968816655271 and parameters: {'n_estimators': 793, 'learning_rate': 0.2677259755603808, 'max_depth': 7, 'subsample': 0.538453179530137, 'colsample_bytree': 0.7576591077148669, 'min_child_weight': 6, 'gamma': 1.4626824539641998, 'reg_alpha': 6.9811728094232155, 'reg_lambda': 3.329870818872565}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  26%|███████████▋                                  | 51/200 [09:43<33:04, 13.32s/it][I 2025-01-27 12:44:11,671] Trial 51 finished with value: 0.04870042174766896 and parameters: {'n_estimators': 1038, 'learning_rate': 0.12204337957108868, 'max_depth': 14, 'subsample': 0.6306444091508313, 'colsample_bytree': 0.5234938344541739, 'min_child_weight': 1, 'gamma': 0.02234072571916868, 'reg_alpha': 4.68254367589377, 'reg_lambda': 3.659629631423371}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  26%|███████████▉                                  | 52/200 [09:55<31:50, 12.91s/it][I 2025-01-27 12:44:36,868] Trial 52 finished with value: 0.050143548300938 and parameters: {'n_estimators': 1159, 'learning_rate': 0.011619890677961865, 'max_depth': 13, 'subsample': 0.7281568263525462, 'colsample_bytree': 0.5467137130042917, 'min_child_weight': 1, 'gamma': 0.4982515246814027, 'reg_alpha': 9.605835743216835, 'reg_lambda': 4.071131092266238}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  26%|████████████▏                                 | 53/200 [10:20<40:39, 16.59s/it][I 2025-01-27 12:44:45,858] Trial 53 finished with value: 0.04767425705087146 and parameters: {'n_estimators': 949, 'learning_rate': 0.17218090680100717, 'max_depth': 12, 'subsample': 0.7042804324774601, 'colsample_bytree': 0.6991816577701129, 'min_child_weight': 2, 'gamma': 0.02310457200858892, 'reg_alpha': 8.692962265154414, 'reg_lambda': 4.477418521568157}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  27%|████████████▍                                 | 54/200 [10:29<34:49, 14.31s/it][I 2025-01-27 12:44:52,273] Trial 54 finished with value: 0.0593838269190463 and parameters: {'n_estimators': 840, 'learning_rate': 0.46071584784094155, 'max_depth': 11, 'subsample': 0.7553359215480506, 'colsample_bytree': 0.7083912017139345, 'min_child_weight': 2, 'gamma': 0.40175083741359296, 'reg_alpha': 8.055722972081123, 'reg_lambda': 4.4090439522597205}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  28%|████████████▋                                 | 55/200 [10:36<28:51, 11.94s/it][I 2025-01-27 12:44:59,962] Trial 55 finished with value: 0.05428835429923232 and parameters: {'n_estimators': 976, 'learning_rate': 0.19100968984646835, 'max_depth': 12, 'subsample': 0.7009133534776544, 'colsample_bytree': 0.6142968971192628, 'min_child_weight': 7, 'gamma': 0.9249841824887236, 'reg_alpha': 5.366072525486527, 'reg_lambda': 4.91552626437022}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  28%|████████████▉                                 | 56/200 [10:43<25:36, 10.67s/it][I 2025-01-27 12:45:05,868] Trial 56 finished with value: 0.05193399039611483 and parameters: {'n_estimators': 756, 'learning_rate': 0.3217307289440773, 'max_depth': 8, 'subsample': 0.8691568623602228, 'colsample_bytree': 0.635864456854321, 'min_child_weight': 2, 'gamma': 0.4420236644987758, 'reg_alpha': 8.63574304039086, 'reg_lambda': 2.538673791913996}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  28%|█████████████                                 | 57/200 [10:49<22:01,  9.24s/it][I 2025-01-27 12:45:17,908] Trial 57 finished with value: 0.0455274079044502 and parameters: {'n_estimators': 885, 'learning_rate': 0.06175960263739908, 'max_depth': 9, 'subsample': 0.7780752606976841, 'colsample_bytree': 0.9550988799021806, 'min_child_weight': 3, 'gamma': 0.029196061523970814, 'reg_alpha': 3.739892339066817, 'reg_lambda': 7.358011121548404}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  29%|█████████████▎                                | 58/200 [11:01<23:51, 10.08s/it][I 2025-01-27 12:45:24,592] Trial 58 finished with value: 0.06942708823064696 and parameters: {'n_estimators': 913, 'learning_rate': 0.24535098949788126, 'max_depth': 9, 'subsample': 0.7809170090778605, 'colsample_bytree': 0.9491249824437453, 'min_child_weight': 1, 'gamma': 9.033915693794114, 'reg_alpha': 3.786580269008028, 'reg_lambda': 8.473461315993418}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  30%|█████████████▌                                | 59/200 [11:08<21:17,  9.06s/it][I 2025-01-27 12:45:30,361] Trial 59 finished with value: 0.05653902331984519 and parameters: {'n_estimators': 695, 'learning_rate': 0.1857934072009832, 'max_depth': 8, 'subsample': 0.7810149017346704, 'colsample_bytree': 0.9960190413758881, 'min_child_weight': 3, 'gamma': 1.9960877827515424, 'reg_alpha': 3.108023919365565, 'reg_lambda': 7.8705864794607585}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  30%|█████████████▊                                | 60/200 [11:14<18:50,  8.07s/it][I 2025-01-27 12:45:35,121] Trial 60 finished with value: 0.07422605556590597 and parameters: {'n_estimators': 623, 'learning_rate': 0.9087518816480896, 'max_depth': 10, 'subsample': 0.8310129746980723, 'colsample_bytree': 0.8680181697611655, 'min_child_weight': 4, 'gamma': 1.2440454254430116, 'reg_alpha': 4.057082930896161, 'reg_lambda': 9.661275473805283}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  30%|██████████████                                | 61/200 [11:18<16:23,  7.08s/it][I 2025-01-27 12:45:44,283] Trial 61 finished with value: 0.050482298185204166 and parameters: {'n_estimators': 853, 'learning_rate': 0.054410086304461196, 'max_depth': 8, 'subsample': 0.6839087040937206, 'colsample_bytree': 0.6796181799951546, 'min_child_weight': 2, 'gamma': 0.3622078444337564, 'reg_alpha': 9.744797623888442, 'reg_lambda': 1.9856685958306672}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  31%|██████████████▎                               | 62/200 [11:28<17:43,  7.70s/it][I 2025-01-27 12:45:56,377] Trial 62 finished with value: 0.045891364935227545 and parameters: {'n_estimators': 1004, 'learning_rate': 0.07910349364394045, 'max_depth': 11, 'subsample': 0.7197805304527475, 'colsample_bytree': 0.7615754780264525, 'min_child_weight': 3, 'gamma': 0.036051926071079536, 'reg_alpha': 2.140399724710156, 'reg_lambda': 9.32994603717251}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  32%|██████████████▍                               | 63/200 [11:40<20:35,  9.02s/it][I 2025-01-27 12:46:03,447] Trial 63 finished with value: 0.06731160295766696 and parameters: {'n_estimators': 954, 'learning_rate': 0.6105161236610104, 'max_depth': 10, 'subsample': 0.7249697720086759, 'colsample_bytree': 0.7765599336439934, 'min_child_weight': 3, 'gamma': 1.1084920117117587, 'reg_alpha': 1.7806933404491314, 'reg_lambda': 9.257133824240773}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  32%|██████████████▋                               | 64/200 [11:47<19:07,  8.44s/it][I 2025-01-27 12:46:13,703] Trial 64 finished with value: 0.04912486585503368 and parameters: {'n_estimators': 1204, 'learning_rate': 0.1197848618614756, 'max_depth': 11, 'subsample': 0.7479681773908309, 'colsample_bytree': 0.8937875281554368, 'min_child_weight': 3, 'gamma': 0.3864944699567938, 'reg_alpha': 1.1331130273149783, 'reg_lambda': 8.137156993409713}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  32%|██████████████▉                               | 65/200 [11:57<20:12,  8.98s/it][I 2025-01-27 12:46:24,214] Trial 65 finished with value: 0.048753681050076124 and parameters: {'n_estimators': 1127, 'learning_rate': 0.3881379563194804, 'max_depth': 11, 'subsample': 0.8027171132343419, 'colsample_bytree': 0.7270045034273256, 'min_child_weight': 1, 'gamma': 0.007431386444888261, 'reg_alpha': 2.4255833551695343, 'reg_lambda': 8.90835089229209}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  33%|███████████████▏                              | 66/200 [12:08<21:05,  9.44s/it][I 2025-01-27 12:46:33,779] Trial 66 finished with value: 0.051340064156474054 and parameters: {'n_estimators': 1012, 'learning_rate': 0.07932224199748988, 'max_depth': 12, 'subsample': 0.975132792478106, 'colsample_bytree': 0.8420065261175972, 'min_child_weight': 2, 'gamma': 0.9935993299213927, 'reg_alpha': 2.0198164992114283, 'reg_lambda': 7.679447979057626}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  34%|███████████████▍                              | 67/200 [12:17<21:00,  9.48s/it][I 2025-01-27 12:46:42,605] Trial 67 finished with value: 0.05533839728292702 and parameters: {'n_estimators': 759, 'learning_rate': 0.043122390867262994, 'max_depth': 9, 'subsample': 0.6749088585343772, 'colsample_bytree': 0.9561357514079325, 'min_child_weight': 1, 'gamma': 1.4453139214094148, 'reg_alpha': 3.1885681405923205, 'reg_lambda': 6.739044800220915}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  34%|███████████████▋                              | 68/200 [12:26<20:25,  9.28s/it][I 2025-01-27 12:46:49,247] Trial 68 finished with value: 0.0631341969731534 and parameters: {'n_estimators': 855, 'learning_rate': 0.15522723354587747, 'max_depth': 10, 'subsample': 0.6538700459192687, 'colsample_bytree': 0.7861162493632189, 'min_child_weight': 4, 'gamma': 4.731327496581679, 'reg_alpha': 4.598409469584839, 'reg_lambda': 6.0269378960641635}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  34%|███████████████▊                              | 69/200 [12:33<18:32,  8.49s/it][I 2025-01-27 12:46:57,272] Trial 69 finished with value: 0.050441467043096044 and parameters: {'n_estimators': 923, 'learning_rate': 0.10107581852325319, 'max_depth': 7, 'subsample': 0.7142330415513032, 'colsample_bytree': 0.7447493451172144, 'min_child_weight': 2, 'gamma': 0.37137544360912467, 'reg_alpha': 4.126242999875265, 'reg_lambda': 7.38632582995241}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  35%|████████████████                              | 70/200 [12:41<18:05,  8.35s/it][I 2025-01-27 12:47:05,086] Trial 70 finished with value: 0.05833532529897896 and parameters: {'n_estimators': 994, 'learning_rate': 0.3009677663433975, 'max_depth': 12, 'subsample': 0.9339879171158977, 'colsample_bytree': 0.7084903541061665, 'min_child_weight': 1, 'gamma': 0.6796677713681538, 'reg_alpha': 0.44534168965218157, 'reg_lambda': 0.6480633119670571}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  36%|████████████████▎                             | 71/200 [12:48<17:36,  8.19s/it][I 2025-01-27 12:47:21,920] Trial 71 finished with value: 0.04720499238597296 and parameters: {'n_estimators': 1063, 'learning_rate': 0.03737898199967579, 'max_depth': 15, 'subsample': 0.7446198713988268, 'colsample_bytree': 0.5887800074990336, 'min_child_weight': 2, 'gamma': 0.06218841069753579, 'reg_alpha': 9.178215169824531, 'reg_lambda': 4.71385442555458}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  36%|████████████████▌                             | 72/200 [13:05<23:00, 10.78s/it][I 2025-01-27 12:47:40,122] Trial 72 finished with value: 0.04581144246774451 and parameters: {'n_estimators': 1242, 'learning_rate': 0.0500709721521716, 'max_depth': 15, 'subsample': 0.7490945989986202, 'colsample_bytree': 0.5175384672197527, 'min_child_weight': 2, 'gamma': 0.015097166896038777, 'reg_alpha': 8.868740538711442, 'reg_lambda': 5.419222866973407}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  36%|████████████████▊                             | 73/200 [13:23<27:32, 13.01s/it][I 2025-01-27 12:47:53,371] Trial 73 finished with value: 0.051325521168464894 and parameters: {'n_estimators': 1345, 'learning_rate': 0.03976548508558274, 'max_depth': 15, 'subsample': 0.7693017797097029, 'colsample_bytree': 0.519008864276012, 'min_child_weight': 2, 'gamma': 0.8222852376451043, 'reg_alpha': 9.14107094886034, 'reg_lambda': 5.736931302142636}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  37%|█████████████████                             | 74/200 [13:37<27:28, 13.08s/it][I 2025-01-27 12:48:05,114] Trial 74 finished with value: 0.04878708019688607 and parameters: {'n_estimators': 1262, 'learning_rate': 0.07565765988420636, 'max_depth': 15, 'subsample': 0.8176762206174489, 'colsample_bytree': 0.5359945196897501, 'min_child_weight': 3, 'gamma': 0.2666105180354159, 'reg_alpha': 9.861504457779816, 'reg_lambda': 5.330792232239495}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  38%|█████████████████▎                            | 75/200 [13:48<26:24, 12.68s/it][I 2025-01-27 12:48:14,324] Trial 75 finished with value: 0.05726509053027569 and parameters: {'n_estimators': 1226, 'learning_rate': 0.13428465027068565, 'max_depth': 15, 'subsample': 0.7431353807942215, 'colsample_bytree': 0.5588843359720379, 'min_child_weight': 1, 'gamma': 3.4539334978058154, 'reg_alpha': 1.2957837709473976, 'reg_lambda': 6.867814079417984}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  38%|█████████████████▍                            | 76/200 [13:58<24:03, 11.64s/it][I 2025-01-27 12:48:28,448] Trial 76 finished with value: 0.05435866267424958 and parameters: {'n_estimators': 1458, 'learning_rate': 0.039664394860787745, 'max_depth': 14, 'subsample': 0.5025409673247124, 'colsample_bytree': 0.919144471350052, 'min_child_weight': 1, 'gamma': 0.5859817943460857, 'reg_alpha': 8.311921252963968, 'reg_lambda': 8.723927538279424}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  38%|█████████████████▋                            | 77/200 [14:12<25:23, 12.38s/it][I 2025-01-27 12:48:37,362] Trial 77 finished with value: 0.06153160803400496 and parameters: {'n_estimators': 1134, 'learning_rate': 0.08270715776323187, 'max_depth': 15, 'subsample': 0.9018885845505267, 'colsample_bytree': 0.5842573444782792, 'min_child_weight': 3, 'gamma': 6.892807344754789, 'reg_alpha': 7.894180129788925, 'reg_lambda': 5.946719939807828}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  39%|█████████████████▉                            | 78/200 [14:21<23:03, 11.34s/it][I 2025-01-27 12:48:50,563] Trial 78 finished with value: 0.04901032099887426 and parameters: {'n_estimators': 1419, 'learning_rate': 0.06371123990849376, 'max_depth': 14, 'subsample': 0.7174445236209318, 'colsample_bytree': 0.514523560699393, 'min_child_weight': 2, 'gamma': 0.2523476388386207, 'reg_alpha': 9.272930136194644, 'reg_lambda': 4.76069778597748}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  40%|██████████████████▏                           | 79/200 [14:34<23:59, 11.90s/it][I 2025-01-27 12:48:59,525] Trial 79 finished with value: 0.05221665752504171 and parameters: {'n_estimators': 1081, 'learning_rate': 0.11886791819575335, 'max_depth': 15, 'subsample': 0.7662744268079787, 'colsample_bytree': 0.540731793019291, 'min_child_weight': 4, 'gamma': 0.9929812085811203, 'reg_alpha': 5.980260655457194, 'reg_lambda': 5.175270697809287}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  40%|██████████████████▍                           | 80/200 [14:43<22:02, 11.02s/it][I 2025-01-27 12:49:09,150] Trial 80 finished with value: 0.054907956789187376 and parameters: {'n_estimators': 1307, 'learning_rate': 0.20803446072007878, 'max_depth': 14, 'subsample': 0.7391753455560233, 'colsample_bytree': 0.6247134820584896, 'min_child_weight': 2, 'gamma': 1.2883117721232566, 'reg_alpha': 8.879731886132067, 'reg_lambda': 1.2612985524127138}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  40%|██████████████████▋                           | 81/200 [14:53<21:01, 10.60s/it][I 2025-01-27 12:49:16,800] Trial 81 finished with value: 0.04951844171183742 and parameters: {'n_estimators': 827, 'learning_rate': 0.17260295661019714, 'max_depth': 13, 'subsample': 0.6981734339496537, 'colsample_bytree': 0.5105583574917854, 'min_child_weight': 2, 'gamma': 0.08366355931772193, 'reg_alpha': 8.709981300121093, 'reg_lambda': 4.253369208629691}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  41%|██████████████████▊                           | 82/200 [15:00<19:06,  9.72s/it][I 2025-01-27 12:49:29,354] Trial 82 finished with value: 0.05102174755733714 and parameters: {'n_estimators': 896, 'learning_rate': 0.03129992546039947, 'max_depth': 15, 'subsample': 0.7117406893237448, 'colsample_bytree': 0.680989380876177, 'min_child_weight': 1, 'gamma': 0.6395893136806546, 'reg_alpha': 5.038743831423439, 'reg_lambda': 4.550337019906134}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  42%|███████████████████                           | 83/200 [15:13<20:36, 10.57s/it][I 2025-01-27 12:49:39,720] Trial 83 finished with value: 0.04762930885870215 and parameters: {'n_estimators': 969, 'learning_rate': 0.09508962384853659, 'max_depth': 12, 'subsample': 0.6836536087835967, 'colsample_bytree': 0.5585619270302735, 'min_child_weight': 3, 'gamma': 0.04745517129497587, 'reg_alpha': 9.756506140964285, 'reg_lambda': 3.027395425139542}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  42%|███████████████████▎                          | 84/200 [15:23<20:18, 10.51s/it][I 2025-01-27 12:49:49,800] Trial 84 finished with value: 0.04929066783691584 and parameters: {'n_estimators': 1164, 'learning_rate': 0.10811326888692874, 'max_depth': 14, 'subsample': 0.7939826824105375, 'colsample_bytree': 0.5002755480240731, 'min_child_weight': 9, 'gamma': 0.2863601347110337, 'reg_alpha': 9.694262482825476, 'reg_lambda': 3.018754332796232}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  42%|███████████████████▌                          | 85/200 [15:33<19:53, 10.38s/it][I 2025-01-27 12:50:04,958] Trial 85 finished with value: 0.04695874842149695 and parameters: {'n_estimators': 1032, 'learning_rate': 0.06373475273042636, 'max_depth': 13, 'subsample': 0.534140852751539, 'colsample_bytree': 0.5614987276088108, 'min_child_weight': 3, 'gamma': 0.010106331883454292, 'reg_alpha': 9.130098031010633, 'reg_lambda': 3.9337085756091215}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  43%|███████████████████▊                          | 86/200 [15:48<22:26, 11.81s/it][I 2025-01-27 12:50:15,338] Trial 86 finished with value: 0.05303000651623143 and parameters: {'n_estimators': 1045, 'learning_rate': 0.0575563122548649, 'max_depth': 13, 'subsample': 0.5311686988585589, 'colsample_bytree': 0.5955586888167301, 'min_child_weight': 4, 'gamma': 0.5878042683023896, 'reg_alpha': 9.192827707421337, 'reg_lambda': 3.7702891691795086}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  44%|████████████████████                          | 87/200 [15:59<21:26, 11.38s/it][I 2025-01-27 12:50:24,008] Trial 87 finished with value: 0.05423935492832353 and parameters: {'n_estimators': 1104, 'learning_rate': 0.1392634610668751, 'max_depth': 14, 'subsample': 0.5874050721200197, 'colsample_bytree': 0.5823109381966343, 'min_child_weight': 5, 'gamma': 0.8898736638719722, 'reg_alpha': 7.781573738276942, 'reg_lambda': 3.9716854832567816}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  44%|████████████████████▏                         | 88/200 [16:07<19:43, 10.57s/it][I 2025-01-27 12:50:51,506] Trial 88 finished with value: 0.05053547854161868 and parameters: {'n_estimators': 1228, 'learning_rate': 0.010640332332887595, 'max_depth': 13, 'subsample': 0.528186847679101, 'colsample_bytree': 0.5723600296131346, 'min_child_weight': 1, 'gamma': 0.2881352733317818, 'reg_alpha': 9.993179673082773, 'reg_lambda': 6.363710764251047}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  44%|████████████████████▍                         | 89/200 [16:35<28:56, 15.65s/it][I 2025-01-27 12:51:00,897] Trial 89 finished with value: 0.05491647271150886 and parameters: {'n_estimators': 1003, 'learning_rate': 0.0651378269775234, 'max_depth': 15, 'subsample': 0.6082638563983493, 'colsample_bytree': 0.5245311603358196, 'min_child_weight': 3, 'gamma': 1.4870560913483437, 'reg_alpha': 8.380189856563007, 'reg_lambda': 3.467434282903817}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  45%|████████████████████▋                         | 90/200 [16:44<25:14, 13.77s/it][I 2025-01-27 12:51:06,752] Trial 90 finished with value: 0.23085555077876196 and parameters: {'n_estimators': 105, 'learning_rate': 0.03423489953641726, 'max_depth': 14, 'subsample': 0.5589635825607576, 'colsample_bytree': 0.5437508377428084, 'min_child_weight': 2, 'gamma': 0.0015622002624389314, 'reg_alpha': 8.955375613898694, 'reg_lambda': 4.932306042969229}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  46%|████████████████████▉                         | 91/200 [16:50<20:42, 11.40s/it][I 2025-01-27 12:51:14,110] Trial 91 finished with value: 0.05113242856070802 and parameters: {'n_estimators': 763, 'learning_rate': 0.09915860420628705, 'max_depth': 12, 'subsample': 0.6881733890176025, 'colsample_bytree': 0.5578837456873966, 'min_child_weight': 3, 'gamma': 0.5306374956263361, 'reg_alpha': 9.56588123034229, 'reg_lambda': 3.2835995743704753}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  46%|█████████████████████▏                        | 92/200 [16:57<18:19, 10.18s/it][I 2025-01-27 12:51:23,497] Trial 92 finished with value: 0.050506962626680155 and parameters: {'n_estimators': 935, 'learning_rate': 0.08058565793624843, 'max_depth': 13, 'subsample': 0.5403111447280785, 'colsample_bytree': 0.5617299753146915, 'min_child_weight': 3, 'gamma': 0.21909081729614052, 'reg_alpha': 9.271758237694463, 'reg_lambda': 3.1129992157219295}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  46%|█████████████████████▍                        | 93/200 [17:07<17:44,  9.95s/it][I 2025-01-27 12:51:34,020] Trial 93 finished with value: 0.05238436578989647 and parameters: {'n_estimators': 885, 'learning_rate': 0.038629501103690705, 'max_depth': 11, 'subsample': 0.6693904374537049, 'colsample_bytree': 0.5310918295466999, 'min_child_weight': 3, 'gamma': 0.856115171487268, 'reg_alpha': 9.744509909230633, 'reg_lambda': 2.4373521586099276}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  47%|█████████████████████▌                        | 94/200 [17:17<17:52, 10.12s/it][I 2025-01-27 12:51:44,830] Trial 94 finished with value: 0.05170414193856325 and parameters: {'n_estimators': 1366, 'learning_rate': 0.14562200651238436, 'max_depth': 12, 'subsample': 0.5742035593812929, 'colsample_bytree': 0.550671130383343, 'min_child_weight': 1, 'gamma': 0.2616738813192832, 'reg_alpha': 6.691412524887184, 'reg_lambda': 5.547391118931413}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  48%|█████████████████████▊                        | 95/200 [17:28<18:04, 10.33s/it][I 2025-01-27 12:51:56,409] Trial 95 finished with value: 0.046680418882346905 and parameters: {'n_estimators': 1054, 'learning_rate': 0.0980499128750159, 'max_depth': 15, 'subsample': 0.7633454951585619, 'colsample_bytree': 0.573965761157695, 'min_child_weight': 4, 'gamma': 0.0240140014408832, 'reg_alpha': 9.425895670179528, 'reg_lambda': 1.9055887768524515}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  48%|██████████████████████                        | 96/200 [17:40<18:33, 10.70s/it][I 2025-01-27 12:52:05,257] Trial 96 finished with value: 0.051009190390275225 and parameters: {'n_estimators': 1051, 'learning_rate': 0.12057120283717435, 'max_depth': 15, 'subsample': 0.7706502443858383, 'colsample_bytree': 0.5751125443491599, 'min_child_weight': 5, 'gamma': 0.5682202163055066, 'reg_alpha': 8.889711833110567, 'reg_lambda': 1.9338246090745903}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  48%|██████████████████████▎                       | 97/200 [17:49<17:25, 10.15s/it][I 2025-01-27 12:52:13,839] Trial 97 finished with value: 0.05172501289542224 and parameters: {'n_estimators': 810, 'learning_rate': 0.05685475539409779, 'max_depth': 15, 'subsample': 0.8694929769319275, 'colsample_bytree': 0.518318092266124, 'min_child_weight': 4, 'gamma': 1.0966660668598156, 'reg_alpha': 9.45382827568679, 'reg_lambda': 0.9208863758297003}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  49%|██████████████████████▌                       | 98/200 [17:57<16:27,  9.68s/it][I 2025-01-27 12:52:31,519] Trial 98 finished with value: 0.049161397735907615 and parameters: {'n_estimators': 1176, 'learning_rate': 0.022239763917492134, 'max_depth': 14, 'subsample': 0.7893025277244233, 'colsample_bytree': 0.5375870114434127, 'min_child_weight': 4, 'gamma': 0.46048568333505685, 'reg_alpha': 5.351323547060621, 'reg_lambda': 0.4238399906073066}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  50%|██████████████████████▊                       | 99/200 [18:15<20:19, 12.08s/it][I 2025-01-27 12:52:41,776] Trial 99 finished with value: 0.06841485575289459 and parameters: {'n_estimators': 1501, 'learning_rate': 0.8049816858863753, 'max_depth': 15, 'subsample': 0.7584681022885743, 'colsample_bytree': 0.6021594660497933, 'min_child_weight': 1, 'gamma': 0.8092848750322648, 'reg_alpha': 9.19055768247479, 'reg_lambda': 1.4009754050854175}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  50%|██████████████████████▌                      | 100/200 [18:25<19:13, 11.53s/it][I 2025-01-27 12:52:50,704] Trial 100 finished with value: 0.06707830745514798 and parameters: {'n_estimators': 1127, 'learning_rate': 0.08335083451558725, 'max_depth': 14, 'subsample': 0.7343330724658612, 'colsample_bytree': 0.5933246341035248, 'min_child_weight': 2, 'gamma': 9.979866587439016, 'reg_alpha': 8.50830491063484, 'reg_lambda': 0.22379116791315057}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  50%|██████████████████████▋                      | 101/200 [18:34<17:44, 10.75s/it][I 2025-01-27 12:53:02,338] Trial 101 finished with value: 0.04733608372008925 and parameters: {'n_estimators': 974, 'learning_rate': 0.10386509587537471, 'max_depth': 15, 'subsample': 0.6225770380875113, 'colsample_bytree': 0.5648633768288011, 'min_child_weight': 3, 'gamma': 0.01410636941105941, 'reg_alpha': 9.737407944558292, 'reg_lambda': 2.8116787113796624}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  51%|██████████████████████▉                      | 102/200 [18:46<17:59, 11.02s/it][I 2025-01-27 12:53:11,762] Trial 102 finished with value: 0.05215276885573369 and parameters: {'n_estimators': 1061, 'learning_rate': 0.10673280849349673, 'max_depth': 15, 'subsample': 0.5526501110997697, 'colsample_bytree': 0.8336146496447069, 'min_child_weight': 3, 'gamma': 0.27113534094763286, 'reg_alpha': 9.41136426812253, 'reg_lambda': 2.556416810032983}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  52%|███████████████████████▏                     | 103/200 [18:55<17:02, 10.54s/it][I 2025-01-27 12:53:27,378] Trial 103 finished with value: 0.05039340549389907 and parameters: {'n_estimators': 1015, 'learning_rate': 0.028785931042858412, 'max_depth': 15, 'subsample': 0.5193121740470281, 'colsample_bytree': 0.6224629179023714, 'min_child_weight': 2, 'gamma': 0.22207662873149406, 'reg_alpha': 9.107094851037719, 'reg_lambda': 4.274735074942105}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  52%|███████████████████████▍                     | 104/200 [19:11<19:17, 12.06s/it][I 2025-01-27 12:53:36,919] Trial 104 finished with value: 0.052383676686831714 and parameters: {'n_estimators': 865, 'learning_rate': 0.05597007159493297, 'max_depth': 9, 'subsample': 0.5448810575887846, 'colsample_bytree': 0.5100343213597619, 'min_child_weight': 4, 'gamma': 0.6209327128770623, 'reg_alpha': 9.642341403827505, 'reg_lambda': 2.698993393522392}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  52%|███████████████████████▋                     | 105/200 [19:20<17:53, 11.31s/it][I 2025-01-27 12:53:46,916] Trial 105 finished with value: 0.04840674966710741 and parameters: {'n_estimators': 931, 'learning_rate': 0.13346869038092896, 'max_depth': 15, 'subsample': 0.622210429313321, 'colsample_bytree': 0.567732281797213, 'min_child_weight': 3, 'gamma': 0.025801788133359236, 'reg_alpha': 8.838414559717512, 'reg_lambda': 2.1539696393326127}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  53%|███████████████████████▊                     | 106/200 [19:30<17:05, 10.91s/it][I 2025-01-27 12:53:53,511] Trial 106 finished with value: 0.05289544039274395 and parameters: {'n_estimators': 725, 'learning_rate': 0.1668024777563453, 'max_depth': 14, 'subsample': 0.6438709212881734, 'colsample_bytree': 0.5277105949328647, 'min_child_weight': 1, 'gamma': 0.4520751034833603, 'reg_alpha': 7.197839744164346, 'reg_lambda': 3.529349253495434}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  54%|████████████████████████                     | 107/200 [19:37<14:54,  9.62s/it][I 2025-01-27 12:54:02,378] Trial 107 finished with value: 0.0514662894775319 and parameters: {'n_estimators': 985, 'learning_rate': 0.07233480334651599, 'max_depth': 5, 'subsample': 0.7540862967322084, 'colsample_bytree': 0.5501143163463935, 'min_child_weight': 2, 'gamma': 0.21216151998178664, 'reg_alpha': 9.834912517539156, 'reg_lambda': 1.7780071553739618}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  54%|████████████████████████▎                    | 108/200 [19:46<14:24,  9.39s/it][I 2025-01-27 12:54:12,513] Trial 108 finished with value: 0.0538531058790051 and parameters: {'n_estimators': 1100, 'learning_rate': 0.08943654401273073, 'max_depth': 15, 'subsample': 0.5961645679278119, 'colsample_bytree': 0.6465650259148614, 'min_child_weight': 3, 'gamma': 0.7278404790698622, 'reg_alpha': 2.6617452234594774, 'reg_lambda': 9.037957405193792}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  55%|████████████████████████▌                    | 109/200 [19:56<14:34,  9.62s/it][I 2025-01-27 12:54:22,873] Trial 109 finished with value: 0.06378106020430205 and parameters: {'n_estimators': 1286, 'learning_rate': 0.051358597348176036, 'max_depth': 15, 'subsample': 0.5682962617771954, 'colsample_bytree': 0.6116431286935462, 'min_child_weight': 5, 'gamma': 5.2206823754778675, 'reg_alpha': 8.176060672228491, 'reg_lambda': 4.680412416670011}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  55%|████████████████████████▊                    | 110/200 [20:06<14:45,  9.84s/it][I 2025-01-27 12:54:29,404] Trial 110 finished with value: 0.05975166620109599 and parameters: {'n_estimators': 887, 'learning_rate': 0.23550448013318664, 'max_depth': 14, 'subsample': 0.7253578058477744, 'colsample_bytree': 0.5859143721189803, 'min_child_weight': 1, 'gamma': 4.164290267873617, 'reg_alpha': 3.4547194617161843, 'reg_lambda': 8.235597473242517}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  56%|████████████████████████▉                    | 111/200 [20:13<13:07,  8.85s/it][I 2025-01-27 12:54:39,676] Trial 111 finished with value: 0.047681031817183354 and parameters: {'n_estimators': 958, 'learning_rate': 0.09128146873175534, 'max_depth': 14, 'subsample': 0.6889660513847654, 'colsample_bytree': 0.559475906907815, 'min_child_weight': 3, 'gamma': 0.054419968469667165, 'reg_alpha': 9.835368389523461, 'reg_lambda': 2.892571847804564}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  56%|█████████████████████████▏                   | 112/200 [20:23<13:36,  9.27s/it][I 2025-01-27 12:55:12,314] Trial 112 finished with value: 0.047227624993925764 and parameters: {'n_estimators': 983, 'learning_rate': 0.012111584212264354, 'max_depth': 12, 'subsample': 0.7166668839711806, 'colsample_bytree': 0.5393906038410766, 'min_child_weight': 3, 'gamma': 0.011294099653237903, 'reg_alpha': 9.526030248792624, 'reg_lambda': 3.8324417485690314}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  56%|█████████████████████████▍                   | 113/200 [20:56<23:36, 16.28s/it][I 2025-01-27 12:55:34,900] Trial 113 finished with value: 0.04976458616047328 and parameters: {'n_estimators': 1021, 'learning_rate': 0.012438122314604859, 'max_depth': 13, 'subsample': 0.7453591915380753, 'colsample_bytree': 0.5441311928266533, 'min_child_weight': 3, 'gamma': 0.42266759498216977, 'reg_alpha': 9.412385893940565, 'reg_lambda': 4.139077004084237}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  57%|█████████████████████████▋                   | 114/200 [21:18<26:02, 18.17s/it][I 2025-01-27 12:55:45,381] Trial 114 finished with value: 0.04861834258283955 and parameters: {'n_estimators': 662, 'learning_rate': 0.0394371160006322, 'max_depth': 10, 'subsample': 0.7115434368948867, 'colsample_bytree': 0.5352977768003017, 'min_child_weight': 2, 'gamma': 0.2043356075076585, 'reg_alpha': 9.059758489596755, 'reg_lambda': 3.771008294474726}. Best is trial 44 with value: 0.0455191129078128.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  57%|█████████████████████████▊                   | 115/200 [21:29<22:28, 15.87s/it][I 2025-01-27 12:56:09,522] Trial 115 finished with value: 0.04518986187440609 and parameters: {'n_estimators': 1071, 'learning_rate': 0.02543101470388167, 'max_depth': 13, 'subsample': 0.9751649450136985, 'colsample_bytree': 0.5127867059807416, 'min_child_weight': 3, 'gamma': 0.01828269667801075, 'reg_alpha': 9.550667046850428, 'reg_lambda': 9.939988319921097}. Best is trial 115 with value: 0.04518986187440609.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  58%|██████████████████████████                   | 116/200 [21:53<25:41, 18.35s/it][I 2025-01-27 12:56:18,893] Trial 116 finished with value: 0.05190885623247417 and parameters: {'n_estimators': 1072, 'learning_rate': 0.06960921114544769, 'max_depth': 9, 'subsample': 0.7742764637341086, 'colsample_bytree': 0.5004744864220341, 'min_child_weight': 4, 'gamma': 1.0127701006895258, 'reg_alpha': 8.736472912011322, 'reg_lambda': 9.949923921214792}. Best is trial 115 with value: 0.04518986187440609.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  58%|██████████████████████████▎                  | 117/200 [22:02<21:39, 15.66s/it][I 2025-01-27 12:56:47,576] Trial 117 finished with value: 0.04639322599268267 and parameters: {'n_estimators': 1134, 'learning_rate': 0.026778515574814896, 'max_depth': 14, 'subsample': 0.5061946936784617, 'colsample_bytree': 0.5159472846339312, 'min_child_weight': 3, 'gamma': 0.014896225776898753, 'reg_alpha': 4.248795447514891, 'reg_lambda': 9.73920928943445}. Best is trial 115 with value: 0.04518986187440609.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  59%|██████████████████████████▌                  | 118/200 [22:31<26:44, 19.56s/it][I 2025-01-27 12:57:05,878] Trial 118 finished with value: 0.048328900192293495 and parameters: {'n_estimators': 1203, 'learning_rate': 0.025618193112367953, 'max_depth': 13, 'subsample': 0.9795986758597366, 'colsample_bytree': 0.5136219976033267, 'min_child_weight': 3, 'gamma': 0.5042498920786301, 'reg_alpha': 4.280063476086166, 'reg_lambda': 9.082689049988256}. Best is trial 115 with value: 0.04518986187440609.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  60%|██████████████████████████▊                  | 119/200 [22:49<25:53, 19.19s/it][I 2025-01-27 12:57:20,007] Trial 119 finished with value: 0.05271315118099477 and parameters: {'n_estimators': 1245, 'learning_rate': 0.04179996247034983, 'max_depth': 13, 'subsample': 0.5119927424553572, 'colsample_bytree': 0.5196651311864691, 'min_child_weight': 3, 'gamma': 0.7656491954886926, 'reg_alpha': 3.746276898398483, 'reg_lambda': 9.562262714307423}. Best is trial 115 with value: 0.04518986187440609.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  60%|███████████████████████████                  | 120/200 [23:03<23:33, 17.67s/it][I 2025-01-27 12:57:48,755] Trial 120 finished with value: 0.049753665299546036 and parameters: {'n_estimators': 1156, 'learning_rate': 0.011973762757609476, 'max_depth': 14, 'subsample': 0.5238544709612513, 'colsample_bytree': 0.525182930444756, 'min_child_weight': 4, 'gamma': 0.3418956721939788, 'reg_alpha': 4.684831697910596, 'reg_lambda': 9.461295965040573}. Best is trial 115 with value: 0.04518986187440609.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  60%|███████████████████████████▏                 | 121/200 [23:32<27:38, 20.99s/it][I 2025-01-27 12:58:04,920] Trial 121 finished with value: 0.04643004048409563 and parameters: {'n_estimators': 1119, 'learning_rate': 0.05869306175937787, 'max_depth': 15, 'subsample': 0.7347382164386261, 'colsample_bytree': 0.5103151341861638, 'min_child_weight': 3, 'gamma': 0.030444814877025578, 'reg_alpha': 5.036311791963847, 'reg_lambda': 9.832910385174443}. Best is trial 115 with value: 0.04518986187440609.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  61%|███████████████████████████▍                 | 122/200 [23:48<25:24, 19.54s/it][I 2025-01-27 12:58:18,647] Trial 122 finished with value: 0.048324289849251134 and parameters: {'n_estimators': 1098, 'learning_rate': 0.05464071343600267, 'max_depth': 15, 'subsample': 0.7392466816844724, 'colsample_bytree': 0.5085489436259109, 'min_child_weight': 3, 'gamma': 0.19333504452434883, 'reg_alpha': 4.457488013360489, 'reg_lambda': 9.840105167669467}. Best is trial 115 with value: 0.04518986187440609.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  62%|███████████████████████████▋                 | 123/200 [24:02<22:50, 17.80s/it][I 2025-01-27 12:58:30,090] Trial 123 finished with value: 0.04995083821492387 and parameters: {'n_estimators': 1151, 'learning_rate': 0.0720013503309212, 'max_depth': 14, 'subsample': 0.7198381874318874, 'colsample_bytree': 0.5330612022255816, 'min_child_weight': 3, 'gamma': 0.43037933258613525, 'reg_alpha': 5.021884787467362, 'reg_lambda': 8.706438569600047}. Best is trial 115 with value: 0.04518986187440609.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  62%|███████████████████████████▉                 | 124/200 [24:13<20:07, 15.89s/it][I 2025-01-27 12:58:43,584] Trial 124 finished with value: 0.052170177029826195 and parameters: {'n_estimators': 1049, 'learning_rate': 0.03493753016045347, 'max_depth': 14, 'subsample': 0.502571333076376, 'colsample_bytree': 0.5152934676364287, 'min_child_weight': 4, 'gamma': 0.6521070712422842, 'reg_alpha': 3.996712871958668, 'reg_lambda': 9.241477979808163}. Best is trial 115 with value: 0.04518986187440609.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  62%|████████████████████████████▏                | 125/200 [24:27<18:57, 15.17s/it][I 2025-01-27 12:58:56,338] Trial 125 finished with value: 0.061108022345835476 and parameters: {'n_estimators': 1195, 'learning_rate': 0.02740561755388127, 'max_depth': 15, 'subsample': 0.8252352650415081, 'colsample_bytree': 0.5019324139762046, 'min_child_weight': 2, 'gamma': 6.290958163381859, 'reg_alpha': 0.8290820812319006, 'reg_lambda': 9.78351946341254}. Best is trial 115 with value: 0.04518986187440609.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  63%|████████████████████████████▎                | 126/200 [24:40<17:49, 14.45s/it][I 2025-01-27 12:59:31,254] Trial 126 finished with value: 0.04407463992994466 and parameters: {'n_estimators': 1316, 'learning_rate': 0.06502753880070211, 'max_depth': 14, 'subsample': 0.7636192776937836, 'colsample_bytree': 0.5439730429655086, 'min_child_weight': 3, 'gamma': 0.0011528059667573233, 'reg_alpha': 4.8576213426039745, 'reg_lambda': 9.38568719763845}. Best is trial 126 with value: 0.04407463992994466.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  64%|████████████████████████████▌                | 127/200 [25:15<25:02, 20.59s/it][I 2025-01-27 12:59:40,869] Trial 127 finished with value: 0.05642445846911833 and parameters: {'n_estimators': 1333, 'learning_rate': 0.4778235130183623, 'max_depth': 15, 'subsample': 0.7927122269252779, 'colsample_bytree': 0.5497191646996379, 'min_child_weight': 3, 'gamma': 0.20571607235756947, 'reg_alpha': 5.647031010376419, 'reg_lambda': 9.450539951659923}. Best is trial 126 with value: 0.04407463992994466.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  64%|████████████████████████████▊                | 128/200 [25:24<20:45, 17.30s/it][I 2025-01-27 12:59:58,969] Trial 128 finished with value: 0.04426360217204064 and parameters: {'n_estimators': 1400, 'learning_rate': 0.12116051466783637, 'max_depth': 14, 'subsample': 0.7674811196142763, 'colsample_bytree': 0.8910659592775285, 'min_child_weight': 2, 'gamma': 0.004256547436624913, 'reg_alpha': 4.920093446948694, 'reg_lambda': 9.99921812888403}. Best is trial 126 with value: 0.04407463992994466.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  64%|█████████████████████████████                | 129/200 [25:42<20:45, 17.54s/it][I 2025-01-27 13:00:10,980] Trial 129 finished with value: 0.06694683781253775 and parameters: {'n_estimators': 1424, 'learning_rate': 0.0673710010472642, 'max_depth': 14, 'subsample': 0.78503200030911, 'colsample_bytree': 0.894767832095287, 'min_child_weight': 4, 'gamma': 8.322619198389342, 'reg_alpha': 4.661647060490293, 'reg_lambda': 9.71482348597728}. Best is trial 126 with value: 0.04407463992994466.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  65%|█████████████████████████████▎               | 130/200 [25:54<18:31, 15.88s/it][I 2025-01-27 13:00:21,930] Trial 130 finished with value: 0.05487126814198445 and parameters: {'n_estimators': 1386, 'learning_rate': 0.12702395029771135, 'max_depth': 8, 'subsample': 0.76445111387346, 'colsample_bytree': 0.9417316175236731, 'min_child_weight': 6, 'gamma': 1.2690182502579002, 'reg_alpha': 4.892539777432268, 'reg_lambda': 9.313529449012947}. Best is trial 126 with value: 0.04407463992994466.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  66%|█████████████████████████████▍               | 131/200 [26:05<16:33, 14.40s/it][I 2025-01-27 13:00:34,287] Trial 131 finished with value: 0.04974901484524043 and parameters: {'n_estimators': 1306, 'learning_rate': 0.08791004477518077, 'max_depth': 14, 'subsample': 0.8150131492040263, 'colsample_bytree': 0.8616207352188328, 'min_child_weight': 2, 'gamma': 0.35584739450696756, 'reg_alpha': 5.277429029238696, 'reg_lambda': 9.554408786895443}. Best is trial 126 with value: 0.04407463992994466.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  66%|█████████████████████████████▋               | 132/200 [26:18<15:37, 13.79s/it][I 2025-01-27 13:00:49,268] Trial 132 finished with value: 0.0484880983165271 and parameters: {'n_estimators': 1251, 'learning_rate': 0.049197282011383445, 'max_depth': 15, 'subsample': 0.7485770433348603, 'colsample_bytree': 0.8053927517136609, 'min_child_weight': 2, 'gamma': 0.20927506840670299, 'reg_alpha': 4.828503918045783, 'reg_lambda': 9.927037108849882}. Best is trial 126 with value: 0.04407463992994466.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  66%|█████████████████████████████▉               | 133/200 [26:33<15:47, 14.15s/it][I 2025-01-27 13:01:01,925] Trial 133 finished with value: 0.051724921796303856 and parameters: {'n_estimators': 1577, 'learning_rate': 0.11198491972793956, 'max_depth': 14, 'subsample': 0.7320724632841593, 'colsample_bytree': 0.9889134611513033, 'min_child_weight': 3, 'gamma': 0.5523489297084323, 'reg_alpha': 4.270484632562202, 'reg_lambda': 9.994499272211895}. Best is trial 126 with value: 0.04407463992994466.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  67%|██████████████████████████████▏              | 134/200 [26:45<15:04, 13.70s/it][I 2025-01-27 13:01:34,245] Trial 134 finished with value: 0.043561411800510784 and parameters: {'n_estimators': 1459, 'learning_rate': 0.07100989831610854, 'max_depth': 15, 'subsample': 0.7579231780007842, 'colsample_bytree': 0.9620222049633008, 'min_child_weight': 2, 'gamma': 0.0020781338196793654, 'reg_alpha': 4.493428425036715, 'reg_lambda': 8.83274058517804}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  68%|██████████████████████████████▍              | 135/200 [27:18<20:53, 19.29s/it][I 2025-01-27 13:01:47,494] Trial 135 finished with value: 0.04609219463225271 and parameters: {'n_estimators': 1414, 'learning_rate': 0.1523162045099849, 'max_depth': 13, 'subsample': 0.7562606774360692, 'colsample_bytree': 0.95643096789839, 'min_child_weight': 7, 'gamma': 0.02050948645468656, 'reg_alpha': 5.147284795164067, 'reg_lambda': 8.924776584273834}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  68%|██████████████████████████████▌              | 136/200 [27:31<18:38, 17.47s/it][I 2025-01-27 13:01:59,315] Trial 136 finished with value: 0.05083618372644079 and parameters: {'n_estimators': 1494, 'learning_rate': 0.1469688469748124, 'max_depth': 14, 'subsample': 0.7764057847549715, 'colsample_bytree': 0.9652631803163547, 'min_child_weight': 6, 'gamma': 0.4255175835970157, 'reg_alpha': 4.474550972133909, 'reg_lambda': 8.682200184568021}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  68%|██████████████████████████████▊              | 137/200 [27:43<16:34, 15.78s/it][I 2025-01-27 13:02:12,722] Trial 137 finished with value: 0.05302862061303738 and parameters: {'n_estimators': 1676, 'learning_rate': 0.11784724066259983, 'max_depth': 15, 'subsample': 0.7609391327273993, 'colsample_bytree': 0.9669774644507709, 'min_child_weight': 8, 'gamma': 0.8347233658003232, 'reg_alpha': 5.082206006463072, 'reg_lambda': 8.989538016614384}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  69%|███████████████████████████████              | 138/200 [27:56<15:34, 15.07s/it][I 2025-01-27 13:02:23,940] Trial 138 finished with value: 0.04889318069838877 and parameters: {'n_estimators': 1441, 'learning_rate': 0.15969245651764338, 'max_depth': 15, 'subsample': 0.7559501842653854, 'colsample_bytree': 0.9281589193287844, 'min_child_weight': 8, 'gamma': 0.18521810374409986, 'reg_alpha': 5.496813807221537, 'reg_lambda': 9.332442134427383}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  70%|███████████████████████████████▎             | 139/200 [28:07<14:08, 13.91s/it][I 2025-01-27 13:02:35,556] Trial 139 finished with value: 0.052323031910606034 and parameters: {'n_estimators': 1370, 'learning_rate': 0.08844927939203112, 'max_depth': 14, 'subsample': 0.8067663387487296, 'colsample_bytree': 0.9732616755416809, 'min_child_weight': 9, 'gamma': 0.6277378818428806, 'reg_alpha': 5.95513194506019, 'reg_lambda': 8.862450153289792}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  70%|███████████████████████████████▍             | 140/200 [28:19<13:13, 13.22s/it][I 2025-01-27 13:02:49,013] Trial 140 finished with value: 0.05019152176236532 and parameters: {'n_estimators': 1523, 'learning_rate': 0.07654944404608796, 'max_depth': 15, 'subsample': 0.768483204717466, 'colsample_bytree': 0.8963082523234533, 'min_child_weight': 7, 'gamma': 0.3740644805619285, 'reg_alpha': 5.1588813637431095, 'reg_lambda': 9.673453752944907}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  70%|███████████████████████████████▋             | 141/200 [28:32<13:04, 13.29s/it][I 2025-01-27 13:03:14,580] Trial 141 finished with value: 0.044151953087561854 and parameters: {'n_estimators': 1418, 'learning_rate': 0.05951196214145253, 'max_depth': 13, 'subsample': 0.7359236878265618, 'colsample_bytree': 0.9544529217635994, 'min_child_weight': 3, 'gamma': 0.004172558398629506, 'reg_alpha': 4.8478759922782455, 'reg_lambda': 9.105059108080205}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  71%|███████████████████████████████▉             | 142/200 [28:58<16:24, 16.98s/it][I 2025-01-27 13:03:40,351] Trial 142 finished with value: 0.044244517190032834 and parameters: {'n_estimators': 1464, 'learning_rate': 0.05185426155402903, 'max_depth': 13, 'subsample': 0.7373716058067856, 'colsample_bytree': 0.9506486913980261, 'min_child_weight': 7, 'gamma': 0.0052705810461034595, 'reg_alpha': 4.787419422947884, 'reg_lambda': 9.108840546321082}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  72%|████████████████████████████████▏            | 143/200 [29:24<18:38, 19.61s/it][I 2025-01-27 13:04:18,420] Trial 143 finished with value: 0.043659144473725243 and parameters: {'n_estimators': 1460, 'learning_rate': 0.046884867283751686, 'max_depth': 13, 'subsample': 0.7341588802190625, 'colsample_bytree': 0.9523439775969882, 'min_child_weight': 7, 'gamma': 0.002171974090160603, 'reg_alpha': 4.78910524126623, 'reg_lambda': 9.213713134024296}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  72%|████████████████████████████████▍            | 144/200 [30:02<23:28, 25.15s/it][I 2025-01-27 13:04:51,230] Trial 144 finished with value: 0.043898757021693276 and parameters: {'n_estimators': 1596, 'learning_rate': 0.04946728872898979, 'max_depth': 13, 'subsample': 0.7346487574830681, 'colsample_bytree': 0.948045133830112, 'min_child_weight': 6, 'gamma': 0.003272554289240179, 'reg_alpha': 4.827601198488144, 'reg_lambda': 9.190605094624255}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  72%|████████████████████████████████▋            | 145/200 [30:35<25:09, 27.45s/it][I 2025-01-27 13:05:09,655] Trial 145 finished with value: 0.04943875206057167 and parameters: {'n_estimators': 1615, 'learning_rate': 0.03655354691831432, 'max_depth': 13, 'subsample': 0.7487255989891526, 'colsample_bytree': 0.9485043743919362, 'min_child_weight': 7, 'gamma': 0.27529209274282374, 'reg_alpha': 3.8335711058138795, 'reg_lambda': 9.165962672934855}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  73%|████████████████████████████████▊            | 146/200 [30:53<22:16, 24.74s/it][I 2025-01-27 13:05:24,306] Trial 146 finished with value: 0.05170846766151917 and parameters: {'n_estimators': 1459, 'learning_rate': 0.049553080653752815, 'max_depth': 13, 'subsample': 0.7054429018460205, 'colsample_bytree': 0.980826945522392, 'min_child_weight': 7, 'gamma': 0.5004688292825797, 'reg_alpha': 4.834904098860292, 'reg_lambda': 8.556077225601227}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  74%|█████████████████████████████████            | 147/200 [31:08<19:10, 21.71s/it][I 2025-01-27 13:05:46,471] Trial 147 finished with value: 0.04865157342084155 and parameters: {'n_estimators': 1829, 'learning_rate': 0.02716999170697877, 'max_depth': 13, 'subsample': 0.7288378505440842, 'colsample_bytree': 0.9327460875995874, 'min_child_weight': 7, 'gamma': 0.2168009491202482, 'reg_alpha': 4.197387190869989, 'reg_lambda': 7.9052491168065995}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  74%|█████████████████████████████████▎           | 148/200 [31:30<18:56, 21.85s/it][I 2025-01-27 13:05:57,721] Trial 148 finished with value: 0.055892736367168926 and parameters: {'n_estimators': 1638, 'learning_rate': 0.5779404506357939, 'max_depth': 13, 'subsample': 0.7419338745212443, 'colsample_bytree': 0.9564696337859786, 'min_child_weight': 7, 'gamma': 0.37358684647134255, 'reg_alpha': 4.497828901471254, 'reg_lambda': 8.856663991419442}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  74%|█████████████████████████████████▌           | 149/200 [31:41<15:52, 18.67s/it][I 2025-01-27 13:06:09,949] Trial 149 finished with value: 0.05201599722740193 and parameters: {'n_estimators': 1461, 'learning_rate': 0.07362571029751358, 'max_depth': 13, 'subsample': 0.7227752185622411, 'colsample_bytree': 0.9110133468771558, 'min_child_weight': 6, 'gamma': 0.6574093179916363, 'reg_alpha': 4.761435721221802, 'reg_lambda': 9.463194168386151}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  75%|█████████████████████████████████▊           | 150/200 [31:53<13:56, 16.74s/it][I 2025-01-27 13:07:03,128] Trial 150 finished with value: 0.04566220941056672 and parameters: {'n_estimators': 1403, 'learning_rate': 0.01072375135980403, 'max_depth': 13, 'subsample': 0.7765097341790042, 'colsample_bytree': 0.9402096602240205, 'min_child_weight': 8, 'gamma': 0.021564615172106255, 'reg_alpha': 5.464089765870316, 'reg_lambda': 9.169376135739043}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  76%|█████████████████████████████████▉           | 151/200 [32:46<22:35, 27.67s/it][I 2025-01-27 13:07:32,288] Trial 151 finished with value: 0.04564197782742442 and parameters: {'n_estimators': 1546, 'learning_rate': 0.024826273791444232, 'max_depth': 13, 'subsample': 0.7529022185296662, 'colsample_bytree': 0.9391385503436136, 'min_child_weight': 8, 'gamma': 0.02386408219092889, 'reg_alpha': 5.333627298228488, 'reg_lambda': 8.299029497919731}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  76%|██████████████████████████████████▏          | 152/200 [33:16<22:29, 28.12s/it][I 2025-01-27 13:08:02,480] Trial 152 finished with value: 0.04386077844132222 and parameters: {'n_estimators': 1414, 'learning_rate': 0.04649215845201929, 'max_depth': 12, 'subsample': 0.7793650938292066, 'colsample_bytree': 0.935139511173, 'min_child_weight': 8, 'gamma': 0.002562641036146921, 'reg_alpha': 5.489032476173662, 'reg_lambda': 8.269601808569275}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  76%|██████████████████████████████████▍          | 153/200 [33:46<22:30, 28.74s/it][I 2025-01-27 13:08:17,564] Trial 153 finished with value: 0.049234358034615136 and parameters: {'n_estimators': 1529, 'learning_rate': 0.05195747155876568, 'max_depth': 12, 'subsample': 0.7799907920040015, 'colsample_bytree': 0.930943436320347, 'min_child_weight': 8, 'gamma': 0.22759802205420432, 'reg_alpha': 6.317910534567633, 'reg_lambda': 8.222845560239334}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  77%|██████████████████████████████████▋          | 154/200 [34:01<18:53, 24.64s/it][I 2025-01-27 13:08:49,778] Trial 154 finished with value: 0.04987830073372075 and parameters: {'n_estimators': 1404, 'learning_rate': 0.010247811019754052, 'max_depth': 12, 'subsample': 0.8012954374251893, 'colsample_bytree': 0.9383908597251196, 'min_child_weight': 8, 'gamma': 0.3721733057212365, 'reg_alpha': 4.624377422470025, 'reg_lambda': 8.359909976803726}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  78%|██████████████████████████████████▉          | 155/200 [34:33<20:11, 26.91s/it][I 2025-01-27 13:09:06,597] Trial 155 finished with value: 0.04838544161101525 and parameters: {'n_estimators': 1559, 'learning_rate': 0.045339033273320783, 'max_depth': 13, 'subsample': 0.7858784749047786, 'colsample_bytree': 0.9156050226982057, 'min_child_weight': 8, 'gamma': 0.1738162177583858, 'reg_alpha': 5.451904326435922, 'reg_lambda': 7.9984470271432135}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  78%|███████████████████████████████████          | 156/200 [34:50<17:30, 23.89s/it][I 2025-01-27 13:09:31,778] Trial 156 finished with value: 0.04419174824763854 and parameters: {'n_estimators': 1484, 'learning_rate': 0.06359672071441158, 'max_depth': 12, 'subsample': 0.77434117400559, 'colsample_bytree': 0.9455832217276907, 'min_child_weight': 9, 'gamma': 0.0031557633620953145, 'reg_alpha': 5.738160447513994, 'reg_lambda': 7.3750554336235945}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  78%|███████████████████████████████████▎         | 157/200 [35:15<17:23, 24.27s/it][I 2025-01-27 13:10:00,254] Trial 157 finished with value: 0.05179249165217039 and parameters: {'n_estimators': 1497, 'learning_rate': 0.01185995440292733, 'max_depth': 12, 'subsample': 0.7686813380204978, 'colsample_bytree': 0.9491416633157816, 'min_child_weight': 9, 'gamma': 0.5642102701186551, 'reg_alpha': 5.624907662354483, 'reg_lambda': 7.2872228261034175}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  79%|███████████████████████████████████▌         | 158/200 [35:44<17:52, 25.53s/it][I 2025-01-27 13:10:12,234] Trial 158 finished with value: 0.053968551808822804 and parameters: {'n_estimators': 1340, 'learning_rate': 0.06394963621471127, 'max_depth': 13, 'subsample': 0.7498645885090024, 'colsample_bytree': 0.9780153756598284, 'min_child_weight': 10, 'gamma': 0.9217767163738959, 'reg_alpha': 5.840315125381586, 'reg_lambda': 7.5082002015941525}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  80%|███████████████████████████████████▊         | 159/200 [35:56<14:40, 21.47s/it][I 2025-01-27 13:10:45,626] Trial 159 finished with value: 0.044045822248002006 and parameters: {'n_estimators': 1471, 'learning_rate': 0.03480812031390489, 'max_depth': 13, 'subsample': 0.834387358693709, 'colsample_bytree': 0.9245300503822127, 'min_child_weight': 9, 'gamma': 0.003596203686340866, 'reg_alpha': 5.327039363591005, 'reg_lambda': 8.56104291102269}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  80%|████████████████████████████████████         | 160/200 [36:29<16:41, 25.05s/it][I 2025-01-27 13:10:58,365] Trial 160 finished with value: 0.04898082682554971 and parameters: {'n_estimators': 1464, 'learning_rate': 0.10584238022249418, 'max_depth': 12, 'subsample': 0.7971173845208158, 'colsample_bytree': 0.9075752222832737, 'min_child_weight': 9, 'gamma': 0.24120649746667422, 'reg_alpha': 5.306632629742051, 'reg_lambda': 8.47863742090726}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  80%|████████████████████████████████████▏        | 161/200 [36:42<13:52, 21.35s/it][I 2025-01-27 13:11:27,341] Trial 161 finished with value: 0.04500540893954639 and parameters: {'n_estimators': 1534, 'learning_rate': 0.03385337051361098, 'max_depth': 13, 'subsample': 0.8390959246692037, 'colsample_bytree': 0.9234982653435828, 'min_child_weight': 9, 'gamma': 0.010293112371666281, 'reg_alpha': 6.1270889071045325, 'reg_lambda': 7.759372090555515}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  81%|████████████████████████████████████▍        | 162/200 [37:11<14:58, 23.64s/it][I 2025-01-27 13:11:45,149] Trial 162 finished with value: 0.050238286783498155 and parameters: {'n_estimators': 1601, 'learning_rate': 0.03180959289238532, 'max_depth': 13, 'subsample': 0.7745962123211524, 'colsample_bytree': 0.9230067234231281, 'min_child_weight': 9, 'gamma': 0.3775223589938748, 'reg_alpha': 6.129915034952545, 'reg_lambda': 7.678091593937233}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  82%|████████████████████████████████████▋        | 163/200 [37:29<13:29, 21.89s/it][I 2025-01-27 13:12:01,109] Trial 163 finished with value: 0.04825197590694149 and parameters: {'n_estimators': 1369, 'learning_rate': 0.04530707079794116, 'max_depth': 13, 'subsample': 0.8427816931300524, 'colsample_bytree': 0.9410867268534552, 'min_child_weight': 9, 'gamma': 0.1749661261528058, 'reg_alpha': 5.6810190576947734, 'reg_lambda': 7.64830374074124}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  82%|████████████████████████████████████▉        | 164/200 [37:44<12:04, 20.11s/it][I 2025-01-27 13:12:14,784] Trial 164 finished with value: 0.051792777695599354 and parameters: {'n_estimators': 1537, 'learning_rate': 0.06986290897465935, 'max_depth': 13, 'subsample': 0.7356672134722947, 'colsample_bytree': 0.9591947059614273, 'min_child_weight': 8, 'gamma': 0.5253712776571482, 'reg_alpha': 5.437063834938692, 'reg_lambda': 7.033287474200738}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  82%|█████████████████████████████████████▏       | 165/200 [37:58<10:36, 18.18s/it][I 2025-01-27 13:12:35,843] Trial 165 finished with value: 0.048040204544154155 and parameters: {'n_estimators': 1481, 'learning_rate': 0.02883962208214669, 'max_depth': 13, 'subsample': 0.8841318239957634, 'colsample_bytree': 0.9656321187937938, 'min_child_weight': 9, 'gamma': 0.1555658267361912, 'reg_alpha': 4.877921663848935, 'reg_lambda': 8.683292647403498}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  83%|█████████████████████████████████████▎       | 166/200 [38:19<10:47, 19.04s/it][I 2025-01-27 13:13:24,888] Trial 166 finished with value: 0.046350673177642875 and parameters: {'n_estimators': 1432, 'learning_rate': 0.010917895941885677, 'max_depth': 13, 'subsample': 0.7598570858668412, 'colsample_bytree': 0.9452861919564274, 'min_child_weight': 10, 'gamma': 0.04055007345861704, 'reg_alpha': 5.179641365844786, 'reg_lambda': 8.083168059342329}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  84%|█████████████████████████████████████▌       | 167/200 [39:08<15:25, 28.04s/it][I 2025-01-27 13:13:40,986] Trial 167 finished with value: 0.049770429133324065 and parameters: {'n_estimators': 1660, 'learning_rate': 0.054997794886363485, 'max_depth': 12, 'subsample': 0.9270175951879814, 'colsample_bytree': 0.9349940047862413, 'min_child_weight': 8, 'gamma': 0.3845052233860596, 'reg_alpha': 5.810090751434648, 'reg_lambda': 8.363262715705618}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  84%|█████████████████████████████████████▊       | 168/200 [39:24<13:02, 24.46s/it][I 2025-01-27 13:13:57,219] Trial 168 finished with value: 0.04541628278853094 and parameters: {'n_estimators': 1560, 'learning_rate': 0.08962482478596243, 'max_depth': 12, 'subsample': 0.7868872554835629, 'colsample_bytree': 0.9041458716827294, 'min_child_weight': 9, 'gamma': 0.01577776878228394, 'reg_alpha': 5.287922463493691, 'reg_lambda': 9.220187821718302}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  84%|██████████████████████████████████████       | 169/200 [39:41<11:21, 21.99s/it][I 2025-01-27 13:14:10,222] Trial 169 finished with value: 0.05326845740707673 and parameters: {'n_estimators': 1705, 'learning_rate': 0.08989914801475274, 'max_depth': 6, 'subsample': 0.8132650208182075, 'colsample_bytree': 0.903809503069968, 'min_child_weight': 9, 'gamma': 0.6414476841288684, 'reg_alpha': 5.5186113903846, 'reg_lambda': 9.201943278589393}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  85%|██████████████████████████████████████▎      | 170/200 [39:54<09:38, 19.30s/it][I 2025-01-27 13:14:22,254] Trial 170 finished with value: 0.05034156310671595 and parameters: {'n_estimators': 1569, 'learning_rate': 0.714954120205544, 'max_depth': 12, 'subsample': 0.8633202429557053, 'colsample_bytree': 0.9241002873805745, 'min_child_weight': 9, 'gamma': 0.014680541666136616, 'reg_alpha': 5.310681533470406, 'reg_lambda': 9.007361199926796}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  86%|██████████████████████████████████████▍      | 171/200 [40:06<08:16, 17.12s/it][I 2025-01-27 13:14:37,658] Trial 171 finished with value: 0.04944389707392503 and parameters: {'n_estimators': 1408, 'learning_rate': 0.044255871511900274, 'max_depth': 12, 'subsample': 0.7814801977185044, 'colsample_bytree': 0.8841992683667672, 'min_child_weight': 8, 'gamma': 0.29968493280568814, 'reg_alpha': 4.9831570381623695, 'reg_lambda': 8.630030443706927}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  86%|██████████████████████████████████████▋      | 172/200 [40:21<07:44, 16.60s/it][I 2025-01-27 13:14:56,274] Trial 172 finished with value: 0.045269564017749606 and parameters: {'n_estimators': 1518, 'learning_rate': 0.0653999071489626, 'max_depth': 11, 'subsample': 0.9577140702477813, 'colsample_bytree': 0.9496539001195987, 'min_child_weight': 6, 'gamma': 0.01764113546526841, 'reg_alpha': 4.615996816754568, 'reg_lambda': 9.139102471187243}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  86%|██████████████████████████████████████▉      | 173/200 [40:40<07:44, 17.21s/it][I 2025-01-27 13:15:15,669] Trial 173 finished with value: 0.0444261114874308 and parameters: {'n_estimators': 1528, 'learning_rate': 0.07626994619591237, 'max_depth': 11, 'subsample': 0.9594831263297812, 'colsample_bytree': 0.9507397327278068, 'min_child_weight': 6, 'gamma': 0.004930918312441919, 'reg_alpha': 4.4476914587571414, 'reg_lambda': 9.377395036212995}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  87%|███████████████████████████████████████▏     | 174/200 [40:59<07:44, 17.86s/it][I 2025-01-27 13:15:28,751] Trial 174 finished with value: 0.0485326093195398 and parameters: {'n_estimators': 1529, 'learning_rate': 0.10271328830355142, 'max_depth': 11, 'subsample': 0.9609617354410949, 'colsample_bytree': 0.997178707360185, 'min_child_weight': 6, 'gamma': 0.2102187797129545, 'reg_alpha': 4.437838888041788, 'reg_lambda': 9.391115585151205}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  88%|███████████████████████████████████████▍     | 175/200 [41:12<06:50, 16.43s/it][I 2025-01-27 13:15:43,103] Trial 175 finished with value: 0.04988367019360088 and parameters: {'n_estimators': 1598, 'learning_rate': 0.07865271164840701, 'max_depth': 11, 'subsample': 0.9538563248207672, 'colsample_bytree': 0.9517852133561882, 'min_child_weight': 6, 'gamma': 0.42137884819939386, 'reg_alpha': 3.933516448395955, 'reg_lambda': 8.828657658970497}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  88%|███████████████████████████████████████▌     | 176/200 [41:26<06:19, 15.81s/it][I 2025-01-27 13:15:55,384] Trial 176 finished with value: 0.05793078280617668 and parameters: {'n_estimators': 1504, 'learning_rate': 0.07342624463165631, 'max_depth': 12, 'subsample': 0.9782890247798457, 'colsample_bytree': 0.9697045249674657, 'min_child_weight': 6, 'gamma': 2.953678651726926, 'reg_alpha': 4.6178950248046515, 'reg_lambda': 9.574744165891913}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  88%|███████████████████████████████████████▊     | 177/200 [41:39<05:39, 14.75s/it][I 2025-01-27 13:16:10,467] Trial 177 finished with value: 0.045015694501005 and parameters: {'n_estimators': 1542, 'learning_rate': 0.1213018866097366, 'max_depth': 11, 'subsample': 0.9675087348919559, 'colsample_bytree': 0.9186313935241499, 'min_child_weight': 6, 'gamma': 0.010079979077307939, 'reg_alpha': 4.799014984610324, 'reg_lambda': 9.108301035734845}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  89%|████████████████████████████████████████     | 178/200 [41:54<05:26, 14.85s/it][I 2025-01-27 13:16:22,483] Trial 178 finished with value: 0.04848955144421132 and parameters: {'n_estimators': 1463, 'learning_rate': 0.12762139420002083, 'max_depth': 11, 'subsample': 0.9933313534748193, 'colsample_bytree': 0.91811203028656, 'min_child_weight': 6, 'gamma': 0.23775444961771242, 'reg_alpha': 4.75756674228146, 'reg_lambda': 9.062510645227237}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  90%|████████████████████████████████████████▎    | 179/200 [42:06<04:53, 14.00s/it][I 2025-01-27 13:16:33,733] Trial 179 finished with value: 0.06358447175309243 and parameters: {'n_estimators': 1632, 'learning_rate': 0.9848665848669697, 'max_depth': 10, 'subsample': 0.9655207070036099, 'colsample_bytree': 0.9264392492716378, 'min_child_weight': 6, 'gamma': 0.7105207623681675, 'reg_alpha': 4.369461732776852, 'reg_lambda': 9.310599753706283}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  90%|████████████████████████████████████████▌    | 180/200 [42:17<04:23, 13.17s/it][I 2025-01-27 13:16:46,102] Trial 180 finished with value: 0.04983922042012197 and parameters: {'n_estimators': 1504, 'learning_rate': 0.10121902058730801, 'max_depth': 11, 'subsample': 0.9436327317956515, 'colsample_bytree': 0.881767333699269, 'min_child_weight': 6, 'gamma': 0.4555609137186069, 'reg_alpha': 4.9297915934594245, 'reg_lambda': 9.109299864066225}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  90%|████████████████████████████████████████▋    | 181/200 [42:29<04:05, 12.93s/it][I 2025-01-27 13:17:09,206] Trial 181 finished with value: 0.04422362700792942 and parameters: {'n_estimators': 1555, 'learning_rate': 0.05998144750473893, 'max_depth': 11, 'subsample': 0.9461846436523211, 'colsample_bytree': 0.987099561381277, 'min_child_weight': 9, 'gamma': 0.002746222531964616, 'reg_alpha': 5.1223732785015645, 'reg_lambda': 8.414890438878274}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  91%|████████████████████████████████████████▉    | 182/200 [42:53<04:47, 15.98s/it][I 2025-01-27 13:17:30,689] Trial 182 finished with value: 0.04452841248014508 and parameters: {'n_estimators': 1562, 'learning_rate': 0.0636100687889983, 'max_depth': 11, 'subsample': 0.986977556809004, 'colsample_bytree': 0.9805185393471229, 'min_child_weight': 9, 'gamma': 0.003372486461595661, 'reg_alpha': 5.169753995813049, 'reg_lambda': 8.801105451253573}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  92%|█████████████████████████████████████████▏   | 183/200 [43:14<04:59, 17.63s/it][I 2025-01-27 13:17:45,406] Trial 183 finished with value: 0.04869038335046944 and parameters: {'n_estimators': 1723, 'learning_rate': 0.08440353267557824, 'max_depth': 11, 'subsample': 0.9688694473028249, 'colsample_bytree': 0.9826367614524659, 'min_child_weight': 9, 'gamma': 0.21202105949942252, 'reg_alpha': 5.118603081106705, 'reg_lambda': 8.799993520631652}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  92%|█████████████████████████████████████████▍   | 184/200 [43:29<04:28, 16.76s/it][I 2025-01-27 13:18:02,820] Trial 184 finished with value: 0.04545141720370717 and parameters: {'n_estimators': 1571, 'learning_rate': 0.06128617270137639, 'max_depth': 10, 'subsample': 0.9877608909398073, 'colsample_bytree': 0.9866143293521821, 'min_child_weight': 10, 'gamma': 0.020809633183600844, 'reg_alpha': 4.654967160389617, 'reg_lambda': 8.514992773157571}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  92%|█████████████████████████████████████████▋   | 185/200 [43:46<04:14, 16.96s/it][I 2025-01-27 13:18:17,215] Trial 185 finished with value: 0.04529445580950485 and parameters: {'n_estimators': 1569, 'learning_rate': 0.12080951736609225, 'max_depth': 10, 'subsample': 0.9835230094902534, 'colsample_bytree': 0.9751572017705806, 'min_child_weight': 10, 'gamma': 0.012686059497385015, 'reg_alpha': 4.79659779474915, 'reg_lambda': 8.498836929557294}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  93%|█████████████████████████████████████████▊   | 186/200 [44:01<03:46, 16.19s/it][I 2025-01-27 13:18:29,700] Trial 186 finished with value: 0.049114369244467646 and parameters: {'n_estimators': 1554, 'learning_rate': 0.12833584832940523, 'max_depth': 11, 'subsample': 0.9500509863449185, 'colsample_bytree': 0.9703147786951377, 'min_child_weight': 10, 'gamma': 0.25005440873702744, 'reg_alpha': 4.908951391672236, 'reg_lambda': 8.801938465286502}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  94%|██████████████████████████████████████████   | 187/200 [44:13<03:15, 15.08s/it][I 2025-01-27 13:18:42,624] Trial 187 finished with value: 0.04990958640769504 and parameters: {'n_estimators': 1605, 'learning_rate': 0.1196598024667915, 'max_depth': 11, 'subsample': 0.9781748099215568, 'colsample_bytree': 0.9990800050512796, 'min_child_weight': 9, 'gamma': 0.3666009622671961, 'reg_alpha': 5.228808094123517, 'reg_lambda': 8.466300857708973}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  94%|██████████████████████████████████████████▎  | 188/200 [44:26<02:53, 14.43s/it][I 2025-01-27 13:19:02,998] Trial 188 finished with value: 0.04374562079320469 and parameters: {'n_estimators': 1516, 'learning_rate': 0.09074135735612378, 'max_depth': 11, 'subsample': 0.9343957999398209, 'colsample_bytree': 0.9605989945360961, 'min_child_weight': 9, 'gamma': 0.0018136437671476668, 'reg_alpha': 4.504710406179548, 'reg_lambda': 9.581468032030914}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  94%|██████████████████████████████████████████▌  | 189/200 [44:46<02:58, 16.21s/it][I 2025-01-27 13:19:14,796] Trial 189 finished with value: 0.05051081764345734 and parameters: {'n_estimators': 1446, 'learning_rate': 0.11482561343894024, 'max_depth': 10, 'subsample': 0.9391193223913541, 'colsample_bytree': 0.9605226689614492, 'min_child_weight': 10, 'gamma': 0.5205842352415071, 'reg_alpha': 4.148294412506054, 'reg_lambda': 9.613530173720774}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  95%|██████████████████████████████████████████▊  | 190/200 [44:58<02:28, 14.89s/it][I 2025-01-27 13:19:29,677] Trial 190 finished with value: 0.04860465888158874 and parameters: {'n_estimators': 1768, 'learning_rate': 0.09403404281343931, 'max_depth': 11, 'subsample': 0.9131064879965458, 'colsample_bytree': 0.9736202201920967, 'min_child_weight': 9, 'gamma': 0.20184577641615517, 'reg_alpha': 4.553042966375096, 'reg_lambda': 9.4549212688735}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  96%|██████████████████████████████████████████▉  | 191/200 [45:13<02:13, 14.89s/it][I 2025-01-27 13:19:47,402] Trial 191 finished with value: 0.04477755558855215 and parameters: {'n_estimators': 1497, 'learning_rate': 0.08041344037768562, 'max_depth': 11, 'subsample': 0.9843384824197153, 'colsample_bytree': 0.951626572226105, 'min_child_weight': 9, 'gamma': 0.006902434195595163, 'reg_alpha': 4.858273225470993, 'reg_lambda': 8.997048114854673}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  96%|███████████████████████████████████████████▏ | 192/200 [45:31<02:05, 15.74s/it][I 2025-01-27 13:20:01,859] Trial 192 finished with value: 0.04844854020320607 and parameters: {'n_estimators': 1501, 'learning_rate': 0.06528650027647247, 'max_depth': 11, 'subsample': 0.9862848251436802, 'colsample_bytree': 0.9487638022262612, 'min_child_weight': 9, 'gamma': 0.20065355629335935, 'reg_alpha': 4.780220043303079, 'reg_lambda': 8.9054387986069}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  96%|███████████████████████████████████████████▍ | 193/200 [45:45<01:47, 15.35s/it][I 2025-01-27 13:20:13,861] Trial 193 finished with value: 0.045743783277273097 and parameters: {'n_estimators': 1484, 'learning_rate': 0.3853593663876569, 'max_depth': 11, 'subsample': 0.9715206168624221, 'colsample_bytree': 0.9607498389871006, 'min_child_weight': 9, 'gamma': 0.003470266336891184, 'reg_alpha': 4.324924352117312, 'reg_lambda': 9.096728046050854}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  97%|███████████████████████████████████████████▋ | 194/200 [45:57<01:26, 14.35s/it][I 2025-01-27 13:20:27,256] Trial 194 finished with value: 0.04968248274740651 and parameters: {'n_estimators': 1534, 'learning_rate': 0.07561345237859252, 'max_depth': 10, 'subsample': 0.95562279783567, 'colsample_bytree': 0.9861965549626138, 'min_child_weight': 9, 'gamma': 0.34927061796890363, 'reg_alpha': 5.035408406377112, 'reg_lambda': 8.56190839077637}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  98%|███████████████████████████████████████████▉ | 195/200 [46:11<01:10, 14.06s/it][I 2025-01-27 13:20:49,216] Trial 195 finished with value: 0.04490557253106621 and parameters: {'n_estimators': 1643, 'learning_rate': 0.050204071551301355, 'max_depth': 11, 'subsample': 0.9952613423785188, 'colsample_bytree': 0.9516514265061574, 'min_child_weight': 6, 'gamma': 0.010921666502023853, 'reg_alpha': 4.465955696876489, 'reg_lambda': 8.156710541489847}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  98%|████████████████████████████████████████████ | 196/200 [46:33<01:05, 16.43s/it][I 2025-01-27 13:21:05,999] Trial 196 finished with value: 0.04833669311311394 and parameters: {'n_estimators': 1648, 'learning_rate': 0.05005117836514092, 'max_depth': 11, 'subsample': 0.9923343600427247, 'colsample_bytree': 0.948902971510566, 'min_child_weight': 6, 'gamma': 0.20335691682932577, 'reg_alpha': 4.450962730769633, 'reg_lambda': 7.927453310422422}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  98%|████████████████████████████████████████████▎| 197/200 [46:49<00:49, 16.54s/it][I 2025-01-27 13:21:21,465] Trial 197 finished with value: 0.05012069288260734 and parameters: {'n_estimators': 1445, 'learning_rate': 0.03950688491353045, 'max_depth': 11, 'subsample': 0.9640897316625348, 'colsample_bytree': 0.9321798240442712, 'min_child_weight': 6, 'gamma': 0.5359382116550035, 'reg_alpha': 4.0288431309932315, 'reg_lambda': 9.724878057451686}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  99%|████████████████████████████████████████████▌| 198/200 [47:05<00:32, 16.22s/it][I 2025-01-27 13:21:36,797] Trial 198 finished with value: 0.049608795298234504 and parameters: {'n_estimators': 1609, 'learning_rate': 0.058913447943417165, 'max_depth': 11, 'subsample': 0.9999568910903173, 'colsample_bytree': 0.9572554397292791, 'min_child_weight': 6, 'gamma': 0.36197607928854025, 'reg_alpha': 4.575275754883483, 'reg_lambda': 8.106180762204861}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...: 100%|████████████████████████████████████████████▊| 199/200 [47:20<00:15, 15.95s/it][I 2025-01-27 13:21:49,575] Trial 199 finished with value: 0.048725792791750606 and parameters: {'n_estimators': 1478, 'learning_rate': 0.09589749920098267, 'max_depth': 11, 'subsample': 0.9736859352775981, 'colsample_bytree': 0.9436234634083064, 'min_child_weight': 5, 'gamma': 0.20093338593960092, 'reg_alpha': 5.087021001117697, 'reg_lambda': 9.34880876205787}. Best is trial 134 with value: 0.043561411800510784.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...: 100%|█████████████████████████████████████████████| 200/200 [47:33<00:00, 14.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최고의 MAPE값 0.043561411800510784 \n",
      "\n",
      "최고의 하이퍼 파라미터 {'n_estimators': 1459, 'learning_rate': 0.07100989831610854, 'max_depth': 15, 'subsample': 0.7579231780007842, 'colsample_bytree': 0.9620222049633008, 'min_child_weight': 2, 'gamma': 0.0020781338196793654, 'reg_alpha': 4.493428425036715, 'reg_lambda': 8.83274058517804} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'update'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 265\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------- 최적 파라미터로 학습 후 제출 ----------------------------------------\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \n\u001b[0;32m    262\u001b[0m \n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# 최적의 하이퍼파라미터 가져오기\u001b[39;00m\n\u001b[0;32m    264\u001b[0m best_params \u001b[38;5;241m=\u001b[39m xgb_study\u001b[38;5;241m.\u001b[39mbest_value\n\u001b[1;32m--> 265\u001b[0m best_params\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[0;32m    266\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtree_method\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhist\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \n\u001b[0;32m    267\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m,       \n\u001b[0;32m    268\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m})\n\u001b[0;32m    271\u001b[0m \u001b[38;5;66;03m# 로그 변환된 타겟 값 사용\u001b[39;00m\n\u001b[0;32m    272\u001b[0m log_y_df \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(y_df)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'update'"
     ]
    }
   ],
   "source": [
    "\n",
    "# =================================================================================================================================\n",
    "# ==================================================== 가중치 변수 없이 6개월 주기 추가  ==================================================\n",
    "# =================================================================================================================================\n",
    "\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "train = train.dropna()\n",
    "train = train.reset_index()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------데이터 전처리\n",
    "\n",
    "# 날짜 파생 변수 생성\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "train['year'] = train['date'].dt.year\n",
    "train['month'] = train['date'].dt.month\n",
    "train['weekday'] = train['date'].dt.weekday\n",
    "train['day'] = train['date'].dt.day\n",
    "train['day_of_week'] = train['date'].dt.dayofweek\n",
    "train['week_of_year'] = train['date'].dt.isocalendar().week\n",
    "train['day_sin'] = np.sin(2 * np.pi * train['day'] / 365)\n",
    "train['day_cos'] = np.cos(2 * np.pi * train['day'] / 365)\n",
    "train['half_year_sin'] = np.sin(2 * np.pi * train['day'] / 182.5)\n",
    "train['half_year_cos'] = np.cos(2 * np.pi * train['day'] / 182.5)\n",
    "train['month_sin'] = np.sin(2 * np.pi * train['month'] / 12)\n",
    "train['month_cos'] = np.cos(2 * np.pi * train['month'] / 12)\n",
    "train['year_sin'] = np.sin(2 * np.pi * train['year'] / 7)\n",
    "train['year_cos'] = np.cos(2 * np.pi * train['year'] / 7)\n",
    "train['group'] = (train['year'] - 2010) * 48 + train['month'] * 4 + train['day'] // 7\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------ 인코딩\n",
    "\n",
    "country_mapping = {\n",
    "    'Kenya': 0,\n",
    "    'Italy': 1,\n",
    "    'Finland': 2,\n",
    "    'Canada': 3,\n",
    "    'Singapore': 4,\n",
    "    'Norway': 5}\n",
    "train['country'] = train['country'].map(country_mapping)\n",
    "\n",
    "\n",
    "store_mapping = {\n",
    "    'Discount Stickers' : 0,\n",
    "    'Stickers for Less' : 1,\n",
    "    'Premium Sticker Mart' : 2}\n",
    "train['store'] = train['store'].map(store_mapping)\n",
    "\n",
    "product_mapping = {\n",
    "    'Holographic Goose' : 0,\n",
    "    'Kerneler' : 1,\n",
    "    'Kerneler Dark Mode' : 2,\n",
    "    'Kaggle Tiers' : 3,\n",
    "    'Kaggle' : 4}\n",
    "train['product'] = train['product'].map(product_mapping)\n",
    "\n",
    "\n",
    "'''\n",
    "# (월,화,수,목 = 0) (금 = 1) (토 = 2) (일 = 3)\n",
    "weekday_mapping = {\n",
    "    0 : 0,\n",
    "    1 : 0,\n",
    "    2 : 0,\n",
    "    3 : 0,\n",
    "    4 : 1,\n",
    "    5 : 2,\n",
    "    6 : 3}\n",
    "train['mapped_weekday'] = train['weekday'].map(weekday_mapping)\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 월별 매핑\n",
    "month_mapping = {\n",
    "    2: 1, 5: 1, 4: 1, 3: 1,   # 2, 5, 4, 3월 → 1\n",
    "    9: 2, 10: 2,              # 9, 10월 → 2\n",
    "    6: 3, 7: 3, 8: 3,         # 6, 7, 8월 → 3\n",
    "    1: 4, 11: 4,              # 1, 11월 → 4\n",
    "    12: 5}                     # 12월 → 5\n",
    "train['mapped_month'] = train['month'].map(month_mapping)   \n",
    "'''\n",
    "\n",
    "# 연도별 배핑\n",
    "'''\n",
    "year_mapping = {\n",
    "    2011: 1, 2013: 1,  # 2011년, 2013년 → 1\n",
    "    2012: 2, 2014: 2,  # 2012년, 2014년 → 2\n",
    "    2010: 3, 2015: 3, 2016: 3} # 2010년, 2015년, 2016년 → 3\n",
    "train['mapped_year'] = train['year'].map(year_mapping)\n",
    "'''\n",
    "\n",
    "# 반응변수 추출\n",
    "y_df = train['num_sold']\n",
    "log_y_df = np.log1p(y_df)\n",
    "\n",
    "# 필요없는 변수 삭제\n",
    "train = train.drop(['num_sold', 'id', 'date', 'index', 'day_of_week'] , axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------- 테스트 데이터 전처리 ----------------------------------------------------------------\n",
    "\n",
    "\n",
    "# 테스트 데이터 전처리\n",
    "\n",
    "# 테스트 데이터 전처리\n",
    "\n",
    "# =================================================================================================================================\n",
    "# ==================================================== 테스트 데이터 전처리 (시도 4로 ) ==================================================\n",
    "# =================================================================================================================================\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# -------------------------------------------------------------데이터 전처리\n",
    "\n",
    "# 날짜 파생 변수 생성\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "test['year'] = test['date'].dt.year\n",
    "test['month'] = test['date'].dt.month\n",
    "test['weekday'] = test['date'].dt.weekday\n",
    "test['day'] = test['date'].dt.day\n",
    "test['day_of_week'] = test['date'].dt.dayofweek\n",
    "test['week_of_year'] = test['date'].dt.isocalendar().week\n",
    "test['day_sin'] = np.sin(2 * np.pi * test['day'] / 365)\n",
    "test['day_cos'] = np.cos(2 * np.pi * test['day'] / 365)\n",
    "test['half_year_sin'] = np.sin(2 * np.pi * test['day'] / 182.5)\n",
    "test['half_year_cos'] = np.cos(2 * np.pi * test['day'] / 182.5)\n",
    "test['month_sin'] = np.sin(2 * np.pi * test['month'] / 12)\n",
    "test['month_cos'] = np.cos(2 * np.pi * test['month'] / 12)\n",
    "test['year_sin'] = np.sin(2 * np.pi * test['year'] / 7)\n",
    "test['year_cos'] = np.cos(2 * np.pi * test['year'] / 7)\n",
    "test['group'] = (test['year'] - 2010) * 48 + test['month'] * 4 + test['day'] // 7\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------ 인코딩\n",
    "\n",
    "country_mapping = {\n",
    "    'Kenya': 0,\n",
    "    'Italy': 1,\n",
    "    'Finland': 2,\n",
    "    'Canada': 3,\n",
    "    'Singapore': 4,\n",
    "    'Norway': 5}\n",
    "test['country'] = test['country'].map(country_mapping)\n",
    "\n",
    "\n",
    "store_mapping = {\n",
    "    'Discount Stickers' : 0,\n",
    "    'Stickers for Less' : 1,\n",
    "    'Premium Sticker Mart' : 2}\n",
    "test['store'] = test['store'].map(store_mapping)\n",
    "\n",
    "\n",
    "product_mapping = {\n",
    "    'Holographic Goose' : 0,\n",
    "    'Kerneler' : 1,\n",
    "    'Kerneler Dark Mode' : 2,\n",
    "    'Kaggle Tiers' : 3,\n",
    "    'Kaggle' : 4}\n",
    "test['product'] = test['product'].map(product_mapping)\n",
    "\n",
    "'''\n",
    "# (월,화,수,목 = 0) (금 = 1) (토 = 2) (일 = 3)\n",
    "weekday_mapping = {\n",
    "    0 : 0,\n",
    "    1 : 0,\n",
    "    2 : 0,\n",
    "    3 : 0,\n",
    "    4 : 1,\n",
    "    5 : 2,\n",
    "    6 : 3}\n",
    "test['mapped_weekday'] = test['weekday'].map(weekday_mapping)\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 월별 매핑\n",
    "month_mapping = {\n",
    "    2: 1, 5: 1, 4: 1, 3: 1,   # 2, 5, 4, 3월 → 1\n",
    "    9: 2, 10: 2,              # 9, 10월 → 2\n",
    "    6: 3, 7: 3, 8: 3,         # 6, 7, 8월 → 3\n",
    "    1: 4, 11: 4,              # 1, 11월 → 4\n",
    "    12: 5}                     # 12월 → 5\n",
    "test['mapped_month'] = test['month'].map(month_mapping)   \n",
    "'''\n",
    "\n",
    "# 연도별 매핑 (2017년 부터인줄 몰랐어)............\n",
    "'''\n",
    "year_mapping = {\n",
    "    2011: 1, 2013: 1,  # 2011년, 2013년 → 1\n",
    "    2012: 2, 2014: 2,  # 2012년, 2014년 → 2\n",
    "    2010: 3, 2015: 3, 2016: 3} # 2010년, 2015년, 2016년 → 3\n",
    "test['mapped_year'] = test['year'].map(year_mapping)\n",
    "'''\n",
    "\n",
    "\n",
    "# 필요없는 변수 삭제\n",
    "test = test.drop(['id', 'date', 'day_of_week'] , axis = 1)\n",
    "\n",
    "# 데이터 확인\n",
    "\n",
    "\n",
    "# --------------------------------------------------- 시도 9 학습 ---------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# --------------------------------------------- 가중치 변수 삭제하고 학습  ---------------------------------------------------\n",
    "\n",
    "# ----------------------------------------------------- 데이터 학습 --------------------------------------------------------------\n",
    "\n",
    "# 목적함수 생성\n",
    "def objective(trial):\n",
    "    params = {\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 100, 2000),  # 트리 개수\n",
    "    'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),  # 학습률\n",
    "    'max_depth': trial.suggest_int('max_depth', 3, 15),  # 트리 최대 깊이\n",
    "    'subsample': trial.suggest_float('subsample', 0.5, 1.0),  # 샘플링 비율\n",
    "    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),  # 특성 샘플링 비율\n",
    "    'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),  # 리프 노드 최소 가중치\n",
    "    'gamma': trial.suggest_float('gamma', 0, 10),  # 최소 손실 감소\n",
    "    'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),  # L1 정규화\n",
    "    'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),  # L2 정규화\n",
    "    \"tree_method\": \"hist\",  # 트리 방법\n",
    "    \"device\": \"cuda\",       # GPU 사용\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    'random_state': 1\n",
    "}\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    xgb_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(train):\n",
    "        x_train, x_val = train.iloc[train_index], train.iloc[val_index]\n",
    "        y_train, y_val = log_y_df[train_index], log_y_df[val_index]\n",
    "\n",
    "        # XGBoost 모델 생성\n",
    "        xgb_model = xgb.XGBRegressor(**params)\n",
    "        xgb_model.fit(x_train, y_train)\n",
    "\n",
    "        # 예측 및 RMSLE 계산\n",
    "        y_pred = np.exp(xgb_model.predict(x_val))\n",
    "        mape = mean_absolute_percentage_error(np.exp(y_val), y_pred)\n",
    "        xgb_scores.append(mape)\n",
    "\n",
    "    return np.mean(xgb_scores)\n",
    "\n",
    "# Optuna 하이퍼파라미터 최적화\n",
    "n_trials = 200\n",
    "xgb_study = optuna.create_study(direction='minimize')\n",
    "\n",
    "for _ in tqdm(range(n_trials), desc='XGBoost 하이퍼파라미터 튜닝 중...'):\n",
    "    xgb_study.optimize(objective, n_trials=1, catch=(Exception,))\n",
    "\n",
    "print('최고의 MAPE값', xgb_study.best_value, '\\n')\n",
    "print('최고의 하이퍼 파라미터', xgb_study.best_params, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------- 최적 파라미터로 학습 후 제출 ----------------------------------------\n",
    "\n",
    "\n",
    "# 최적의 하이퍼파라미터 가져오기\n",
    "best_params = xgb_study.best_params\n",
    "best_params.update({\n",
    "     \"tree_method\": \"hist\",  \n",
    "    \"device\": \"cuda\",       \n",
    "    \"objective\": \"reg:squarederror\"})\n",
    "\n",
    "# 로그 변환된 타겟 값 사용\n",
    "log_y_df = np.log(y_df)\n",
    "\n",
    "# 최적의 파라미터로 최종 모델 학습\n",
    "final_xgb_model = xgb.XGBRegressor(**best_params)\n",
    "final_xgb_model.fit(train, log_y_df)\n",
    "\n",
    "# 예측 및 지수 함수로 변환\n",
    "y_pred_log = final_xgb_model.predict(test)\n",
    "y_pred = np.exp(y_pred_log)  # 로그 변환된 값을 지수 함수로 복원\n",
    "\n",
    "# 변수 중요도 추출\n",
    "feature_importances = final_xgb_model.feature_importances_\n",
    "features = train.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 변수 중요도 출력\n",
    "print(\"Feature Importances:\")\n",
    "print(importance_df)\n",
    "\n",
    "# 변수 중요도 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance (XGBoost)')\n",
    "plt.gca().invert_yaxis()  # 중요도가 높은 순서로 표시\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------- 제출 파일 -----------------------------------------------------------------\n",
    "\n",
    "sub_9 = sub.copy()\n",
    "sub_9['num_sold'] = y_pred\n",
    "\n",
    "sub_9.to_csv('sub_9.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed8aa084-4ba4-495f-ae83-82f65ba216b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "          Feature  Importance\n",
      "0         country    0.663392\n",
      "1           store    0.182490\n",
      "2         product    0.144021\n",
      "15       year_cos    0.002969\n",
      "5         weekday    0.001970\n",
      "3            year    0.001222\n",
      "12      month_sin    0.001180\n",
      "4           month    0.000667\n",
      "13      month_cos    0.000610\n",
      "7    week_of_year    0.000595\n",
      "16          group    0.000503\n",
      "14       year_sin    0.000288\n",
      "6             day    0.000055\n",
      "8         day_sin    0.000038\n",
      "11  half_year_cos    0.000000\n",
      "10  half_year_sin    0.000000\n",
      "9         day_cos    0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------------------- 최적 파라미터로 학습 후 제출 ----------------------------------------\n",
    "\n",
    "\n",
    "# 최적의 하이퍼파라미터 가져오기\n",
    "best_params = xgb_study.best_params\n",
    "best_params.update({\n",
    "     \"tree_method\": \"hist\",  \n",
    "    \"device\": \"cuda\",       \n",
    "    \"objective\": \"reg:squarederror\"})\n",
    "\n",
    "# 로그 변환된 타겟 값 사용\n",
    "log_y_df = np.log(y_df)\n",
    "\n",
    "# 최적의 파라미터로 최종 모델 학습\n",
    "final_xgb_model = xgb.XGBRegressor(**best_params)\n",
    "final_xgb_model.fit(train, log_y_df)\n",
    "\n",
    "# 예측 및 지수 함수로 변환\n",
    "y_pred_log = final_xgb_model.predict(test)\n",
    "y_pred = np.exp(y_pred_log)  # 로그 변환된 값을 지수 함수로 복원\n",
    "\n",
    "# 변수 중요도 추출\n",
    "feature_importances = final_xgb_model.feature_importances_\n",
    "features = train.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 변수 중요도 출력\n",
    "print(\"Feature Importances:\")\n",
    "print(importance_df)\n",
    "\n",
    "# 변수 중요도 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance (XGBoost)')\n",
    "plt.gca().invert_yaxis()  # 중요도가 높은 순서로 표시\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------- 제출 파일 -----------------------------------------------------------------\n",
    "\n",
    "sub_9 = sub.copy()\n",
    "sub_9['num_sold'] = y_pred\n",
    "\n",
    "sub_9.to_csv('sub_9.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3bbabd-268e-447a-a6bb-57d6e2fb359b",
   "metadata": {},
   "source": [
    "<div style=\"background-color:red; padding:10px; border-radius:10px; font-size:18px;\">\n",
    "(시도 10)<br><br>\n",
    "GDP 변수 추가 (시도 중단함)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73daa10-70d4-4d94-852a-abb47d885e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =================================================================================================================================\n",
    "# ==================================================== 가중치 변수 없이 6개월 주기 추가  ==================================================\n",
    "# =================================================================================================================================\n",
    "\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "train = train.dropna()\n",
    "train = train.reset_index()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------데이터 전처리\n",
    "\n",
    "# 날짜 파생 변수 생성\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "train['year'] = train['date'].dt.year\n",
    "train['month'] = train['date'].dt.month\n",
    "train['weekday'] = train['date'].dt.weekday\n",
    "train['day'] = train['date'].dt.day\n",
    "train['day_of_week'] = train['date'].dt.dayofweek\n",
    "train['week_of_year'] = train['date'].dt.isocalendar().week\n",
    "train['day_sin'] = np.sin(2 * np.pi * train['day'] / 365)\n",
    "train['day_cos'] = np.cos(2 * np.pi * train['day'] / 365)\n",
    "train['month_sin'] = np.sin(2 * np.pi * train['month'] / 12)\n",
    "train['month_cos'] = np.cos(2 * np.pi * train['month'] / 12)\n",
    "train['year_sin'] = np.sin(2 * np.pi * train['year'] / 7)\n",
    "train['year_cos'] = np.cos(2 * np.pi * train['year'] / 7)\n",
    "train['group'] = (train['year'] - 2010) * 48 + train['month'] * 4 + train['day'] // 7\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------ 인코딩\n",
    "\n",
    "country_mapping = {\n",
    "    'Kenya': 0,\n",
    "    'Italy': 1,\n",
    "    'Finland': 2,\n",
    "    'Canada': 3,\n",
    "    'Singapore': 4,\n",
    "    'Norway': 5}\n",
    "train['country'] = train['country'].map(country_mapping)\n",
    "\n",
    "\n",
    "store_mapping = {\n",
    "    'Discount Stickers' : 0,\n",
    "    'Stickers for Less' : 1,\n",
    "    'Premium Sticker Mart' : 2}\n",
    "train['store'] = train['store'].map(store_mapping)\n",
    "\n",
    "product_mapping = {\n",
    "    'Holographic Goose' : 0,\n",
    "    'Kerneler' : 1,\n",
    "    'Kerneler Dark Mode' : 2,\n",
    "    'Kaggle Tiers' : 3,\n",
    "    'Kaggle' : 4}\n",
    "train['product'] = train['product'].map(product_mapping)\n",
    "\n",
    "\n",
    "'''\n",
    "# (월,화,수,목 = 0) (금 = 1) (토 = 2) (일 = 3)\n",
    "weekday_mapping = {\n",
    "    0 : 0,\n",
    "    1 : 0,\n",
    "    2 : 0,\n",
    "    3 : 0,\n",
    "    4 : 1,\n",
    "    5 : 2,\n",
    "    6 : 3}\n",
    "train['mapped_weekday'] = train['weekday'].map(weekday_mapping)\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 월별 매핑\n",
    "month_mapping = {\n",
    "    2: 1, 5: 1, 4: 1, 3: 1,   # 2, 5, 4, 3월 → 1\n",
    "    9: 2, 10: 2,              # 9, 10월 → 2\n",
    "    6: 3, 7: 3, 8: 3,         # 6, 7, 8월 → 3\n",
    "    1: 4, 11: 4,              # 1, 11월 → 4\n",
    "    12: 5}                     # 12월 → 5\n",
    "train['mapped_month'] = train['month'].map(month_mapping)   \n",
    "'''\n",
    "\n",
    "# 연도별 배핑\n",
    "'''\n",
    "year_mapping = {\n",
    "    2011: 1, 2013: 1,  # 2011년, 2013년 → 1\n",
    "    2012: 2, 2014: 2,  # 2012년, 2014년 → 2\n",
    "    2010: 3, 2015: 3, 2016: 3} # 2010년, 2015년, 2016년 → 3\n",
    "train['mapped_year'] = train['year'].map(year_mapping)\n",
    "'''\n",
    "\n",
    "# 반응변수 추출\n",
    "y_df = train['num_sold']\n",
    "log_y_df = np.log1p(y_df)\n",
    "\n",
    "# 필요없는 변수 삭제\n",
    "train = train.drop(['num_sold', 'id', 'date', 'index', 'day_of_week'] , axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------- 테스트 데이터 전처리 ----------------------------------------------------------------\n",
    "\n",
    "\n",
    "# 테스트 데이터 전처리\n",
    "\n",
    "# 테스트 데이터 전처리\n",
    "\n",
    "# =================================================================================================================================\n",
    "# ==================================================== 테스트 데이터 전처리 (시도 4로 ) ==================================================\n",
    "# =================================================================================================================================\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# -------------------------------------------------------------데이터 전처리\n",
    "\n",
    "# 날짜 파생 변수 생성\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "test['year'] = test['date'].dt.year\n",
    "test['month'] = test['date'].dt.month\n",
    "test['weekday'] = test['date'].dt.weekday\n",
    "test['day'] = test['date'].dt.day\n",
    "test['day_of_week'] = test['date'].dt.dayofweek\n",
    "test['week_of_year'] = test['date'].dt.isocalendar().week\n",
    "test['day_sin'] = np.sin(2 * np.pi * test['day'] / 365)\n",
    "test['day_cos'] = np.cos(2 * np.pi * test['day'] / 365)\n",
    "test['month_sin'] = np.sin(2 * np.pi * test['month'] / 12)\n",
    "test['month_cos'] = np.cos(2 * np.pi * test['month'] / 12)\n",
    "test['year_sin'] = np.sin(2 * np.pi * test['year'] / 7)\n",
    "test['year_cos'] = np.cos(2 * np.pi * test['year'] / 7)\n",
    "test['group'] = (test['year'] - 2010) * 48 + test['month'] * 4 + test['day'] // 7\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------ 인코딩\n",
    "\n",
    "country_mapping = {\n",
    "    'Kenya': 0,\n",
    "    'Italy': 1,\n",
    "    'Finland': 2,\n",
    "    'Canada': 3,\n",
    "    'Singapore': 4,\n",
    "    'Norway': 5}\n",
    "test['country'] = test['country'].map(country_mapping)\n",
    "\n",
    "\n",
    "store_mapping = {\n",
    "    'Discount Stickers' : 0,\n",
    "    'Stickers for Less' : 1,\n",
    "    'Premium Sticker Mart' : 2}\n",
    "test['store'] = test['store'].map(store_mapping)\n",
    "\n",
    "\n",
    "product_mapping = {\n",
    "    'Holographic Goose' : 0,\n",
    "    'Kerneler' : 1,\n",
    "    'Kerneler Dark Mode' : 2,\n",
    "    'Kaggle Tiers' : 3,\n",
    "    'Kaggle' : 4}\n",
    "test['product'] = test['product'].map(product_mapping)\n",
    "\n",
    "'''\n",
    "# (월,화,수,목 = 0) (금 = 1) (토 = 2) (일 = 3)\n",
    "weekday_mapping = {\n",
    "    0 : 0,\n",
    "    1 : 0,\n",
    "    2 : 0,\n",
    "    3 : 0,\n",
    "    4 : 1,\n",
    "    5 : 2,\n",
    "    6 : 3}\n",
    "test['mapped_weekday'] = test['weekday'].map(weekday_mapping)\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 월별 매핑\n",
    "month_mapping = {\n",
    "    2: 1, 5: 1, 4: 1, 3: 1,   # 2, 5, 4, 3월 → 1\n",
    "    9: 2, 10: 2,              # 9, 10월 → 2\n",
    "    6: 3, 7: 3, 8: 3,         # 6, 7, 8월 → 3\n",
    "    1: 4, 11: 4,              # 1, 11월 → 4\n",
    "    12: 5}                     # 12월 → 5\n",
    "test['mapped_month'] = test['month'].map(month_mapping)   \n",
    "'''\n",
    "\n",
    "# 연도별 매핑 (2017년 부터인줄 몰랐어)............\n",
    "'''\n",
    "year_mapping = {\n",
    "    2011: 1, 2013: 1,  # 2011년, 2013년 → 1\n",
    "    2012: 2, 2014: 2,  # 2012년, 2014년 → 2\n",
    "    2010: 3, 2015: 3, 2016: 3} # 2010년, 2015년, 2016년 → 3\n",
    "test['mapped_year'] = test['year'].map(year_mapping)\n",
    "'''\n",
    "\n",
    "\n",
    "# 필요없는 변수 삭제\n",
    "test = test.drop(['id', 'date', 'day_of_week'] , axis = 1)\n",
    "\n",
    "# 데이터 확인\n",
    "\n",
    "\n",
    "# --------------------------------------------------- 시도 9 학습 ---------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# --------------------------------------------- 가중치 변수 삭제하고 학습  ---------------------------------------------------\n",
    "\n",
    "# ----------------------------------------------------- 데이터 학습 --------------------------------------------------------------\n",
    "\n",
    "# 목적함수 생성\n",
    "def objective(trial):\n",
    "    params = {\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 100, 2000),  # 트리 개수\n",
    "    'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),  # 학습률\n",
    "    'max_depth': trial.suggest_int('max_depth', 3, 15),  # 트리 최대 깊이\n",
    "    'subsample': trial.suggest_float('subsample', 0.5, 1.0),  # 샘플링 비율\n",
    "    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),  # 특성 샘플링 비율\n",
    "    'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),  # 리프 노드 최소 가중치\n",
    "    'gamma': trial.suggest_float('gamma', 0, 10),  # 최소 손실 감소\n",
    "    'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),  # L1 정규화\n",
    "    'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),  # L2 정규화\n",
    "    \"tree_method\": \"hist\",  # 트리 방법\n",
    "    \"device\": \"cuda\",       # GPU 사용\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    'random_state': 1\n",
    "}\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    xgb_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(train):\n",
    "        x_train, x_val = train.iloc[train_index], train.iloc[val_index]\n",
    "        y_train, y_val = log_y_df[train_index], log_y_df[val_index]\n",
    "\n",
    "        # XGBoost 모델 생성\n",
    "        xgb_model = xgb.XGBRegressor(**params)\n",
    "        xgb_model.fit(x_train, y_train)\n",
    "\n",
    "        # 예측 및 RMSLE 계산\n",
    "        y_pred = np.exp(xgb_model.predict(x_val))\n",
    "        mape = mean_absolute_percentage_error(np.exp(y_val), y_pred)\n",
    "        xgb_scores.append(mape)\n",
    "\n",
    "    return np.mean(xgb_scores)\n",
    "\n",
    "# Optuna 하이퍼파라미터 최적화\n",
    "n_trials = 200\n",
    "xgb_study = optuna.create_study(direction='minimize')\n",
    "\n",
    "for _ in tqdm(range(n_trials), desc='XGBoost 하이퍼파라미터 튜닝 중...'):\n",
    "    xgb_study.optimize(objective, n_trials=1, catch=(Exception,))\n",
    "\n",
    "print('최고의 MAPE값', xgb_study.best_value, '\\n')\n",
    "print('최고의 하이퍼 파라미터', xgb_study.best_params, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------- 최적 파라미터로 학습 후 제출 ----------------------------------------\n",
    "\n",
    "\n",
    "# 최적의 하이퍼파라미터 가져오기\n",
    "best_params = xgb_study.best_params\n",
    "best_params.update({\n",
    "     \"tree_method\": \"hist\",  \n",
    "    \"device\": \"cuda\",       \n",
    "    \"objective\": \"reg:squarederror\"})\n",
    "\n",
    "# 로그 변환된 타겟 값 사용\n",
    "log_y_df = np.log(y_df)\n",
    "\n",
    "# 최적의 파라미터로 최종 모델 학습\n",
    "final_xgb_model = xgb.XGBRegressor(**best_params)\n",
    "final_xgb_model.fit(train, log_y_df)\n",
    "\n",
    "# 예측 및 지수 함수로 변환\n",
    "y_pred_log = final_xgb_model.predict(test)\n",
    "y_pred = np.exp(y_pred_log)  # 로그 변환된 값을 지수 함수로 복원\n",
    "\n",
    "# 변수 중요도 추출\n",
    "feature_importances = final_xgb_model.feature_importances_\n",
    "features = train.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 변수 중요도 출력\n",
    "print(\"Feature Importances:\")\n",
    "print(importance_df)\n",
    "\n",
    "# 변수 중요도 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance (XGBoost)')\n",
    "plt.gca().invert_yaxis()  # 중요도가 높은 순서로 표시\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------- 제출 파일 -----------------------------------------------------------------\n",
    "\n",
    "sub_9 = sub.copy()\n",
    "sub_9['num_sold'] = y_pred\n",
    "\n",
    "sub_9.to_csv('sub_9.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
