{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf424ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "<div style=\"background-color:gray; padding:15px; border-radius:10px; font-size:20px; color:white;\">\n",
    "    <h2 style=\"margin-bottom:10px;\">xgb 모델 예측 목차</h2>\n",
    "    <ol style=\"padding-left:20px;\">\n",
    "        <li>데이터 확인</li>\n",
    "        <li>(시도 1) 수동 전처리 사용</li>\n",
    "        <li>추세 및 주기성 확인 (주파수 분석)</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af7aff5",
   "metadata": {},
   "source": [
    "<div style=\"background-color:red; padding:10px; border-radius:10px; font-size:18px;\">\n",
    "데이터 확인\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1912781f-0c6b-463a-8b6f-f8af2375a593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 패키지\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 머신러닝 패키지\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "# 그래프 한글 표시\n",
    "plt.rcParams['font.family'] = 'NanumGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab4430b6-3a29-451f-909a-1ac4529edb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Holographic Goose</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>973.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle Tiers</td>\n",
       "      <td>906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kerneler</td>\n",
       "      <td>423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kerneler Dark Mode</td>\n",
       "      <td>491.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date country              store             product  num_sold\n",
       "0   0  2010-01-01  Canada  Discount Stickers   Holographic Goose       NaN\n",
       "1   1  2010-01-01  Canada  Discount Stickers              Kaggle     973.0\n",
       "2   2  2010-01-01  Canada  Discount Stickers        Kaggle Tiers     906.0\n",
       "3   3  2010-01-01  Canada  Discount Stickers            Kerneler     423.0\n",
       "4   4  2010-01-01  Canada  Discount Stickers  Kerneler Dark Mode     491.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e566d-b02a-4817-ac78-9dd4c5bc1609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 정의 평가지표 MAPE 함수 생성\n",
    "def MAPE(y_true, y_pred):\n",
    "    \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "\n",
    "    # 분모가 0인 경우\n",
    "    if np.any(y_true == 0):\n",
    "        raise ValueError(\"0이 존재해서 불가능\")\n",
    "\n",
    "    # MAPE 계산\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0d978e25-5ff0-4b71-b0a2-38017ca8d3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 230130 entries, 0 to 230129\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   id        230130 non-null  int64  \n",
      " 1   date      230130 non-null  object \n",
      " 2   country   230130 non-null  object \n",
      " 3   store     230130 non-null  object \n",
      " 4   product   230130 non-null  object \n",
      " 5   num_sold  221259 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 10.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767934a6-8f3e-4b6d-a081-e72d5b8fc558",
   "metadata": {},
   "source": [
    "<div style=\"background-color:red; padding:10px; border-radius:10px; font-size:18px;\">\n",
    "(시도 1)<br><br>\n",
    "군집별 EDA 결과에 기반한 순서인코딩<br>\n",
    "결측치 0 처리\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecad6746-c436-41f8-a640-eb68d5f10574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>mapped_weekday</th>\n",
       "      <th>mapped_month</th>\n",
       "      <th>mapped_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  store  product  mapped_weekday  mapped_month  mapped_year\n",
       "0        3      0        0               1             4            3\n",
       "1        3      0        4               1             4            3\n",
       "2        3      0        3               1             4            3\n",
       "3        3      0        1               1             4            3\n",
       "4        3      0        2               1             4            3"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------------------------------------데이터 전처리\n",
    "\n",
    "# 날짜 파생 변수 생성\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "train['year'] = train['date'].dt.year\n",
    "train['month'] = train['date'].dt.month\n",
    "train['weekday'] = train['date'].dt.weekday\n",
    "\n",
    "# 결측치 처리\n",
    "train['num_sold'] = train['num_sold'].fillna(0)\n",
    "\n",
    "# ------------------------------------------------------------------ 라벨 인코딩\n",
    "\n",
    "country_mapping = {\n",
    "    'Kenya': 0,\n",
    "    'Italy': 1,\n",
    "    'Finland': 2,\n",
    "    'Canada': 3,\n",
    "    'Singapore': 4,\n",
    "    'Norway': 5}\n",
    "train['country'] = train['country'].map(country_mapping)\n",
    "\n",
    "\n",
    "store_mapping = {\n",
    "    'Discount Stickers' : 0,\n",
    "    'Stickers for Less' : 1,\n",
    "    'Premium Sticker Mart' : 2}\n",
    "train['store'] = train['store'].map(store_mapping)\n",
    "\n",
    "\n",
    "product_mapping = {\n",
    "    'Holographic Goose' : 0,\n",
    "    'Kerneler' : 1,\n",
    "    'Kerneler Dark Mode' : 2,\n",
    "    'Kaggle Tiers' : 3,\n",
    "    'Kaggle' : 4}\n",
    "train['product'] = train['product'].map(product_mapping)\n",
    "\n",
    "# (월,화,수,목 = 0) (금 = 1) (토 = 2) (일 = 3)\n",
    "weekday_mapping = {\n",
    "    0 : 0,\n",
    "    1 : 0,\n",
    "    2 : 0,\n",
    "    3 : 0,\n",
    "    4 : 1,\n",
    "    5 : 2,\n",
    "    6 : 3}\n",
    "train['mapped_weekday'] = train['weekday'].map(weekday_mapping)\n",
    "\n",
    "# 월별 매핑\n",
    "month_mapping = {\n",
    "    2: 1, 5: 1, 4: 1, 3: 1,   # 2, 5, 4, 3월 = 1\n",
    "    9: 2, 10: 2,              # 9, 10월      = 2\n",
    "    6: 3, 7: 3, 8: 3,         # 6, 7, 8월    = 3\n",
    "    1: 4, 11: 4,              # 1, 11월      = 4\n",
    "    12: 5}                    # 12월         = 5\n",
    "train['mapped_month'] = train['month'].map(month_mapping)   \n",
    "\n",
    "# 연도별 배핑\n",
    "year_mapping = {\n",
    "    2011: 1, 2013: 1,                  # 2011년, 2013년 = 1\n",
    "    2012: 2, 2014: 2,                  # 2012년, 2014년 = 2\n",
    "    2010: 3, 2015: 3, 2016: 3}         # 2010년, 2015년, 2016년 = 3\n",
    "train['mapped_year'] = train['year'].map(year_mapping)\n",
    "\n",
    "# 타겟 추출\n",
    "y_df = train['num_sold']\n",
    "log_y_df = np.log1p(y_df)\n",
    "\n",
    "# 필요없는 변수 삭제\n",
    "train = train.drop(['num_sold', 'id', 'date', 'year', 'month', 'weekday'] , axis = 1)\n",
    "\n",
    "# 데이터 확인\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d097270-0c88-4584-abf2-c2c9249d91ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-24 19:53:24,465] A new study created in memory with name: no-name-4ffd1622-8b85-4535-ad46-3ab899096034\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   0%|                                                        | 0/50 [00:00<?, ?it/s][I 2025-01-24 19:53:25,721] Trial 0 finished with value: 21.54408635294019 and parameters: {'n_estimators': 101, 'learning_rate': 0.8490881556247726, 'max_depth': 12, 'subsample': 0.7540704240784426, 'colsample_bytree': 0.8575292010130573, 'min_child_weight': 7, 'gamma': 6.489393425358409, 'reg_alpha': 1.006086195746324, 'reg_lambda': 5.3226227983703165}. Best is trial 0 with value: 21.54408635294019.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   2%|▉                                               | 1/50 [00:01<01:01,  1.25s/it][I 2025-01-24 19:53:30,802] Trial 1 finished with value: 21.879739934126047 and parameters: {'n_estimators': 779, 'learning_rate': 0.7680385915487548, 'max_depth': 11, 'subsample': 0.7629356734842172, 'colsample_bytree': 0.989128314640833, 'min_child_weight': 8, 'gamma': 6.4375267578044575, 'reg_alpha': 6.491309220659872, 'reg_lambda': 1.9185186394251907}. Best is trial 0 with value: 21.54408635294019.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   4%|█▉                                              | 2/50 [00:06<02:48,  3.51s/it][I 2025-01-24 19:53:36,804] Trial 2 finished with value: 25.93517257367601 and parameters: {'n_estimators': 872, 'learning_rate': 0.18250695841012962, 'max_depth': 5, 'subsample': 0.7964269366297613, 'colsample_bytree': 0.9778277811433284, 'min_child_weight': 8, 'gamma': 8.309400717515224, 'reg_alpha': 6.592379183911186, 'reg_lambda': 2.538818882901107}. Best is trial 0 with value: 21.54408635294019.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   6%|██▉                                             | 3/50 [00:12<03:38,  4.65s/it][I 2025-01-24 19:53:41,001] Trial 3 finished with value: 31.379297932103135 and parameters: {'n_estimators': 582, 'learning_rate': 0.7513799670320304, 'max_depth': 8, 'subsample': 0.9439246742894779, 'colsample_bytree': 0.6540294353246652, 'min_child_weight': 7, 'gamma': 4.951995743824486, 'reg_alpha': 6.040407023692692, 'reg_lambda': 0.8152535089451063}. Best is trial 0 with value: 21.54408635294019.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   8%|███▊                                            | 4/50 [00:16<03:25,  4.47s/it][I 2025-01-24 19:53:47,399] Trial 4 finished with value: 28.819516218744514 and parameters: {'n_estimators': 988, 'learning_rate': 0.9799048626887797, 'max_depth': 4, 'subsample': 0.9771323281684756, 'colsample_bytree': 0.6910872533380914, 'min_child_weight': 8, 'gamma': 2.3446478732329865, 'reg_alpha': 2.2217043062823083, 'reg_lambda': 3.1921015366158247}. Best is trial 0 with value: 21.54408635294019.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  10%|████▊                                           | 5/50 [00:22<03:52,  5.16s/it][I 2025-01-24 19:53:53,888] Trial 5 finished with value: 23.823093178980468 and parameters: {'n_estimators': 975, 'learning_rate': 0.2850823392115417, 'max_depth': 12, 'subsample': 0.6893624679865286, 'colsample_bytree': 0.82323098618278, 'min_child_weight': 1, 'gamma': 7.9395739987058525, 'reg_alpha': 7.200432114464345, 'reg_lambda': 8.212999503550355}. Best is trial 0 with value: 21.54408635294019.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  12%|█████▊                                          | 6/50 [00:29<04:07,  5.61s/it][W 2025-01-24 19:53:54,878] Trial 6 failed with parameters: {'n_estimators': 399, 'learning_rate': 0.653969002091379, 'max_depth': 10, 'subsample': 0.8337647566716564, 'colsample_bytree': 0.5529709102425904, 'min_child_weight': 3, 'gamma': 6.0416598164784565, 'reg_alpha': 5.6091488993617595, 'reg_lambda': 7.526041924599426} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10204\\1838609157.py\", line 30, in objective\n",
      "    xgb_model.fit(x_train, y_train)\n",
      "  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1108, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 2101, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-01-24 19:53:54,880] Trial 6 failed with value None.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  12%|█████▊                                          | 6/50 [00:30<03:43,  5.07s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------- 데이터 학습 --------------------------------------------------------------\n",
    "\n",
    "# 목적함수 생성\n",
    "def objective(trial):\n",
    "    params = {\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 100, 1000),  # 트리 개수\n",
    "    'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),  # 학습률\n",
    "    'max_depth': trial.suggest_int('max_depth', 3, 15),  # 트리 최대 깊이\n",
    "    'subsample': trial.suggest_float('subsample', 0.5, 1.0),  # 샘플링 비율\n",
    "    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),  # 특성 샘플링 비율\n",
    "    'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),  # 리프 노드 최소 가중치\n",
    "    'gamma': trial.suggest_float('gamma', 0, 10),  # 최소 손실 감소\n",
    "    'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),  # L1 정규화\n",
    "    'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),  # L2 정규화\n",
    "    \"tree_method\": \"hist\",  # 트리 방법\n",
    "    \"device\": \"cuda\",       # GPU 사용\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    'random_state': 1\n",
    "}\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    xgb_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(train):\n",
    "        x_train, x_val = train.iloc[train_index], train.iloc[val_index]\n",
    "        y_train, y_val = log_y_df[train_index], log_y_df[val_index]\n",
    "\n",
    "        # XGBoost 모델 생성\n",
    "        xgb_model = xgb.XGBRegressor(**params)\n",
    "        xgb_model.fit(x_train, y_train)\n",
    "\n",
    "        # 예측 및 RMSLE 계산\n",
    "        y_pred = np.exp(xgb_model.predict(x_val))\n",
    "        mape = mean_absolute_percentage_error(np.exp(y_val), y_pred)\n",
    "        xgb_scores.append(mape)\n",
    "\n",
    "    return np.mean(xgb_scores)\n",
    "\n",
    "# Optuna 하이퍼파라미터 최적화\n",
    "n_trials = 50\n",
    "xgb_study = optuna.create_study(direction='minimize')\n",
    "\n",
    "for _ in tqdm(range(n_trials), desc='XGBoost 하이퍼파라미터 튜닝 중...'):\n",
    "    xgb_study.optimize(objective, n_trials=1, catch=(Exception,))\n",
    "\n",
    "print('최고의 MAPE값', xgb_study.best_value, '\\n')\n",
    "print('최고의 하이퍼 파라미터', xgb_study.best_params, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9131ab1-7c18-4fa3-8691-4513ee40587a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:red; padding:10px; border-radius:10px; font-size:18px;\">\n",
    "(시도 2)<br><br>\n",
    "군집별 EDA 결과에 기반한 순서인코딩<br>\n",
    "결측치 0 처리<br>\n",
    "주기성이 있는 sin,cos 파생변수 추가\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a799f822-ae30-4d46-8d5b-d1352a160f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>year_sin</th>\n",
       "      <th>year_cos</th>\n",
       "      <th>group</th>\n",
       "      <th>mapped_weekday</th>\n",
       "      <th>mapped_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  store  product  year  month  weekday  day  day_of_week  \\\n",
       "0        3      0        0  2010      1        4    1            4   \n",
       "1        3      0        4  2010      1        4    1            4   \n",
       "2        3      0        3  2010      1        4    1            4   \n",
       "3        3      0        1  2010      1        4    1            4   \n",
       "4        3      0        2  2010      1        4    1            4   \n",
       "\n",
       "   week_of_year   day_sin   day_cos  month_sin  month_cos  year_sin  year_cos  \\\n",
       "0            53  0.017213  0.999852        0.5   0.866025  0.781831   0.62349   \n",
       "1            53  0.017213  0.999852        0.5   0.866025  0.781831   0.62349   \n",
       "2            53  0.017213  0.999852        0.5   0.866025  0.781831   0.62349   \n",
       "3            53  0.017213  0.999852        0.5   0.866025  0.781831   0.62349   \n",
       "4            53  0.017213  0.999852        0.5   0.866025  0.781831   0.62349   \n",
       "\n",
       "   group  mapped_weekday  mapped_month  \n",
       "0      4               1             4  \n",
       "1      4               1             4  \n",
       "2      4               1             4  \n",
       "3      4               1             4  \n",
       "4      4               1             4  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "train.head()\n",
    "\n",
    "# -------------------------------------------------------------데이터 전처리\n",
    "\n",
    "# 날짜 파생 변수 생성\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "train['year'] = train['date'].dt.year\n",
    "train['month'] = train['date'].dt.month\n",
    "train['weekday'] = train['date'].dt.weekday\n",
    "train['day'] = train['date'].dt.day\n",
    "train['day_of_week'] = train['date'].dt.dayofweek\n",
    "train['week_of_year'] = train['date'].dt.isocalendar().week\n",
    "train['day_sin'] = np.sin(2 * np.pi * train['day'] / 365)\n",
    "train['day_cos'] = np.cos(2 * np.pi * train['day'] / 365)\n",
    "train['month_sin'] = np.sin(2 * np.pi * train['month'] / 12)\n",
    "train['month_cos'] = np.cos(2 * np.pi * train['month'] / 12)\n",
    "train['year_sin'] = np.sin(2 * np.pi * train['year'] / 7)\n",
    "train['year_cos'] = np.cos(2 * np.pi * train['year'] / 7)\n",
    "\n",
    "train['group'] = (train['year'] - 2010) * 48 + train['month'] * 4 + train['day'] // 7\n",
    "\n",
    "# 결측치 처리\n",
    "train['num_sold'] = train['num_sold'].fillna(0)\n",
    "\n",
    "# ------------------------------------------------------------------ 인코딩\n",
    "\n",
    "country_mapping = {\n",
    "    'Kenya': 0,\n",
    "    'Italy': 1,\n",
    "    'Finland': 2,\n",
    "    'Canada': 3,\n",
    "    'Singapore': 4,\n",
    "    'Norway': 5}\n",
    "train['country'] = train['country'].map(country_mapping)\n",
    "\n",
    "\n",
    "store_mapping = {\n",
    "    'Discount Stickers' : 0,\n",
    "    'Stickers for Less' : 1,\n",
    "    'Premium Sticker Mart' : 2}\n",
    "train['store'] = train['store'].map(store_mapping)\n",
    "\n",
    "\n",
    "product_mapping = {\n",
    "    'Holographic Goose' : 0,\n",
    "    'Kerneler' : 1,\n",
    "    'Kerneler Dark Mode' : 2,\n",
    "    'Kaggle Tiers' : 3,\n",
    "    'Kaggle' : 4}\n",
    "train['product'] = train['product'].map(product_mapping)\n",
    "\n",
    "\n",
    "weekday_mapping = {\n",
    "    0 : 0,\n",
    "    1 : 0,\n",
    "    2 : 0,\n",
    "    3 : 0,\n",
    "    4 : 1,\n",
    "    5 : 2,\n",
    "    6 : 3}\n",
    "train['mapped_weekday'] = train['weekday'].map(weekday_mapping)\n",
    "\n",
    "# 월별 매핑\n",
    "month_mapping = {\n",
    "    2: 1, 5: 1, 4: 1, 3: 1,   \n",
    "    9: 2, 10: 2,              \n",
    "    6: 3, 7: 3, 8: 3,         \n",
    "    1: 4, 11: 4,              \n",
    "    12: 5}                     \n",
    "train['mapped_month'] = train['month'].map(month_mapping)   \n",
    "\n",
    "# 연도별 배핑\n",
    "'''\n",
    "year_mapping = {\n",
    "    2011: 1, 2013: 1,  # 2011년, 2013년 → 1\n",
    "    2012: 2, 2014: 2,  # 2012년, 2014년 → 2\n",
    "    2010: 3, 2015: 3, 2016: 3} # 2010년, 2015년, 2016년 → 3\n",
    "train['mapped_year'] = train['year'].map(year_mapping)\n",
    "'''\n",
    "\n",
    "# 반응변수 추출\n",
    "y_df = train['num_sold']\n",
    "log_y_df = np.log1p(y_df)\n",
    "\n",
    "# 필요없는 변수 삭제\n",
    "train = train.drop(['num_sold', 'id', 'date'] , axis = 1)\n",
    "\n",
    "# 데이터 확인\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275e74a5-b518-4914-9ea4-40ebbd84866a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-24 20:25:49,296] A new study created in memory with name: no-name-d801565a-947f-4b32-951e-4ac6dfabee86\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   0%|                                                        | 0/50 [00:00<?, ?it/s][I 2025-01-24 20:25:51,916] Trial 0 finished with value: 0.1607399713412205 and parameters: {'n_estimators': 149, 'learning_rate': 0.19887163176090053, 'max_depth': 9, 'subsample': 0.6338867977164484, 'colsample_bytree': 0.7287118860671196, 'min_child_weight': 3, 'gamma': 2.530482807013661, 'reg_alpha': 0.9802881609257974, 'reg_lambda': 4.942301059828006}. Best is trial 0 with value: 0.1607399713412205.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   2%|▉                                               | 1/50 [00:02<02:08,  2.62s/it][I 2025-01-24 20:25:57,371] Trial 1 finished with value: 0.14697701104906188 and parameters: {'n_estimators': 631, 'learning_rate': 0.2632910812803494, 'max_depth': 13, 'subsample': 0.8871662332622847, 'colsample_bytree': 0.9642591715952652, 'min_child_weight': 8, 'gamma': 1.5475073699848962, 'reg_alpha': 0.6074178580428158, 'reg_lambda': 8.052525989519348}. Best is trial 1 with value: 0.14697701104906188.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   4%|█▉                                              | 2/50 [00:08<03:25,  4.29s/it][I 2025-01-24 20:26:05,160] Trial 2 finished with value: 0.17335945910502557 and parameters: {'n_estimators': 989, 'learning_rate': 0.17273634067819926, 'max_depth': 15, 'subsample': 0.8795098883167446, 'colsample_bytree': 0.7365403909861807, 'min_child_weight': 2, 'gamma': 9.971978178902955, 'reg_alpha': 7.0094942827427, 'reg_lambda': 7.368386308430505}. Best is trial 1 with value: 0.14697701104906188.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   6%|██▉                                             | 3/50 [00:15<04:36,  5.89s/it][I 2025-01-24 20:26:11,359] Trial 3 finished with value: 0.1736535060920785 and parameters: {'n_estimators': 755, 'learning_rate': 0.7585669939856496, 'max_depth': 10, 'subsample': 0.5298713597409168, 'colsample_bytree': 0.9939132447996801, 'min_child_weight': 7, 'gamma': 2.5099224581589974, 'reg_alpha': 0.05517180110973796, 'reg_lambda': 0.5220055522765454}. Best is trial 1 with value: 0.14697701104906188.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   8%|███▊                                            | 4/50 [00:22<04:36,  6.01s/it][I 2025-01-24 20:26:17,817] Trial 4 finished with value: 0.18908228800836818 and parameters: {'n_estimators': 839, 'learning_rate': 0.5108057603001389, 'max_depth': 15, 'subsample': 0.5118513004724532, 'colsample_bytree': 0.7619398624601503, 'min_child_weight': 1, 'gamma': 6.324450384384638, 'reg_alpha': 9.754063670749604, 'reg_lambda': 1.535488336666675}. Best is trial 1 with value: 0.14697701104906188.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  10%|████▊                                           | 5/50 [00:28<04:37,  6.17s/it][I 2025-01-24 20:26:22,574] Trial 5 finished with value: 0.19609682455398791 and parameters: {'n_estimators': 596, 'learning_rate': 0.737220756479075, 'max_depth': 11, 'subsample': 0.7978929273039291, 'colsample_bytree': 0.6357900523618747, 'min_child_weight': 3, 'gamma': 5.214645623511159, 'reg_alpha': 4.710143684068373, 'reg_lambda': 0.4808222764657788}. Best is trial 1 with value: 0.14697701104906188.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  12%|█████▊                                          | 6/50 [00:33<04:10,  5.69s/it][I 2025-01-24 20:26:29,687] Trial 6 finished with value: 0.14163431326486958 and parameters: {'n_estimators': 824, 'learning_rate': 0.2552932343746045, 'max_depth': 5, 'subsample': 0.7645802190622504, 'colsample_bytree': 0.9664844528856114, 'min_child_weight': 4, 'gamma': 0.29318458745380527, 'reg_alpha': 3.0677178620916834, 'reg_lambda': 6.595130365430627}. Best is trial 6 with value: 0.14163431326486958.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  14%|██████▋                                         | 7/50 [00:40<04:24,  6.16s/it][I 2025-01-24 20:26:32,788] Trial 7 finished with value: 0.21061681210783498 and parameters: {'n_estimators': 201, 'learning_rate': 0.7070251535143935, 'max_depth': 11, 'subsample': 0.6960638369071617, 'colsample_bytree': 0.5695945346314587, 'min_child_weight': 9, 'gamma': 0.4499355602387012, 'reg_alpha': 5.235870869065739, 'reg_lambda': 9.281418750916977}. Best is trial 6 with value: 0.14163431326486958.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  16%|███████▋                                        | 8/50 [00:43<03:37,  5.18s/it][I 2025-01-24 20:26:39,713] Trial 8 finished with value: 0.16410789066376683 and parameters: {'n_estimators': 867, 'learning_rate': 0.1917369073196046, 'max_depth': 12, 'subsample': 0.7872154605698578, 'colsample_bytree': 0.6146033809913782, 'min_child_weight': 3, 'gamma': 4.44797102824416, 'reg_alpha': 8.03391346960934, 'reg_lambda': 8.06720655607331}. Best is trial 6 with value: 0.14163431326486958.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  18%|████████▋                                       | 9/50 [00:50<03:54,  5.73s/it][I 2025-01-24 20:26:44,524] Trial 9 finished with value: 0.1673632472374899 and parameters: {'n_estimators': 558, 'learning_rate': 0.2873428645145169, 'max_depth': 12, 'subsample': 0.6384515710467809, 'colsample_bytree': 0.7350579280215973, 'min_child_weight': 3, 'gamma': 3.4595891853726624, 'reg_alpha': 7.908294908277288, 'reg_lambda': 3.6145464114396484}. Best is trial 6 with value: 0.14163431326486958.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  20%|█████████▍                                     | 10/50 [00:55<03:37,  5.44s/it][I 2025-01-24 20:26:47,964] Trial 10 finished with value: 0.2514667142339837 and parameters: {'n_estimators': 401, 'learning_rate': 0.4304362219485086, 'max_depth': 4, 'subsample': 0.9959875639368414, 'colsample_bytree': 0.8823900193458842, 'min_child_weight': 5, 'gamma': 7.504510920518185, 'reg_alpha': 2.7708956435691725, 'reg_lambda': 5.7304906070032615}. Best is trial 6 with value: 0.14163431326486958.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  22%|██████████▎                                    | 11/50 [00:58<03:08,  4.83s/it][I 2025-01-24 20:26:57,623] Trial 11 finished with value: 0.2792493693362838 and parameters: {'n_estimators': 715, 'learning_rate': 0.010893673439432039, 'max_depth': 4, 'subsample': 0.9037477366688631, 'colsample_bytree': 0.9925584148236128, 'min_child_weight': 10, 'gamma': 0.4146839292649146, 'reg_alpha': 2.5120697923277686, 'reg_lambda': 6.807696547405698}. Best is trial 6 with value: 0.14163431326486958.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  24%|███████████▎                                   | 12/50 [01:08<03:59,  6.30s/it][I 2025-01-24 20:27:04,040] Trial 12 finished with value: 0.13514372092006305 and parameters: {'n_estimators': 328, 'learning_rate': 0.42640385116873303, 'max_depth': 6, 'subsample': 0.869884568647046, 'colsample_bytree': 0.8980966500101731, 'min_child_weight': 6, 'gamma': 0.03057507233707657, 'reg_alpha': 2.2040460240726696, 'reg_lambda': 9.366085551637351}. Best is trial 12 with value: 0.13514372092006305.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  26%|████████████▏                                  | 13/50 [01:14<03:54,  6.34s/it][I 2025-01-24 20:27:07,539] Trial 13 finished with value: 0.16785803469451305 and parameters: {'n_estimators': 401, 'learning_rate': 0.9472264066594575, 'max_depth': 7, 'subsample': 0.7487920757459723, 'colsample_bytree': 0.8757692921302815, 'min_child_weight': 5, 'gamma': 1.2305210522953534, 'reg_alpha': 3.0472215578656767, 'reg_lambda': 9.95923448636862}. Best is trial 12 with value: 0.13514372092006305.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  28%|█████████████▏                                 | 14/50 [01:18<03:17,  5.48s/it][I 2025-01-24 20:27:11,274] Trial 14 finished with value: 0.13956119841492626 and parameters: {'n_estimators': 335, 'learning_rate': 0.4381442738294387, 'max_depth': 6, 'subsample': 0.8362818549731575, 'colsample_bytree': 0.872980565495469, 'min_child_weight': 6, 'gamma': 0.16052929308440939, 'reg_alpha': 4.266104979540622, 'reg_lambda': 4.212198623523758}. Best is trial 12 with value: 0.13514372092006305.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  30%|██████████████                                 | 15/50 [01:21<02:53,  4.95s/it][I 2025-01-24 20:27:14,349] Trial 15 finished with value: 0.16053038321876362 and parameters: {'n_estimators': 340, 'learning_rate': 0.48715020598019254, 'max_depth': 7, 'subsample': 0.9908488761591705, 'colsample_bytree': 0.8581259726394672, 'min_child_weight': 7, 'gamma': 2.1999540149371093, 'reg_alpha': 4.973863607820343, 'reg_lambda': 3.42786234632484}. Best is trial 12 with value: 0.13514372092006305.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  32%|███████████████                                | 16/50 [01:25<02:29,  4.39s/it][I 2025-01-24 20:27:16,949] Trial 16 finished with value: 0.16996781969434108 and parameters: {'n_estimators': 268, 'learning_rate': 0.6026088849313479, 'max_depth': 7, 'subsample': 0.8411050229530821, 'colsample_bytree': 0.8118698443155428, 'min_child_weight': 6, 'gamma': 3.7848916024464607, 'reg_alpha': 1.680883886247718, 'reg_lambda': 3.6304990384199183}. Best is trial 12 with value: 0.13514372092006305.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  34%|███████████████▉                               | 17/50 [01:27<02:07,  3.85s/it][I 2025-01-24 20:27:20,939] Trial 17 finished with value: 0.1823427215410588 and parameters: {'n_estimators': 465, 'learning_rate': 0.43551038132988895, 'max_depth': 6, 'subsample': 0.9342686035978095, 'colsample_bytree': 0.9118179190998217, 'min_child_weight': 7, 'gamma': 8.396844703300552, 'reg_alpha': 4.157540933762969, 'reg_lambda': 5.120083497561264}. Best is trial 12 with value: 0.13514372092006305.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  36%|████████████████▉                              | 18/50 [01:31<02:04,  3.89s/it][I 2025-01-24 20:27:23,738] Trial 18 finished with value: 0.26617717260583595 and parameters: {'n_estimators': 270, 'learning_rate': 0.35918735611595176, 'max_depth': 3, 'subsample': 0.8480087975321247, 'colsample_bytree': 0.8095936694640894, 'min_child_weight': 6, 'gamma': 1.4062230620688263, 'reg_alpha': 6.563675630785598, 'reg_lambda': 2.2661747279596414}. Best is trial 12 with value: 0.13514372092006305.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  38%|█████████████████▊                             | 19/50 [01:34<01:50,  3.56s/it][I 2025-01-24 20:27:25,309] Trial 19 finished with value: 0.1697905912607724 and parameters: {'n_estimators': 109, 'learning_rate': 0.6200513631798367, 'max_depth': 8, 'subsample': 0.6967909082195043, 'colsample_bytree': 0.9356996514130622, 'min_child_weight': 8, 'gamma': 5.641229050688411, 'reg_alpha': 3.770519205581107, 'reg_lambda': 4.424193850120675}. Best is trial 12 with value: 0.13514372092006305.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  40%|██████████████████▊                            | 20/50 [01:36<01:28,  2.97s/it][I 2025-01-24 20:27:33,328] Trial 20 finished with value: 0.14714064654163223 and parameters: {'n_estimators': 481, 'learning_rate': 0.0777225960079227, 'max_depth': 5, 'subsample': 0.9523824980372233, 'colsample_bytree': 0.8170491187043948, 'min_child_weight': 5, 'gamma': 0.007623574815506504, 'reg_alpha': 1.6961556249116558, 'reg_lambda': 2.6001409650224767}. Best is trial 12 with value: 0.13514372092006305.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  42%|███████████████████▋                           | 21/50 [01:44<02:09,  4.48s/it][I 2025-01-24 20:27:36,320] Trial 21 finished with value: 0.17500743763997645 and parameters: {'n_estimators': 308, 'learning_rate': 0.37981703181208415, 'max_depth': 5, 'subsample': 0.8033306681755925, 'colsample_bytree': 0.9347330019853436, 'min_child_weight': 4, 'gamma': 0.8940629716960742, 'reg_alpha': 3.4002290940191395, 'reg_lambda': 6.244314802352062}. Best is trial 12 with value: 0.13514372092006305.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  44%|████████████████████▋                          | 22/50 [01:47<01:52,  4.04s/it][I 2025-01-24 20:27:40,485] Trial 22 finished with value: 0.16653279326317144 and parameters: {'n_estimators': 503, 'learning_rate': 0.3205969827108216, 'max_depth': 6, 'subsample': 0.7321260350612809, 'colsample_bytree': 0.9018449903257553, 'min_child_weight': 4, 'gamma': 1.9337889257246603, 'reg_alpha': 2.0434114766496236, 'reg_lambda': 8.714223632618117}. Best is trial 12 with value: 0.13514372092006305.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  46%|█████████████████████▌                         | 23/50 [01:51<01:49,  4.07s/it][I 2025-01-24 20:27:45,018] Trial 23 finished with value: 0.18789263645395704 and parameters: {'n_estimators': 383, 'learning_rate': 0.5681903529057247, 'max_depth': 3, 'subsample': 0.8325401787332561, 'colsample_bytree': 0.9525162980663198, 'min_child_weight': 6, 'gamma': 0.08840576086811565, 'reg_alpha': 5.985625970877924, 'reg_lambda': 6.990599819258289}. Best is trial 12 with value: 0.13514372092006305.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  48%|██████████████████████▌                        | 24/50 [01:55<01:49,  4.21s/it][I 2025-01-24 20:27:52,513] Trial 24 finished with value: 0.19898922141718092 and parameters: {'n_estimators': 995, 'learning_rate': 0.10941559214350838, 'max_depth': 5, 'subsample': 0.7801581884589753, 'colsample_bytree': 0.8505550172212295, 'min_child_weight': 4, 'gamma': 3.19641401585155, 'reg_alpha': 4.3986555609350635, 'reg_lambda': 5.984574122510391}. Best is trial 12 with value: 0.13514372092006305.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  50%|███████████████████████▌                       | 25/50 [02:03<02:09,  5.20s/it][I 2025-01-24 20:27:57,928] Trial 25 finished with value: 0.16742362922698512 and parameters: {'n_estimators': 689, 'learning_rate': 0.4242080837293056, 'max_depth': 8, 'subsample': 0.7069591126747734, 'colsample_bytree': 0.6900790302822246, 'min_child_weight': 8, 'gamma': 0.9380185926939025, 'reg_alpha': 3.5336337445555657, 'reg_lambda': 9.853796015489252}. Best is trial 12 with value: 0.13514372092006305.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  52%|████████████████████████▍                      | 26/50 [02:08<02:06,  5.26s/it][I 2025-01-24 20:28:00,382] Trial 26 finished with value: 0.20065024145528612 and parameters: {'n_estimators': 210, 'learning_rate': 0.2599553629156823, 'max_depth': 6, 'subsample': 0.6512179127758041, 'colsample_bytree': 0.5088458004502028, 'min_child_weight': 5, 'gamma': 2.927649811833593, 'reg_alpha': 2.2819584159395645, 'reg_lambda': 7.84518473045915}. Best is trial 12 with value: 0.13514372092006305.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  54%|█████████████████████████▍                     | 27/50 [02:11<01:41,  4.42s/it][I 2025-01-24 20:28:06,634] Trial 27 finished with value: 0.25181439612320605 and parameters: {'n_estimators': 852, 'learning_rate': 0.5100627135351217, 'max_depth': 4, 'subsample': 0.9294608871079961, 'colsample_bytree': 0.8312418620239459, 'min_child_weight': 6, 'gamma': 4.036578301512493, 'reg_alpha': 1.1039182268646508, 'reg_lambda': 8.94676187881548}. Best is trial 12 with value: 0.13514372092006305.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  56%|██████████████████████████▎                    | 28/50 [02:17<01:49,  4.97s/it][I 2025-01-24 20:28:10,351] Trial 28 finished with value: 0.16997793230123628 and parameters: {'n_estimators': 430, 'learning_rate': 0.8326202015544466, 'max_depth': 8, 'subsample': 0.8593113408584963, 'colsample_bytree': 0.9167795968891436, 'min_child_weight': 4, 'gamma': 1.7526707409809261, 'reg_alpha': 5.68600622834682, 'reg_lambda': 4.289023986282968}. Best is trial 12 with value: 0.13514372092006305.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  58%|███████████████████████████▎                   | 29/50 [02:21<01:36,  4.59s/it][I 2025-01-24 20:28:12,632] Trial 29 finished with value: 0.16264459980807536 and parameters: {'n_estimators': 170, 'learning_rate': 0.3434242767025761, 'max_depth': 6, 'subsample': 0.5968297088511856, 'colsample_bytree': 0.786543034438239, 'min_child_weight': 2, 'gamma': 0.8268253396082248, 'reg_alpha': 1.1900659663408315, 'reg_lambda': 5.208797756379572}. Best is trial 12 with value: 0.13514372092006305.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  60%|████████████████████████████▏                  | 30/50 [02:23<01:17,  3.90s/it][I 2025-01-24 20:28:19,587] Trial 30 finished with value: 0.19179151813387552 and parameters: {'n_estimators': 922, 'learning_rate': 0.2249852294891567, 'max_depth': 5, 'subsample': 0.757313571927177, 'colsample_bytree': 0.9718809769929706, 'min_child_weight': 7, 'gamma': 2.5375148122930957, 'reg_alpha': 4.014663485470961, 'reg_lambda': 6.3317191276230895}. Best is trial 12 with value: 0.13514372092006305.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  62%|█████████████████████████████▏                 | 31/50 [02:30<01:31,  4.82s/it][I 2025-01-24 20:28:25,798] Trial 31 finished with value: 0.14551903153797194 and parameters: {'n_estimators': 649, 'learning_rate': 0.14708459808931307, 'max_depth': 14, 'subsample': 0.8998831291682566, 'colsample_bytree': 0.9567613753155525, 'min_child_weight': 8, 'gamma': 1.5774419152103902, 'reg_alpha': 1.1465669083436323, 'reg_lambda': 8.408169098411289}. Best is trial 12 with value: 0.13514372092006305.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  64%|██████████████████████████████                 | 32/50 [02:36<01:34,  5.23s/it][I 2025-01-24 20:28:32,274] Trial 32 finished with value: 0.13227285541020345 and parameters: {'n_estimators': 652, 'learning_rate': 0.1286513841673141, 'max_depth': 9, 'subsample': 0.8182119980488091, 'colsample_bytree': 0.9610649696432964, 'min_child_weight': 9, 'gamma': 0.7197220226176467, 'reg_alpha': 0.11860166011485429, 'reg_lambda': 8.323547925892612}. Best is trial 32 with value: 0.13227285541020345.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  66%|███████████████████████████████                | 33/50 [02:42<01:35,  5.61s/it][I 2025-01-24 20:28:41,575] Trial 33 finished with value: 0.13145362994723192 and parameters: {'n_estimators': 757, 'learning_rate': 0.06412315981044295, 'max_depth': 9, 'subsample': 0.8684849404478191, 'colsample_bytree': 0.8900125991644868, 'min_child_weight': 10, 'gamma': 0.6040728038337957, 'reg_alpha': 0.12133745427308273, 'reg_lambda': 7.6751064623177365}. Best is trial 33 with value: 0.13145362994723192.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  68%|███████████████████████████████▉               | 34/50 [02:52<01:47,  6.72s/it][I 2025-01-24 20:28:53,548] Trial 34 finished with value: 0.13356175531674497 and parameters: {'n_estimators': 748, 'learning_rate': 0.029254622632340417, 'max_depth': 9, 'subsample': 0.8169988669434698, 'colsample_bytree': 0.8928857535667036, 'min_child_weight': 10, 'gamma': 0.9440085834993106, 'reg_alpha': 0.17120490922860976, 'reg_lambda': 7.597607408833273}. Best is trial 33 with value: 0.13145362994723192.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  70%|████████████████████████████████▉              | 35/50 [03:04<02:04,  8.29s/it][I 2025-01-24 20:29:12,811] Trial 35 finished with value: 0.13374945320649556 and parameters: {'n_estimators': 780, 'learning_rate': 0.014194684164420168, 'max_depth': 9, 'subsample': 0.8766685054465341, 'colsample_bytree': 0.8962222240222494, 'min_child_weight': 10, 'gamma': 1.0170358649012812, 'reg_alpha': 0.3973481835356242, 'reg_lambda': 7.556750190975205}. Best is trial 33 with value: 0.13145362994723192.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  72%|█████████████████████████████████▊             | 36/50 [03:23<02:42, 11.58s/it][I 2025-01-24 20:29:32,763] Trial 36 finished with value: 0.1375000644023608 and parameters: {'n_estimators': 777, 'learning_rate': 0.010543152004342757, 'max_depth': 9, 'subsample': 0.8148200423026055, 'colsample_bytree': 0.9979786465181709, 'min_child_weight': 10, 'gamma': 2.3493852565964444, 'reg_alpha': 0.056853860634554776, 'reg_lambda': 7.374643681228536}. Best is trial 33 with value: 0.13145362994723192.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  74%|██████████████████████████████████▊            | 37/50 [03:43<03:03, 14.09s/it][I 2025-01-24 20:29:41,055] Trial 37 finished with value: 0.13826082070154508 and parameters: {'n_estimators': 777, 'learning_rate': 0.07236698944329403, 'max_depth': 10, 'subsample': 0.8903542257843919, 'colsample_bytree': 0.7769441843808798, 'min_child_weight': 9, 'gamma': 1.1161534205606378, 'reg_alpha': 0.5419406011270219, 'reg_lambda': 7.515384048734952}. Best is trial 33 with value: 0.13145362994723192.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  76%|███████████████████████████████████▋           | 38/50 [03:51<02:28, 12.35s/it][I 2025-01-24 20:29:47,139] Trial 38 finished with value: 0.14035161914280883 and parameters: {'n_estimators': 639, 'learning_rate': 0.1277067152584308, 'max_depth': 10, 'subsample': 0.9601369909638549, 'colsample_bytree': 0.8468370502834032, 'min_child_weight': 9, 'gamma': 1.9833406112234018, 'reg_alpha': 0.4224663577867998, 'reg_lambda': 7.913522000152425}. Best is trial 33 with value: 0.13145362994723192.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  78%|████████████████████████████████████▋          | 39/50 [03:57<01:55, 10.47s/it][I 2025-01-24 20:29:56,551] Trial 39 finished with value: 0.14021058339762937 and parameters: {'n_estimators': 922, 'learning_rate': 0.04962305732579152, 'max_depth': 9, 'subsample': 0.9189308132271093, 'colsample_bytree': 0.9366629800520365, 'min_child_weight': 10, 'gamma': 2.7275232357161676, 'reg_alpha': 0.07627909014485525, 'reg_lambda': 8.227131631175135}. Best is trial 33 with value: 0.13145362994723192.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  80%|█████████████████████████████████████▌         | 40/50 [04:07<01:41, 10.15s/it][I 2025-01-24 20:30:02,465] Trial 40 finished with value: 0.1514760619107111 and parameters: {'n_estimators': 732, 'learning_rate': 0.21589115100744327, 'max_depth': 11, 'subsample': 0.8713279877863284, 'colsample_bytree': 0.9747379030076443, 'min_child_weight': 9, 'gamma': 6.746145564413595, 'reg_alpha': 0.8420070494011388, 'reg_lambda': 7.287254905265395}. Best is trial 33 with value: 0.13145362994723192.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  82%|██████████████████████████████████████▌        | 41/50 [04:13<01:19,  8.88s/it][I 2025-01-24 20:30:08,907] Trial 41 finished with value: 0.13418749850157793 and parameters: {'n_estimators': 680, 'learning_rate': 0.16682427421947676, 'max_depth': 9, 'subsample': 0.8159932236717006, 'colsample_bytree': 0.8956896076806778, 'min_child_weight': 10, 'gamma': 0.6618315856254404, 'reg_alpha': 0.6336217909896414, 'reg_lambda': 9.340569072022507}. Best is trial 33 with value: 0.13145362994723192.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  84%|███████████████████████████████████████▍       | 42/50 [04:19<01:05,  8.15s/it][I 2025-01-24 20:30:14,484] Trial 42 finished with value: 0.13540061833753397 and parameters: {'n_estimators': 584, 'learning_rate': 0.15983222001167632, 'max_depth': 9, 'subsample': 0.7898748307999075, 'colsample_bytree': 0.8909417199980453, 'min_child_weight': 10, 'gamma': 0.6740650962551304, 'reg_alpha': 0.5662360664240309, 'reg_lambda': 9.241293622646207}. Best is trial 33 with value: 0.13145362994723192.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  86%|████████████████████████████████████████▍      | 43/50 [04:25<00:51,  7.38s/it][I 2025-01-24 20:30:21,272] Trial 43 finished with value: 0.13761803052914073 and parameters: {'n_estimators': 681, 'learning_rate': 0.10340819743421834, 'max_depth': 10, 'subsample': 0.8204512996907276, 'colsample_bytree': 0.9198566079588386, 'min_child_weight': 10, 'gamma': 1.3878129464626978, 'reg_alpha': 1.6434620727994487, 'reg_lambda': 8.598570619703112}. Best is trial 33 with value: 0.13145362994723192.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  88%|█████████████████████████████████████████▎     | 44/50 [04:31<00:43,  7.20s/it][I 2025-01-24 20:30:33,459] Trial 44 finished with value: 0.13712555073513766 and parameters: {'n_estimators': 800, 'learning_rate': 0.041980504098934446, 'max_depth': 11, 'subsample': 0.87547059793393, 'colsample_bytree': 0.8696836387595595, 'min_child_weight': 9, 'gamma': 0.68036965438213, 'reg_alpha': 0.08239292610518616, 'reg_lambda': 7.641020250884083}. Best is trial 33 with value: 0.13145362994723192.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  90%|██████████████████████████████████████████▎    | 45/50 [04:44<00:43,  8.70s/it][I 2025-01-24 20:30:39,720] Trial 45 finished with value: 0.15227824785429592 and parameters: {'n_estimators': 740, 'learning_rate': 0.19530500631176462, 'max_depth': 8, 'subsample': 0.7720744955564188, 'colsample_bytree': 0.6886538018468489, 'min_child_weight': 10, 'gamma': 1.654614900379404, 'reg_alpha': 1.340186343727508, 'reg_lambda': 9.508890337361793}. Best is trial 33 with value: 0.13145362994723192.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  92%|███████████████████████████████████████████▏   | 46/50 [04:50<00:31,  7.97s/it][I 2025-01-24 20:30:47,225] Trial 46 finished with value: 0.13621645399226295 and parameters: {'n_estimators': 604, 'learning_rate': 0.10003350315770693, 'max_depth': 12, 'subsample': 0.8132782050239477, 'colsample_bytree': 0.944537553313696, 'min_child_weight': 9, 'gamma': 0.5459401049844241, 'reg_alpha': 0.6938261700226974, 'reg_lambda': 8.922730959470874}. Best is trial 33 with value: 0.13145362994723192.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  94%|████████████████████████████████████████████▏  | 47/50 [04:57<00:23,  7.83s/it][I 2025-01-24 20:30:54,296] Trial 47 finished with value: 0.15375468733205003 and parameters: {'n_estimators': 891, 'learning_rate': 0.16375338018769475, 'max_depth': 10, 'subsample': 0.721060300139064, 'colsample_bytree': 0.8913909894654413, 'min_child_weight': 10, 'gamma': 9.03812314123062, 'reg_alpha': 0.40670505844479243, 'reg_lambda': 0.023953538683219477}. Best is trial 33 with value: 0.13145362994723192.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  96%|█████████████████████████████████████████████  | 48/50 [05:04<00:15,  7.60s/it][I 2025-01-24 20:31:03,066] Trial 48 finished with value: 0.13662348579488756 and parameters: {'n_estimators': 677, 'learning_rate': 0.047579109646840534, 'max_depth': 9, 'subsample': 0.8555635607258386, 'colsample_bytree': 0.8426256726539475, 'min_child_weight': 8, 'gamma': 1.1480056237806044, 'reg_alpha': 0.8814965861373893, 'reg_lambda': 6.840119822580434}. Best is trial 33 with value: 0.13145362994723192.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  98%|██████████████████████████████████████████████ | 49/50 [05:13<00:07,  7.95s/it][I 2025-01-24 20:31:19,037] Trial 49 finished with value: 0.13761472572021455 and parameters: {'n_estimators': 540, 'learning_rate': 0.01300177247703561, 'max_depth': 9, 'subsample': 0.9022635360003227, 'colsample_bytree': 0.9847792629369525, 'min_child_weight': 10, 'gamma': 2.151917363162469, 'reg_alpha': 0.0020581171494105654, 'reg_lambda': 8.356523308328343}. Best is trial 33 with value: 0.13145362994723192.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...: 100%|███████████████████████████████████████████████| 50/50 [05:29<00:00,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최고의 MAPE값 0.13145362994723192 \n",
      "\n",
      "최고의 하이퍼 파라미터 {'n_estimators': 757, 'learning_rate': 0.06412315981044295, 'max_depth': 9, 'subsample': 0.8684849404478191, 'colsample_bytree': 0.8900125991644868, 'min_child_weight': 10, 'gamma': 0.6040728038337957, 'reg_alpha': 0.12133745427308273, 'reg_lambda': 7.6751064623177365} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------- 데이터 학습 --------------------------------------------------------------\n",
    "\n",
    "# 목적함수 생성\n",
    "def objective(trial):\n",
    "    params = {\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 100, 1000),  # 트리 개수\n",
    "    'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),  # 학습률\n",
    "    'max_depth': trial.suggest_int('max_depth', 3, 15),  # 트리 최대 깊이\n",
    "    'subsample': trial.suggest_float('subsample', 0.5, 1.0),  # 샘플링 비율\n",
    "    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),  # 특성 샘플링 비율\n",
    "    'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),  # 리프 노드 최소 가중치\n",
    "    'gamma': trial.suggest_float('gamma', 0, 10),  # 최소 손실 감소\n",
    "    'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),  # L1 정규화\n",
    "    'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),  # L2 정규화\n",
    "    \"tree_method\": \"hist\",  # 트리 방법\n",
    "    \"device\": \"cuda\",       # GPU 사용\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    'random_state': 1\n",
    "}\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    xgb_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(train):\n",
    "        x_train, x_val = train.iloc[train_index], train.iloc[val_index]\n",
    "        y_train, y_val = log_y_df[train_index], log_y_df[val_index]\n",
    "\n",
    "        # XGBoost 모델 생성\n",
    "        xgb_model = xgb.XGBRegressor(**params)\n",
    "        xgb_model.fit(x_train, y_train)\n",
    "\n",
    "        # 예측 및 RMSLE 계산\n",
    "        y_pred = np.exp(xgb_model.predict(x_val))\n",
    "        mape = mean_absolute_percentage_error(np.exp(y_val), y_pred)\n",
    "        xgb_scores.append(mape)\n",
    "\n",
    "    return np.mean(xgb_scores)\n",
    "\n",
    "# Optuna 하이퍼파라미터 최적화\n",
    "n_trials = 50\n",
    "xgb_study = optuna.create_study(direction='minimize')\n",
    "\n",
    "for _ in tqdm(range(n_trials), desc='XGBoost 하이퍼파라미터 튜닝 중...'):\n",
    "    xgb_study.optimize(objective, n_trials=1, catch=(Exception,))\n",
    "\n",
    "print('최고의 MAPE값', xgb_study.best_value, '\\n')\n",
    "print('최고의 하이퍼 파라미터', xgb_study.best_params, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a323aa07-697f-42a6-bed3-f9b956bb2920",
   "metadata": {},
   "source": [
    "<div style=\"background-color:red; padding:10px; border-radius:10px; font-size:18px;\">\n",
    "(시도 3)<br><br>\n",
    "군집별 EDA 결과에 기반한 순서인코딩<br>\n",
    "결측치 0 처리<br>\n",
    "주기성이 있는 sin,cos 파생변수 추가<br>\n",
    "year, month, weekday 그대로 넣고 학습\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647b2638-3c59-44e7-a205-72a93e020e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-24 20:31:38,359] A new study created in memory with name: no-name-5f90f144-af29-4207-90a3-973171991212\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   0%|                                                        | 0/50 [00:00<?, ?it/s][I 2025-01-24 20:31:44,066] Trial 0 finished with value: 0.1701659961940587 and parameters: {'n_estimators': 701, 'learning_rate': 0.5359521500211163, 'max_depth': 12, 'subsample': 0.5475767889900958, 'colsample_bytree': 0.8462444999474408, 'min_child_weight': 1, 'gamma': 7.2363235842289075, 'reg_alpha': 1.2612769114378641, 'reg_lambda': 4.761880797713878}. Best is trial 0 with value: 0.1701659961940587.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   2%|▉                                               | 1/50 [00:05<04:39,  5.71s/it][I 2025-01-24 20:31:49,652] Trial 1 finished with value: 0.1893251389258657 and parameters: {'n_estimators': 717, 'learning_rate': 0.9807250289327208, 'max_depth': 14, 'subsample': 0.6486081641606851, 'colsample_bytree': 0.9508855020430376, 'min_child_weight': 3, 'gamma': 1.9627491593323876, 'reg_alpha': 0.8394859488589357, 'reg_lambda': 6.992870021672379}. Best is trial 0 with value: 0.1701659961940587.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   4%|█▉                                              | 2/50 [00:11<04:30,  5.64s/it][I 2025-01-24 20:31:54,131] Trial 2 finished with value: 0.1590565419669831 and parameters: {'n_estimators': 559, 'learning_rate': 0.496160052842717, 'max_depth': 14, 'subsample': 0.9737999100049136, 'colsample_bytree': 0.7533840456414218, 'min_child_weight': 10, 'gamma': 3.6299586702292066, 'reg_alpha': 5.328162051091711, 'reg_lambda': 8.882805217951567}. Best is trial 2 with value: 0.1590565419669831.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   6%|██▉                                             | 3/50 [00:15<04:00,  5.11s/it][I 2025-01-24 20:31:57,307] Trial 3 finished with value: 0.27870516565217063 and parameters: {'n_estimators': 290, 'learning_rate': 0.1114110836925458, 'max_depth': 4, 'subsample': 0.8088098598666758, 'colsample_bytree': 0.7003402752734147, 'min_child_weight': 9, 'gamma': 7.46912880202363, 'reg_alpha': 6.2543790637902505, 'reg_lambda': 0.2527130902702257}. Best is trial 2 with value: 0.1590565419669831.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   8%|███▊                                            | 4/50 [00:18<03:19,  4.34s/it][I 2025-01-24 20:32:00,583] Trial 4 finished with value: 0.1508051179227743 and parameters: {'n_estimators': 299, 'learning_rate': 0.1739465003457975, 'max_depth': 10, 'subsample': 0.9106584372853809, 'colsample_bytree': 0.9122037424393934, 'min_child_weight': 8, 'gamma': 8.442942057400076, 'reg_alpha': 7.588363475640979, 'reg_lambda': 6.6475495209205215}. Best is trial 4 with value: 0.1508051179227743.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  10%|████▊                                           | 5/50 [00:22<02:58,  3.96s/it][I 2025-01-24 20:32:04,793] Trial 5 finished with value: 0.2117007253730852 and parameters: {'n_estimators': 489, 'learning_rate': 0.30408678058232436, 'max_depth': 4, 'subsample': 0.9908502510755259, 'colsample_bytree': 0.717436492878551, 'min_child_weight': 10, 'gamma': 0.2358071416463392, 'reg_alpha': 6.731076084128399, 'reg_lambda': 8.953501428281537}. Best is trial 4 with value: 0.1508051179227743.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  12%|█████▊                                          | 6/50 [00:26<02:57,  4.04s/it][I 2025-01-24 20:32:08,504] Trial 6 finished with value: 0.2097520044388505 and parameters: {'n_estimators': 418, 'learning_rate': 0.2844409799329339, 'max_depth': 5, 'subsample': 0.7257015108313243, 'colsample_bytree': 0.9772054838846457, 'min_child_weight': 2, 'gamma': 6.396749242831446, 'reg_alpha': 8.25368905676778, 'reg_lambda': 2.639504146673305}. Best is trial 4 with value: 0.1508051179227743.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  14%|██████▋                                         | 7/50 [00:30<02:49,  3.94s/it][I 2025-01-24 20:32:14,476] Trial 7 finished with value: 0.1929338339706497 and parameters: {'n_estimators': 796, 'learning_rate': 0.4623895473366595, 'max_depth': 6, 'subsample': 0.9360823454407263, 'colsample_bytree': 0.7864972069519285, 'min_child_weight': 6, 'gamma': 8.070726299051262, 'reg_alpha': 2.8039459965601576, 'reg_lambda': 6.156712318461097}. Best is trial 4 with value: 0.1508051179227743.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  16%|███████▋                                        | 8/50 [00:36<03:12,  4.58s/it][I 2025-01-24 20:32:20,975] Trial 8 finished with value: 0.1819038224411285 and parameters: {'n_estimators': 847, 'learning_rate': 0.6135494497334977, 'max_depth': 7, 'subsample': 0.9046722591845118, 'colsample_bytree': 0.6259396116077403, 'min_child_weight': 4, 'gamma': 4.381447512755562, 'reg_alpha': 5.448197950743435, 'reg_lambda': 0.8048967622373038}. Best is trial 4 with value: 0.1508051179227743.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  18%|████████▋                                       | 9/50 [00:42<03:32,  5.18s/it][I 2025-01-24 20:32:22,629] Trial 9 finished with value: 0.18274122944422597 and parameters: {'n_estimators': 113, 'learning_rate': 0.8120843976045554, 'max_depth': 13, 'subsample': 0.7465914288747995, 'colsample_bytree': 0.7587417739157485, 'min_child_weight': 5, 'gamma': 5.583794393300292, 'reg_alpha': 1.1379581310907394, 'reg_lambda': 8.952533200932805}. Best is trial 4 with value: 0.1508051179227743.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  20%|█████████▍                                     | 10/50 [00:44<02:43,  4.09s/it][I 2025-01-24 20:32:25,467] Trial 10 finished with value: 0.18098019173000277 and parameters: {'n_estimators': 141, 'learning_rate': 0.09896291960478998, 'max_depth': 10, 'subsample': 0.8441440075554194, 'colsample_bytree': 0.5467494237025994, 'min_child_weight': 7, 'gamma': 9.655804369888374, 'reg_alpha': 9.822023118552348, 'reg_lambda': 3.9022289760479683}. Best is trial 4 with value: 0.1508051179227743.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  22%|██████████▎                                    | 11/50 [00:47<02:24,  3.71s/it][I 2025-01-24 20:32:30,446] Trial 11 finished with value: 0.1466360693586528 and parameters: {'n_estimators': 601, 'learning_rate': 0.3089439968391876, 'max_depth': 10, 'subsample': 0.9921565970573567, 'colsample_bytree': 0.8730397854371469, 'min_child_weight': 8, 'gamma': 3.6932172294582797, 'reg_alpha': 4.0048827716666375, 'reg_lambda': 7.393100671039813}. Best is trial 11 with value: 0.1466360693586528.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  24%|███████████▎                                   | 12/50 [00:52<02:35,  4.10s/it][I 2025-01-24 20:32:33,593] Trial 12 finished with value: 0.14317116333358287 and parameters: {'n_estimators': 300, 'learning_rate': 0.28647515219609104, 'max_depth': 9, 'subsample': 0.865734953923208, 'colsample_bytree': 0.8952362033257453, 'min_child_weight': 8, 'gamma': 3.2099375485204633, 'reg_alpha': 3.1342598908182335, 'reg_lambda': 7.04021496267964}. Best is trial 12 with value: 0.14317116333358287.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  26%|████████████▏                                  | 13/50 [00:55<02:20,  3.81s/it][I 2025-01-24 20:32:40,917] Trial 13 finished with value: 0.144827161370564 and parameters: {'n_estimators': 966, 'learning_rate': 0.3268457980773134, 'max_depth': 9, 'subsample': 0.8451608466720466, 'colsample_bytree': 0.8707577213235709, 'min_child_weight': 8, 'gamma': 3.275706199193445, 'reg_alpha': 3.566503935122637, 'reg_lambda': 7.657998176041998}. Best is trial 12 with value: 0.14317116333358287.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  28%|█████████████▏                                 | 14/50 [01:02<02:55,  4.87s/it][I 2025-01-24 20:32:47,908] Trial 14 finished with value: 0.1512995466157643 and parameters: {'n_estimators': 916, 'learning_rate': 0.3942989465450547, 'max_depth': 8, 'subsample': 0.8175887721894209, 'colsample_bytree': 0.8401108319761514, 'min_child_weight': 7, 'gamma': 1.7486092611997504, 'reg_alpha': 3.2118559966634193, 'reg_lambda': 7.828574995856914}. Best is trial 12 with value: 0.14317116333358287.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  30%|██████████████                                 | 15/50 [01:09<03:12,  5.51s/it][I 2025-01-24 20:32:50,938] Trial 15 finished with value: 0.15557488477721776 and parameters: {'n_estimators': 324, 'learning_rate': 0.6664388084581053, 'max_depth': 8, 'subsample': 0.6534771613353639, 'colsample_bytree': 0.9995691343601829, 'min_child_weight': 6, 'gamma': 2.314929848754468, 'reg_alpha': 2.3626539618276894, 'reg_lambda': 9.991396118216095}. Best is trial 12 with value: 0.14317116333358287.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  32%|███████████████                                | 16/50 [01:12<02:41,  4.76s/it][I 2025-01-24 20:33:10,795] Trial 16 finished with value: 0.13583881211314322 and parameters: {'n_estimators': 988, 'learning_rate': 0.022359197201823833, 'max_depth': 12, 'subsample': 0.8611019920912498, 'colsample_bytree': 0.9003466295694983, 'min_child_weight': 8, 'gamma': 0.4888614424786475, 'reg_alpha': 4.024300211252428, 'reg_lambda': 5.341731435524077}. Best is trial 16 with value: 0.13583881211314322.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  34%|███████████████▉                               | 17/50 [01:32<05:06,  9.30s/it][I 2025-01-24 20:33:19,245] Trial 17 finished with value: 0.13514056587609974 and parameters: {'n_estimators': 215, 'learning_rate': 0.061947188417488884, 'max_depth': 12, 'subsample': 0.861544181010857, 'colsample_bytree': 0.9200337179461149, 'min_child_weight': 9, 'gamma': 0.16789217343256746, 'reg_alpha': 4.3577389867737875, 'reg_lambda': 5.447931261869952}. Best is trial 17 with value: 0.13514056587609974.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  36%|████████████████▉                              | 18/50 [01:40<04:49,  9.05s/it][I 2025-01-24 20:33:46,859] Trial 18 finished with value: 0.13336090661660277 and parameters: {'n_estimators': 639, 'learning_rate': 0.015149295481368799, 'max_depth': 12, 'subsample': 0.778718025339186, 'colsample_bytree': 0.9305671609737894, 'min_child_weight': 9, 'gamma': 0.20922413982856392, 'reg_alpha': 4.57773549716846, 'reg_lambda': 5.405040386833778}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  38%|█████████████████▊                             | 19/50 [02:08<07:33, 14.62s/it][I 2025-01-24 20:34:12,074] Trial 19 finished with value: 0.14103780770011684 and parameters: {'n_estimators': 663, 'learning_rate': 0.01109740612887139, 'max_depth': 15, 'subsample': 0.6893952793214135, 'colsample_bytree': 0.8049593045608289, 'min_child_weight': 10, 'gamma': 0.923028610421975, 'reg_alpha': 4.544368708380664, 'reg_lambda': 3.1287415150608004}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  40%|██████████████████▊                            | 20/50 [02:33<08:54, 17.80s/it][I 2025-01-24 20:34:16,889] Trial 20 finished with value: 0.13806234702017128 and parameters: {'n_estimators': 466, 'learning_rate': 0.1939040167583479, 'max_depth': 11, 'subsample': 0.780868274224056, 'colsample_bytree': 0.9464703934478058, 'min_child_weight': 9, 'gamma': 1.039506050308181, 'reg_alpha': 6.042531751444722, 'reg_lambda': 5.468940161988833}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  42%|███████████████████▋                           | 21/50 [02:38<06:43, 13.90s/it][I 2025-01-24 20:35:26,817] Trial 21 finished with value: 0.1360919483577549 and parameters: {'n_estimators': 997, 'learning_rate': 0.017359017389095847, 'max_depth': 12, 'subsample': 0.885112875843563, 'colsample_bytree': 0.926427668024902, 'min_child_weight': 9, 'gamma': 0.0056304847962000415, 'reg_alpha': 4.435498047896539, 'reg_lambda': 4.880320075020815}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  44%|████████████████████▋                          | 22/50 [03:48<14:20, 30.72s/it][I 2025-01-24 20:35:35,031] Trial 22 finished with value: 0.14268294060290568 and parameters: {'n_estimators': 789, 'learning_rate': 0.10201814748688383, 'max_depth': 12, 'subsample': 0.7729445968466323, 'colsample_bytree': 0.8202891721622181, 'min_child_weight': 7, 'gamma': 1.05701507096738, 'reg_alpha': 2.178695107719612, 'reg_lambda': 4.065036594407979}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  46%|█████████████████████▌                         | 23/50 [03:56<10:47, 23.97s/it][I 2025-01-24 20:35:38,290] Trial 23 finished with value: 0.14469675236266002 and parameters: {'n_estimators': 210, 'learning_rate': 0.16247584381238075, 'max_depth': 13, 'subsample': 0.8003499176693802, 'colsample_bytree': 0.9559751001781875, 'min_child_weight': 9, 'gamma': 2.414733616321184, 'reg_alpha': 4.892680065984516, 'reg_lambda': 5.732930285896019}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  48%|██████████████████████▌                        | 24/50 [03:59<07:41, 17.75s/it][I 2025-01-24 20:35:49,757] Trial 24 finished with value: 0.13472271581855155 and parameters: {'n_estimators': 411, 'learning_rate': 0.032496814545234766, 'max_depth': 11, 'subsample': 0.9349978080293829, 'colsample_bytree': 0.9030656640905981, 'min_child_weight': 10, 'gamma': 0.5273618578129099, 'reg_alpha': 4.021905694462595, 'reg_lambda': 2.2177684234473793}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  50%|███████████████████████▌                       | 25/50 [04:11<06:36, 15.87s/it][I 2025-01-24 20:35:55,540] Trial 25 finished with value: 0.13964491970717402 and parameters: {'n_estimators': 406, 'learning_rate': 0.09005168566342071, 'max_depth': 11, 'subsample': 0.949165568580678, 'colsample_bytree': 0.9976823927209322, 'min_child_weight': 10, 'gamma': 1.5674271968821945, 'reg_alpha': 1.7562483285950234, 'reg_lambda': 1.9748039660011214}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  52%|████████████████████████▍                      | 26/50 [04:17<05:08, 12.84s/it][I 2025-01-24 20:35:58,554] Trial 26 finished with value: 0.16637669110144904 and parameters: {'n_estimators': 228, 'learning_rate': 0.21911948909709933, 'max_depth': 15, 'subsample': 0.5627792339630877, 'colsample_bytree': 0.5098753408335689, 'min_child_weight': 9, 'gamma': 2.7313749701386114, 'reg_alpha': 6.977373552256951, 'reg_lambda': 3.778400511035516}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  54%|█████████████████████████▍                     | 27/50 [04:20<03:47,  9.89s/it][I 2025-01-24 20:36:08,500] Trial 27 finished with value: 0.1469850136927613 and parameters: {'n_estimators': 380, 'learning_rate': 0.22299101424984336, 'max_depth': 11, 'subsample': 0.9321452094378407, 'colsample_bytree': 0.8686419768511172, 'min_child_weight': 10, 'gamma': 0.01916484185438322, 'reg_alpha': 0.25878093403425595, 'reg_lambda': 1.5795722455910628}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  56%|██████████████████████████▎                    | 28/50 [04:30<03:37,  9.91s/it][I 2025-01-24 20:36:14,336] Trial 28 finished with value: 0.15798518202259437 and parameters: {'n_estimators': 510, 'learning_rate': 0.08160581049516485, 'max_depth': 13, 'subsample': 0.7168642217182429, 'colsample_bytree': 0.6350770108767783, 'min_child_weight': 5, 'gamma': 4.6778884898815525, 'reg_alpha': 5.587404754704487, 'reg_lambda': 3.1702943159416086}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  58%|███████████████████████████▎                   | 29/50 [04:35<03:02,  8.69s/it][I 2025-01-24 20:36:19,513] Trial 29 finished with value: 0.17191588298908284 and parameters: {'n_estimators': 614, 'learning_rate': 0.409828789555427, 'max_depth': 14, 'subsample': 0.519287743677039, 'colsample_bytree': 0.8396364493070424, 'min_child_weight': 1, 'gamma': 1.3296481577199468, 'reg_alpha': 3.948892814348836, 'reg_lambda': 4.532452293671677}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  60%|████████████████████████████▏                  | 30/50 [04:41<02:32,  7.63s/it][I 2025-01-24 20:36:21,892] Trial 30 finished with value: 0.14330095350060573 and parameters: {'n_estimators': 187, 'learning_rate': 0.5792266252914378, 'max_depth': 11, 'subsample': 0.8908554811423562, 'colsample_bytree': 0.9272146840880587, 'min_child_weight': 7, 'gamma': 0.8162028195604784, 'reg_alpha': 4.692624761558373, 'reg_lambda': 1.9097814247539089}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  62%|█████████████████████████████▏                 | 31/50 [04:43<01:55,  6.06s/it][I 2025-01-24 20:36:37,885] Trial 31 finished with value: 0.13773881679035532 and parameters: {'n_estimators': 699, 'learning_rate': 0.024158729175135292, 'max_depth': 12, 'subsample': 0.8476543681403499, 'colsample_bytree': 0.8833190198710812, 'min_child_weight': 9, 'gamma': 0.6328009501726645, 'reg_alpha': 3.8742597510383643, 'reg_lambda': 5.418154808155657}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  64%|██████████████████████████████                 | 32/50 [04:59<02:42,  9.04s/it][I 2025-01-24 20:36:49,513] Trial 32 finished with value: 0.1396684560171304 and parameters: {'n_estimators': 875, 'learning_rate': 0.059714081538466725, 'max_depth': 13, 'subsample': 0.8687231002571918, 'colsample_bytree': 0.9100004621444039, 'min_child_weight': 8, 'gamma': 0.48820137579373807, 'reg_alpha': 2.7582927760339224, 'reg_lambda': 6.360174771223725}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  66%|███████████████████████████████                | 33/50 [05:11<02:46,  9.81s/it][I 2025-01-24 20:36:56,342] Trial 33 finished with value: 0.1435435452946417 and parameters: {'n_estimators': 748, 'learning_rate': 0.14802167563877594, 'max_depth': 12, 'subsample': 0.9629702735437001, 'colsample_bytree': 0.9613985377043963, 'min_child_weight': 10, 'gamma': 1.7102494575873899, 'reg_alpha': 4.939082045827945, 'reg_lambda': 4.815551614439469}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  68%|███████████████████████████████▉               | 34/50 [05:17<02:22,  8.92s/it][I 2025-01-24 20:37:00,740] Trial 34 finished with value: 0.17615615424478573 and parameters: {'n_estimators': 534, 'learning_rate': 0.7504824941179358, 'max_depth': 14, 'subsample': 0.8180458469563323, 'colsample_bytree': 0.9420144872983698, 'min_child_weight': 9, 'gamma': 2.1170178907895973, 'reg_alpha': 5.860153744513909, 'reg_lambda': 5.95736938780142}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  70%|████████████████████████████████▉              | 35/50 [05:22<01:53,  7.56s/it][I 2025-01-24 20:37:10,605] Trial 35 finished with value: 0.18183308856351152 and parameters: {'n_estimators': 245, 'learning_rate': 0.9055413523563923, 'max_depth': 10, 'subsample': 0.9191062641417003, 'colsample_bytree': 0.900036588295605, 'min_child_weight': 8, 'gamma': 0.006582969611163503, 'reg_alpha': 4.231562684741004, 'reg_lambda': 4.365019822551795}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  72%|█████████████████████████████████▊             | 36/50 [05:32<01:55,  8.25s/it][I 2025-01-24 20:37:15,192] Trial 36 finished with value: 0.14506868716309568 and parameters: {'n_estimators': 360, 'learning_rate': 0.1416708173877172, 'max_depth': 14, 'subsample': 0.7608343371517364, 'colsample_bytree': 0.7883918149754076, 'min_child_weight': 10, 'gamma': 1.4084819975444232, 'reg_alpha': 3.5851069256491206, 'reg_lambda': 5.239894202031123}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  74%|██████████████████████████████████▊            | 37/50 [05:36<01:32,  7.15s/it][I 2025-01-24 20:37:20,960] Trial 37 finished with value: 0.13637425201097916 and parameters: {'n_estimators': 628, 'learning_rate': 0.23669030474216696, 'max_depth': 12, 'subsample': 0.8201142157767094, 'colsample_bytree': 0.8464264184550471, 'min_child_weight': 9, 'gamma': 0.5717815217134296, 'reg_alpha': 6.525292440971681, 'reg_lambda': 3.4206938751892912}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  76%|███████████████████████████████████▋           | 38/50 [05:42<01:20,  6.74s/it][I 2025-01-24 20:37:25,715] Trial 38 finished with value: 0.30064161547898544 and parameters: {'n_estimators': 452, 'learning_rate': 0.07759476344297726, 'max_depth': 3, 'subsample': 0.6070887333367017, 'colsample_bytree': 0.9721734033260097, 'min_child_weight': 10, 'gamma': 2.799018179411256, 'reg_alpha': 5.238576313235955, 'reg_lambda': 8.252048331847455}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  78%|████████████████████████████████████▋          | 39/50 [05:47<01:07,  6.14s/it][I 2025-01-24 20:37:31,609] Trial 39 finished with value: 0.14792198293810288 and parameters: {'n_estimators': 166, 'learning_rate': 0.03837769247925099, 'max_depth': 11, 'subsample': 0.9676546518923695, 'colsample_bytree': 0.9243395264580435, 'min_child_weight': 8, 'gamma': 3.8900033037006843, 'reg_alpha': 2.035440918107671, 'reg_lambda': 6.766133810526844}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  80%|█████████████████████████████████████▌         | 40/50 [05:53<01:00,  6.07s/it][I 2025-01-24 20:37:35,027] Trial 40 finished with value: 0.15867791581333682 and parameters: {'n_estimators': 267, 'learning_rate': 0.18385547686157105, 'max_depth': 13, 'subsample': 0.7882512694062636, 'colsample_bytree': 0.7058972859285201, 'min_child_weight': 3, 'gamma': 5.525816650901035, 'reg_alpha': 7.438099831950673, 'reg_lambda': 0.07125223420268867}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  82%|██████████████████████████████████████▌        | 41/50 [05:56<00:47,  5.27s/it][I 2025-01-24 20:38:05,042] Trial 41 finished with value: 0.1340514083472398 and parameters: {'n_estimators': 969, 'learning_rate': 0.01486608348944975, 'max_depth': 12, 'subsample': 0.8904020235978631, 'colsample_bytree': 0.9258745033522437, 'min_child_weight': 9, 'gamma': 0.26792083134347067, 'reg_alpha': 4.543997313205952, 'reg_lambda': 6.334885249761142}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  84%|███████████████████████████████████████▍       | 42/50 [06:26<01:41, 12.70s/it][I 2025-01-24 20:38:14,079] Trial 42 finished with value: 0.1376514515233388 and parameters: {'n_estimators': 934, 'learning_rate': 0.12989623137916495, 'max_depth': 12, 'subsample': 0.9092317451500493, 'colsample_bytree': 0.8578542867764963, 'min_child_weight': 9, 'gamma': 0.558408737181006, 'reg_alpha': 3.3412480018112474, 'reg_lambda': 6.313912540295612}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  86%|████████████████████████████████████████▍      | 43/50 [06:35<01:21, 11.60s/it][I 2025-01-24 20:38:23,961] Trial 43 finished with value: 0.13533938540276305 and parameters: {'n_estimators': 911, 'learning_rate': 0.05686344178231562, 'max_depth': 10, 'subsample': 0.8683017221724108, 'colsample_bytree': 0.8978149355525341, 'min_child_weight': 10, 'gamma': 1.251676234301356, 'reg_alpha': 4.373480988467178, 'reg_lambda': 5.789175754251751}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  88%|█████████████████████████████████████████▎     | 44/50 [06:45<01:06, 11.08s/it][I 2025-01-24 20:38:33,312] Trial 44 finished with value: 0.13493818063425703 and parameters: {'n_estimators': 908, 'learning_rate': 0.06929328560934492, 'max_depth': 10, 'subsample': 0.8890408242682851, 'colsample_bytree': 0.9831631116086145, 'min_child_weight': 10, 'gamma': 1.2877792861040993, 'reg_alpha': 5.257197522920352, 'reg_lambda': 7.1223979415460965}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  90%|██████████████████████████████████████████▎    | 45/50 [06:54<00:52, 10.56s/it][I 2025-01-24 20:38:40,564] Trial 45 finished with value: 0.14961452972792985 and parameters: {'n_estimators': 875, 'learning_rate': 0.12495248719189221, 'max_depth': 9, 'subsample': 0.9998497020120536, 'colsample_bytree': 0.9791840459350568, 'min_child_weight': 9, 'gamma': 6.9595787803195215, 'reg_alpha': 5.345340811393986, 'reg_lambda': 7.212304477823327}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  92%|███████████████████████████████████████████▏   | 46/50 [07:02<00:38,  9.57s/it][I 2025-01-24 20:38:46,764] Trial 46 finished with value: 0.14015078068910883 and parameters: {'n_estimators': 765, 'learning_rate': 0.2553212078115014, 'max_depth': 8, 'subsample': 0.93777268214628, 'colsample_bytree': 0.9861354595665801, 'min_child_weight': 10, 'gamma': 1.7626305920268424, 'reg_alpha': 6.295630005175722, 'reg_lambda': 6.592372736878716}. Best is trial 18 with value: 0.13336090661660277.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  94%|████████████████████████████████████████████▏  | 47/50 [07:08<00:25,  8.56s/it][I 2025-01-24 20:38:56,717] Trial 47 finished with value: 0.13010926745131102 and parameters: {'n_estimators': 835, 'learning_rate': 0.06945289620317992, 'max_depth': 10, 'subsample': 0.8976739184327465, 'colsample_bytree': 0.9380242683737381, 'min_child_weight': 10, 'gamma': 0.276292006511761, 'reg_alpha': 9.162146954425516, 'reg_lambda': 8.296086782509244}. Best is trial 47 with value: 0.13010926745131102.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  96%|█████████████████████████████████████████████  | 48/50 [07:18<00:17,  8.98s/it][I 2025-01-24 20:39:03,192] Trial 48 finished with value: 0.1406202115044854 and parameters: {'n_estimators': 820, 'learning_rate': 0.3440062550190827, 'max_depth': 10, 'subsample': 0.8945138166242292, 'colsample_bytree': 0.9439200292865901, 'min_child_weight': 10, 'gamma': 2.0478252122270924, 'reg_alpha': 8.15303009661768, 'reg_lambda': 8.405912974014287}. Best is trial 47 with value: 0.13010926745131102.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  98%|██████████████████████████████████████████████ | 49/50 [07:24<00:08,  8.23s/it][I 2025-01-24 20:39:08,812] Trial 49 finished with value: 0.14828651225434877 and parameters: {'n_estimators': 574, 'learning_rate': 0.11423139981249422, 'max_depth': 7, 'subsample': 0.9222029213181338, 'colsample_bytree': 0.753758213701206, 'min_child_weight': 10, 'gamma': 0.8734064349080672, 'reg_alpha': 9.719037257108964, 'reg_lambda': 9.450259754792487}. Best is trial 47 with value: 0.13010926745131102.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...: 100%|███████████████████████████████████████████████| 50/50 [07:30<00:00,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최고의 MAPE값 0.13010926745131102 \n",
      "\n",
      "최고의 하이퍼 파라미터 {'n_estimators': 835, 'learning_rate': 0.06945289620317992, 'max_depth': 10, 'subsample': 0.8976739184327465, 'colsample_bytree': 0.9380242683737381, 'min_child_weight': 10, 'gamma': 0.276292006511761, 'reg_alpha': 9.162146954425516, 'reg_lambda': 8.296086782509244} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------year, month, weekday 그대로 넣고 학습 ---------------------------------------------------\n",
    "\n",
    "# ----------------------------------------------------- 데이터 학습 --------------------------------------------------------------\n",
    "\n",
    "# 목적함수 생성\n",
    "def objective(trial):\n",
    "    params = {\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 100, 1000),  # 트리 개수\n",
    "    'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),  # 학습률\n",
    "    'max_depth': trial.suggest_int('max_depth', 3, 15),  # 트리 최대 깊이\n",
    "    'subsample': trial.suggest_float('subsample', 0.5, 1.0),  # 샘플링 비율\n",
    "    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),  # 특성 샘플링 비율\n",
    "    'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),  # 리프 노드 최소 가중치\n",
    "    'gamma': trial.suggest_float('gamma', 0, 10),  # 최소 손실 감소\n",
    "    'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),  # L1 정규화\n",
    "    'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),  # L2 정규화\n",
    "    \"tree_method\": \"hist\",  # 트리 방법\n",
    "    \"device\": \"cuda\",       # GPU 사용\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    'random_state': 1\n",
    "}\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    xgb_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(train):\n",
    "        x_train, x_val = train.iloc[train_index], train.iloc[val_index]\n",
    "        y_train, y_val = log_y_df[train_index], log_y_df[val_index]\n",
    "\n",
    "        # XGBoost 모델 생성\n",
    "        xgb_model = xgb.XGBRegressor(**params)\n",
    "        xgb_model.fit(x_train, y_train)\n",
    "\n",
    "        # 예측 및 RMSLE 계산\n",
    "        y_pred = np.exp(xgb_model.predict(x_val))\n",
    "        mape = mean_absolute_percentage_error(np.exp(y_val), y_pred)\n",
    "        xgb_scores.append(mape)\n",
    "\n",
    "    return np.mean(xgb_scores)\n",
    "\n",
    "# Optuna 하이퍼파라미터 최적화\n",
    "n_trials = 50\n",
    "xgb_study = optuna.create_study(direction='minimize')\n",
    "\n",
    "for _ in tqdm(range(n_trials), desc='XGBoost 하이퍼파라미터 튜닝 중...'):\n",
    "    xgb_study.optimize(objective, n_trials=1, catch=(Exception,))\n",
    "\n",
    "print('최고의 MAPE값', xgb_study.best_value, '\\n')\n",
    "print('최고의 하이퍼 파라미터', xgb_study.best_params, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fed770-1543-45ea-b0bf-b0fdbcad323b",
   "metadata": {},
   "source": [
    "<div style=\"background-color:red; padding:10px; border-radius:10px; font-size:18px;\">\n",
    "(시도 4)<br><br>\n",
    "군집별 EDA 결과에 기반한 순서인코딩<br>\n",
    "주기성이 있는 sin,cos 파생변수 추가<br>\n",
    "year, month, weekday 그대로 넣고 학습<br>\n",
    "결측치 존재하는 케이스 제외\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02556831-e1ae-40d0-8763-7cbc9f69f22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>year_sin</th>\n",
       "      <th>year_cos</th>\n",
       "      <th>group</th>\n",
       "      <th>mapped_weekday</th>\n",
       "      <th>mapped_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  country  store  product  year  month  weekday  day  day_of_week  \\\n",
       "0      1        3      0        4  2010      1        4    1            4   \n",
       "1      2        3      0        3  2010      1        4    1            4   \n",
       "2      3        3      0        1  2010      1        4    1            4   \n",
       "3      4        3      0        2  2010      1        4    1            4   \n",
       "4      5        3      1        0  2010      1        4    1            4   \n",
       "\n",
       "   week_of_year   day_sin   day_cos  month_sin  month_cos  year_sin  year_cos  \\\n",
       "0            53  0.017213  0.999852        0.5   0.866025  0.781831   0.62349   \n",
       "1            53  0.017213  0.999852        0.5   0.866025  0.781831   0.62349   \n",
       "2            53  0.017213  0.999852        0.5   0.866025  0.781831   0.62349   \n",
       "3            53  0.017213  0.999852        0.5   0.866025  0.781831   0.62349   \n",
       "4            53  0.017213  0.999852        0.5   0.866025  0.781831   0.62349   \n",
       "\n",
       "   group  mapped_weekday  mapped_month  \n",
       "0      4               1             4  \n",
       "1      4               1             4  \n",
       "2      4               1             4  \n",
       "3      4               1             4  \n",
       "4      4               1             4  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# =================================================================================================================================\n",
    "# ==================================================== 결측치 제외한 데이터 프레임 ==================================================\n",
    "# =================================================================================================================================\n",
    "\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "train = train.dropna()\n",
    "train = train.reset_index()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------데이터 전처리\n",
    "\n",
    "# 날짜 파생 변수 생성\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "train['year'] = train['date'].dt.year\n",
    "train['month'] = train['date'].dt.month\n",
    "train['weekday'] = train['date'].dt.weekday\n",
    "train['day'] = train['date'].dt.day\n",
    "train['day_of_week'] = train['date'].dt.dayofweek\n",
    "train['week_of_year'] = train['date'].dt.isocalendar().week\n",
    "train['day_sin'] = np.sin(2 * np.pi * train['day'] / 365)\n",
    "train['day_cos'] = np.cos(2 * np.pi * train['day'] / 365)\n",
    "train['month_sin'] = np.sin(2 * np.pi * train['month'] / 12)\n",
    "train['month_cos'] = np.cos(2 * np.pi * train['month'] / 12)\n",
    "train['year_sin'] = np.sin(2 * np.pi * train['year'] / 7)\n",
    "train['year_cos'] = np.cos(2 * np.pi * train['year'] / 7)\n",
    "\n",
    "train['group'] = (train['year'] - 2010) * 48 + train['month'] * 4 + train['day'] // 7\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------ 인코딩\n",
    "\n",
    "country_mapping = {\n",
    "    'Kenya': 0,\n",
    "    'Italy': 1,\n",
    "    'Finland': 2,\n",
    "    'Canada': 3,\n",
    "    'Singapore': 4,\n",
    "    'Norway': 5}\n",
    "train['country'] = train['country'].map(country_mapping)\n",
    "\n",
    "\n",
    "store_mapping = {\n",
    "    'Discount Stickers' : 0,\n",
    "    'Stickers for Less' : 1,\n",
    "    'Premium Sticker Mart' : 2}\n",
    "train['store'] = train['store'].map(store_mapping)\n",
    "\n",
    "\n",
    "product_mapping = {\n",
    "    'Holographic Goose' : 0,\n",
    "    'Kerneler' : 1,\n",
    "    'Kerneler Dark Mode' : 2,\n",
    "    'Kaggle Tiers' : 3,\n",
    "    'Kaggle' : 4}\n",
    "train['product'] = train['product'].map(product_mapping)\n",
    "\n",
    "weekday_mapping = {\n",
    "    0 : 0,\n",
    "    1 : 0,\n",
    "    2 : 0,\n",
    "    3 : 0,\n",
    "    4 : 1,\n",
    "    5 : 2,\n",
    "    6 : 3}\n",
    "train['mapped_weekday'] = train['weekday'].map(weekday_mapping)\n",
    "\n",
    "# 월별 매핑\n",
    "month_mapping = {\n",
    "    2: 1, 5: 1, 4: 1, 3: 1,   \n",
    "    9: 2, 10: 2,              \n",
    "    6: 3, 7: 3, 8: 3,         \n",
    "    1: 4, 11: 4,             \n",
    "    12: 5}                     \n",
    "train['mapped_month'] = train['month'].map(month_mapping)   \n",
    "\n",
    "# 연도별 배핑\n",
    "'''\n",
    "year_mapping = {\n",
    "    2011: 1, 2013: 1,  # 2011년, 2013년 → 1\n",
    "    2012: 2, 2014: 2,  # 2012년, 2014년 → 2\n",
    "    2010: 3, 2015: 3, 2016: 3} # 2010년, 2015년, 2016년 → 3\n",
    "train['mapped_year'] = train['year'].map(year_mapping)\n",
    "'''\n",
    "\n",
    "# 반응변수 추출\n",
    "y_df = train['num_sold']\n",
    "log_y_df = np.log1p(y_df)\n",
    "\n",
    "# 필요없는 변수 삭제\n",
    "train = train.drop(['num_sold', 'id', 'date'] , axis = 1)\n",
    "\n",
    "# 데이터 확인\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05f25a9f-8148-46b4-b5ef-fc69def8c124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-25 11:42:44,240] A new study created in memory with name: no-name-24fe02b2-0939-464f-853d-1fec68f3ed0b\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   0%|                                                        | 0/50 [00:00<?, ?it/s][I 2025-01-25 11:42:51,509] Trial 0 finished with value: 0.0663594307377248 and parameters: {'n_estimators': 983, 'learning_rate': 0.5206503819172389, 'max_depth': 8, 'subsample': 0.9842887515794022, 'colsample_bytree': 0.8250193402542779, 'min_child_weight': 3, 'gamma': 7.282712888425904, 'reg_alpha': 2.376035888114425, 'reg_lambda': 1.2374866636811899}. Best is trial 0 with value: 0.0663594307377248.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   2%|▉                                               | 1/50 [00:07<05:56,  7.27s/it][I 2025-01-25 11:42:57,513] Trial 1 finished with value: 0.08843722904928435 and parameters: {'n_estimators': 822, 'learning_rate': 0.8585533760375402, 'max_depth': 10, 'subsample': 0.599877162085646, 'colsample_bytree': 0.9440999772884135, 'min_child_weight': 10, 'gamma': 8.219095493416798, 'reg_alpha': 9.34098238491972, 'reg_lambda': 7.544840837471653}. Best is trial 0 with value: 0.0663594307377248.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   4%|█▉                                              | 2/50 [00:13<05:13,  6.52s/it][I 2025-01-25 11:43:04,169] Trial 2 finished with value: 0.07387936230090228 and parameters: {'n_estimators': 913, 'learning_rate': 0.8494987974138622, 'max_depth': 13, 'subsample': 0.9712374646838924, 'colsample_bytree': 0.7854426879584941, 'min_child_weight': 2, 'gamma': 4.192103476567369, 'reg_alpha': 1.4483712647920166, 'reg_lambda': 9.747648403146364}. Best is trial 0 with value: 0.0663594307377248.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   6%|██▉                                             | 3/50 [00:19<05:09,  6.58s/it][I 2025-01-25 11:43:10,460] Trial 3 finished with value: 0.06568259611844711 and parameters: {'n_estimators': 852, 'learning_rate': 0.48680280523150016, 'max_depth': 15, 'subsample': 0.8956487405724521, 'colsample_bytree': 0.663056079671162, 'min_child_weight': 5, 'gamma': 7.49613181432416, 'reg_alpha': 2.128049063672229, 'reg_lambda': 7.01984562441922}. Best is trial 3 with value: 0.06568259611844711.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   8%|███▊                                            | 4/50 [00:26<04:57,  6.47s/it][I 2025-01-25 11:43:16,353] Trial 4 finished with value: 0.048944344792231725 and parameters: {'n_estimators': 537, 'learning_rate': 0.11683367932220504, 'max_depth': 8, 'subsample': 0.523447438031795, 'colsample_bytree': 0.5644016780660495, 'min_child_weight': 6, 'gamma': 0.12178798059552465, 'reg_alpha': 8.28090966745332, 'reg_lambda': 6.851684985716238}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  10%|████▊                                           | 5/50 [00:32<04:41,  6.26s/it][I 2025-01-25 11:43:19,740] Trial 5 finished with value: 0.07762609235189849 and parameters: {'n_estimators': 400, 'learning_rate': 0.6560188962639334, 'max_depth': 9, 'subsample': 0.597273901882781, 'colsample_bytree': 0.9994973543462491, 'min_child_weight': 8, 'gamma': 8.734738850628478, 'reg_alpha': 6.637455931488238, 'reg_lambda': 0.02154322896337102}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  12%|█████▊                                          | 6/50 [00:35<03:52,  5.28s/it][I 2025-01-25 11:43:25,501] Trial 6 finished with value: 0.058400414812663226 and parameters: {'n_estimators': 741, 'learning_rate': 0.4144155013589176, 'max_depth': 8, 'subsample': 0.6128617564855889, 'colsample_bytree': 0.619995512010967, 'min_child_weight': 10, 'gamma': 1.628409094178478, 'reg_alpha': 6.488385160594753, 'reg_lambda': 2.6982483902260657}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  14%|██████▋                                         | 7/50 [00:41<03:53,  5.44s/it][I 2025-01-25 11:43:27,846] Trial 7 finished with value: 0.062408237948232706 and parameters: {'n_estimators': 186, 'learning_rate': 0.255313517641885, 'max_depth': 12, 'subsample': 0.6913484065165347, 'colsample_bytree': 0.7641998149227192, 'min_child_weight': 2, 'gamma': 4.582582977896143, 'reg_alpha': 9.690833913561185, 'reg_lambda': 0.8255812032800158}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  16%|███████▋                                        | 8/50 [00:43<03:07,  4.45s/it][I 2025-01-25 11:43:32,442] Trial 8 finished with value: 0.06162143768100166 and parameters: {'n_estimators': 572, 'learning_rate': 0.38166289987315216, 'max_depth': 15, 'subsample': 0.5681869369437995, 'colsample_bytree': 0.7855928891816172, 'min_child_weight': 6, 'gamma': 3.111728162377222, 'reg_alpha': 0.6188381307128377, 'reg_lambda': 0.4100509162412913}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  18%|████████▋                                       | 9/50 [00:48<03:04,  4.50s/it][I 2025-01-25 11:43:38,755] Trial 9 finished with value: 0.07584559781698062 and parameters: {'n_estimators': 865, 'learning_rate': 0.814595657738506, 'max_depth': 6, 'subsample': 0.5913550184974283, 'colsample_bytree': 0.6646975403546045, 'min_child_weight': 8, 'gamma': 5.176378560141041, 'reg_alpha': 2.7509173627325967, 'reg_lambda': 5.149166209919257}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  20%|█████████▍                                     | 10/50 [00:54<03:22,  5.06s/it][I 2025-01-25 11:43:43,803] Trial 10 finished with value: 0.06350762191161251 and parameters: {'n_estimators': 447, 'learning_rate': 0.06965582279993637, 'max_depth': 3, 'subsample': 0.7537190630867346, 'colsample_bytree': 0.5542870778593019, 'min_child_weight': 5, 'gamma': 0.14642993161844853, 'reg_alpha': 7.362195065111832, 'reg_lambda': 4.314440811208826}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  22%|██████████▎                                    | 11/50 [00:59<03:17,  5.06s/it][I 2025-01-25 11:43:55,865] Trial 11 finished with value: 0.051173021124955656 and parameters: {'n_estimators': 648, 'learning_rate': 0.016622349797351554, 'max_depth': 6, 'subsample': 0.5009229797743152, 'colsample_bytree': 0.5210087762597009, 'min_child_weight': 10, 'gamma': 0.11741759743502016, 'reg_alpha': 4.901318833005945, 'reg_lambda': 3.3618836521255706}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  24%|███████████▎                                   | 12/50 [01:11<04:33,  7.19s/it][I 2025-01-25 11:44:06,003] Trial 12 finished with value: 0.0784796463600396 and parameters: {'n_estimators': 624, 'learning_rate': 0.011715655052242459, 'max_depth': 5, 'subsample': 0.5057736672583756, 'colsample_bytree': 0.515281955835007, 'min_child_weight': 8, 'gamma': 0.06675213243935815, 'reg_alpha': 4.618786132991263, 'reg_lambda': 5.171257107671828}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  26%|████████████▏                                  | 13/50 [01:21<04:58,  8.08s/it][I 2025-01-25 11:44:09,521] Trial 13 finished with value: 0.05710232577174769 and parameters: {'n_estimators': 351, 'learning_rate': 0.19872645499999433, 'max_depth': 6, 'subsample': 0.5231391587796809, 'colsample_bytree': 0.5804643832780899, 'min_child_weight': 7, 'gamma': 1.8971650098394854, 'reg_alpha': 4.367475984335156, 'reg_lambda': 3.144135962651108}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  28%|█████████████▏                                 | 14/50 [01:25<04:01,  6.70s/it][I 2025-01-25 11:44:15,013] Trial 14 finished with value: 0.06841210400125214 and parameters: {'n_estimators': 679, 'learning_rate': 0.1561187875645026, 'max_depth': 3, 'subsample': 0.7199714033091626, 'colsample_bytree': 0.5074756246979482, 'min_child_weight': 4, 'gamma': 1.5395802214415384, 'reg_alpha': 7.827864925022075, 'reg_lambda': 7.096797325778226}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  30%|██████████████                                 | 15/50 [01:30<03:41,  6.34s/it][I 2025-01-25 11:44:19,235] Trial 15 finished with value: 0.05989936744610371 and parameters: {'n_estimators': 500, 'learning_rate': 0.293039478645268, 'max_depth': 5, 'subsample': 0.7981833591956209, 'colsample_bytree': 0.6747081921463849, 'min_child_weight': 9, 'gamma': 2.973512512389413, 'reg_alpha': 5.528764055901747, 'reg_lambda': 9.767671048505498}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  32%|███████████████                                | 16/50 [01:34<03:13,  5.70s/it][I 2025-01-25 11:44:22,891] Trial 16 finished with value: 0.051739804140752056 and parameters: {'n_estimators': 257, 'learning_rate': 0.13719215280558975, 'max_depth': 11, 'subsample': 0.6676521890462547, 'colsample_bytree': 0.5923306059265808, 'min_child_weight': 1, 'gamma': 0.7631668800305725, 'reg_alpha': 3.8307777437495485, 'reg_lambda': 5.959663035435966}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  34%|███████████████▉                               | 17/50 [01:38<02:47,  5.09s/it][I 2025-01-25 11:44:28,256] Trial 17 finished with value: 0.08079473147412312 and parameters: {'n_estimators': 711, 'learning_rate': 0.9974590376921644, 'max_depth': 7, 'subsample': 0.5106387340958257, 'colsample_bytree': 0.70388242811608, 'min_child_weight': 6, 'gamma': 2.8135771261434543, 'reg_alpha': 8.550237487783841, 'reg_lambda': 8.383577674785613}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  36%|████████████████▉                              | 18/50 [01:44<02:45,  5.17s/it][I 2025-01-25 11:44:36,236] Trial 18 finished with value: 0.060583777999073864 and parameters: {'n_estimators': 575, 'learning_rate': 0.030245311376999387, 'max_depth': 9, 'subsample': 0.8357878410876233, 'colsample_bytree': 0.5413080910138288, 'min_child_weight': 7, 'gamma': 5.741139671034926, 'reg_alpha': 5.720121064149037, 'reg_lambda': 1.8942595919665743}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  38%|█████████████████▊                             | 19/50 [01:51<03:06,  6.01s/it][I 2025-01-25 11:44:39,180] Trial 19 finished with value: 0.06949281014660473 and parameters: {'n_estimators': 308, 'learning_rate': 0.32151635422360547, 'max_depth': 4, 'subsample': 0.6482684162199649, 'colsample_bytree': 0.6036552362517029, 'min_child_weight': 9, 'gamma': 6.2184181447922295, 'reg_alpha': 3.506449446364101, 'reg_lambda': 3.8829526104360275}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  40%|██████████████████▊                            | 20/50 [01:54<02:32,  5.09s/it][I 2025-01-25 11:44:43,851] Trial 20 finished with value: 0.055424100772156856 and parameters: {'n_estimators': 492, 'learning_rate': 0.13417057130015525, 'max_depth': 7, 'subsample': 0.5691421779682397, 'colsample_bytree': 0.8618321563719309, 'min_child_weight': 7, 'gamma': 0.9986114198898652, 'reg_alpha': 8.360849801751293, 'reg_lambda': 6.074283655954961}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  42%|███████████████████▋                           | 21/50 [01:59<02:24,  4.97s/it][I 2025-01-25 11:44:46,810] Trial 21 finished with value: 0.05167724771804688 and parameters: {'n_estimators': 118, 'learning_rate': 0.12425685635753202, 'max_depth': 12, 'subsample': 0.6469273170894294, 'colsample_bytree': 0.6051423015530046, 'min_child_weight': 1, 'gamma': 0.6517095646217226, 'reg_alpha': 3.8195886562721757, 'reg_lambda': 6.010027348244481}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  44%|████████████████████▋                          | 22/50 [02:02<02:02,  4.36s/it][I 2025-01-25 11:44:49,062] Trial 22 finished with value: 0.05913877005247046 and parameters: {'n_estimators': 151, 'learning_rate': 0.22769275907194644, 'max_depth': 11, 'subsample': 0.5362053733567693, 'colsample_bytree': 0.5543898587879371, 'min_child_weight': 4, 'gamma': 2.142426947094387, 'reg_alpha': 5.159588852241889, 'reg_lambda': 6.3649979077562495}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  46%|█████████████████████▌                         | 23/50 [02:04<01:40,  3.73s/it][I 2025-01-25 11:44:53,036] Trial 23 finished with value: 0.05166563156492626 and parameters: {'n_estimators': 233, 'learning_rate': 0.09656298253460445, 'max_depth': 13, 'subsample': 0.6518093379917214, 'colsample_bytree': 0.5001976972805227, 'min_child_weight': 1, 'gamma': 0.7874209888491333, 'reg_alpha': 6.204253318085177, 'reg_lambda': 8.276132411362223}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  48%|██████████████████████▌                        | 24/50 [02:08<01:38,  3.80s/it][I 2025-01-25 11:44:56,580] Trial 24 finished with value: 0.061178823814124386 and parameters: {'n_estimators': 229, 'learning_rate': 0.08138324611101254, 'max_depth': 13, 'subsample': 0.548797534816627, 'colsample_bytree': 0.5008974370074852, 'min_child_weight': 4, 'gamma': 3.7835968992148143, 'reg_alpha': 7.152754662721787, 'reg_lambda': 8.704362935354816}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  50%|███████████████████████▌                       | 25/50 [02:12<01:33,  3.73s/it][I 2025-01-25 11:45:05,644] Trial 25 finished with value: 0.06999863189911185 and parameters: {'n_estimators': 775, 'learning_rate': 0.023498749272690057, 'max_depth': 8, 'subsample': 0.6300635955320463, 'colsample_bytree': 0.7195824599572427, 'min_child_weight': 3, 'gamma': 9.618646958343003, 'reg_alpha': 6.386441008666729, 'reg_lambda': 8.217309406432364}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  52%|████████████████████████▍                      | 26/50 [02:21<02:07,  5.33s/it][I 2025-01-25 11:45:11,584] Trial 26 finished with value: 0.050110031446337466 and parameters: {'n_estimators': 658, 'learning_rate': 0.21206765829824117, 'max_depth': 10, 'subsample': 0.7047179721215636, 'colsample_bytree': 0.6362676502302066, 'min_child_weight': 9, 'gamma': 0.15217071793644976, 'reg_alpha': 8.93249393765117, 'reg_lambda': 4.209284571178215}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  54%|█████████████████████████▍                     | 27/50 [02:27<02:06,  5.51s/it][I 2025-01-25 11:45:16,981] Trial 27 finished with value: 0.057617842607390966 and parameters: {'n_estimators': 645, 'learning_rate': 0.21025588751267482, 'max_depth': 10, 'subsample': 0.7682010623543816, 'colsample_bytree': 0.6365265875037026, 'min_child_weight': 9, 'gamma': 2.4028228391382083, 'reg_alpha': 9.039509192772126, 'reg_lambda': 4.189229490768778}. Best is trial 4 with value: 0.048944344792231725.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  56%|██████████████████████████▎                    | 28/50 [02:32<02:00,  5.48s/it][I 2025-01-25 11:45:21,697] Trial 28 finished with value: 0.0486434582279439 and parameters: {'n_estimators': 531, 'learning_rate': 0.33404178768440285, 'max_depth': 7, 'subsample': 0.6964487843814893, 'colsample_bytree': 0.5655407830227526, 'min_child_weight': 10, 'gamma': 0.051007579441523634, 'reg_alpha': 8.065547134190565, 'reg_lambda': 3.3587823143417426}. Best is trial 28 with value: 0.0486434582279439.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  58%|███████████████████████████▎                   | 29/50 [02:37<01:50,  5.25s/it][I 2025-01-25 11:45:28,909] Trial 29 finished with value: 0.05989931968004771 and parameters: {'n_estimators': 985, 'learning_rate': 0.574667877000003, 'max_depth': 8, 'subsample': 0.7074182158519419, 'colsample_bytree': 0.5740007166450929, 'min_child_weight': 9, 'gamma': 1.1741251440755291, 'reg_alpha': 9.920872466802408, 'reg_lambda': 4.676999332417313}. Best is trial 28 with value: 0.0486434582279439.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  60%|████████████████████████████▏                  | 30/50 [02:44<01:56,  5.84s/it][I 2025-01-25 11:45:33,006] Trial 30 finished with value: 0.06064182623013011 and parameters: {'n_estimators': 472, 'learning_rate': 0.36435883087885335, 'max_depth': 10, 'subsample': 0.8265262315958768, 'colsample_bytree': 0.6406717612826716, 'min_child_weight': 10, 'gamma': 3.589515564851371, 'reg_alpha': 8.119026604213108, 'reg_lambda': 2.0811786206828686}. Best is trial 28 with value: 0.0486434582279439.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  62%|█████████████████████████████▏                 | 31/50 [02:48<01:40,  5.32s/it][I 2025-01-25 11:45:37,585] Trial 31 finished with value: 0.0521634867413462 and parameters: {'n_estimators': 544, 'learning_rate': 0.4555831134716744, 'max_depth': 7, 'subsample': 0.7232848296784032, 'colsample_bytree': 0.5415154599586767, 'min_child_weight': 10, 'gamma': 0.22287577087536076, 'reg_alpha': 8.80711226532602, 'reg_lambda': 3.4549899194456555}. Best is trial 28 with value: 0.0486434582279439.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  64%|██████████████████████████████                 | 32/50 [02:53<01:31,  5.09s/it][I 2025-01-25 11:45:42,922] Trial 32 finished with value: 0.04743576767031904 and parameters: {'n_estimators': 630, 'learning_rate': 0.2764994212940964, 'max_depth': 6, 'subsample': 0.8972702292699505, 'colsample_bytree': 0.5688965296114663, 'min_child_weight': 10, 'gamma': 0.061243202952817336, 'reg_alpha': 7.638138411203313, 'reg_lambda': 2.679841974035623}. Best is trial 32 with value: 0.04743576767031904.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  66%|███████████████████████████████                | 33/50 [02:58<01:27,  5.17s/it][I 2025-01-25 11:45:47,884] Trial 33 finished with value: 0.054508207678727306 and parameters: {'n_estimators': 589, 'learning_rate': 0.3039696573504169, 'max_depth': 8, 'subsample': 0.9332710572509668, 'colsample_bytree': 0.7009989189834923, 'min_child_weight': 9, 'gamma': 1.3926296665907354, 'reg_alpha': 7.704990181165249, 'reg_lambda': 2.4330006162401707}. Best is trial 32 with value: 0.04743576767031904.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  68%|███████████████████████████████▉               | 34/50 [03:03<01:21,  5.11s/it][W 2025-01-25 11:45:51,442] Trial 34 failed with parameters: {'n_estimators': 780, 'learning_rate': 0.5836502453199157, 'max_depth': 9, 'subsample': 0.9973095577583949, 'colsample_bytree': 0.5756563133449244, 'min_child_weight': 8, 'gamma': 0.6475641703364912, 'reg_alpha': 9.382049591507764, 'reg_lambda': 1.4689172356783513} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9608\\3946747138.py\", line 29, in objective\n",
      "    x_train, x_val = train.iloc[train_index], train.iloc[val_index]\n",
      "                     ^^^^^^^^^^\n",
      "  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py\", line 161, in iloc\n",
      "    @property\n",
      "    \n",
      "KeyboardInterrupt\n",
      "[W 2025-01-25 11:45:51,453] Trial 34 failed with value None.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  68%|███████████████████████████████▉               | 34/50 [03:07<01:28,  5.51s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# --------------------------------------------- 결측치 제외하고 학습  ---------------------------------------------------\n",
    "\n",
    "# ----------------------------------------------------- 데이터 학습 --------------------------------------------------------------\n",
    "\n",
    "# 목적함수 생성\n",
    "def objective(trial):\n",
    "    params = {\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 100, 1000),  # 트리 개수\n",
    "    'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),  # 학습률\n",
    "    'max_depth': trial.suggest_int('max_depth', 3, 15),  # 트리 최대 깊이\n",
    "    'subsample': trial.suggest_float('subsample', 0.5, 1.0),  # 샘플링 비율\n",
    "    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),  # 특성 샘플링 비율\n",
    "    'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),  # 리프 노드 최소 가중치\n",
    "    'gamma': trial.suggest_float('gamma', 0, 10),  # 최소 손실 감소\n",
    "    'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),  # L1 정규화\n",
    "    'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),  # L2 정규화\n",
    "    \"tree_method\": \"hist\",  # 트리 방법\n",
    "    \"device\": \"cuda\",       # GPU 사용\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    'random_state': 1\n",
    "}\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    xgb_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(train):\n",
    "        x_train, x_val = train.iloc[train_index], train.iloc[val_index]\n",
    "        y_train, y_val = log_y_df[train_index], log_y_df[val_index]\n",
    "\n",
    "        # XGBoost 모델 생성\n",
    "        xgb_model = xgb.XGBRegressor(**params)\n",
    "        xgb_model.fit(x_train, y_train)\n",
    "\n",
    "        # 예측 및 RMSLE 계산\n",
    "        y_pred = np.exp(xgb_model.predict(x_val))\n",
    "        mape = mean_absolute_percentage_error(np.exp(y_val), y_pred)\n",
    "        xgb_scores.append(mape)\n",
    "\n",
    "    return np.mean(xgb_scores)\n",
    "\n",
    "# Optuna 하이퍼파라미터 최적화\n",
    "n_trials = 50\n",
    "xgb_study = optuna.create_study(direction='minimize')\n",
    "\n",
    "for _ in tqdm(range(n_trials), desc='XGBoost 하이퍼파라미터 튜닝 중...'):\n",
    "    xgb_study.optimize(objective, n_trials=1, catch=(Exception,))\n",
    "\n",
    "print('최고의 MAPE값', xgb_study.best_value, '\\n')\n",
    "print('최고의 하이퍼 파라미터', xgb_study.best_params, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bd9b2d-cab4-41a0-b109-7ae2f805bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = xgb_study.best_params\n",
    "best_params.update({\n",
    "    \"tree_method\": \"hist\",  # 트리 방법\n",
    "    \"device\": \"cuda\",       # GPU 사용\n",
    "    \"objective\": \"reg:squarederror\"})\n",
    "\n",
    "final_xgb_model = xgb.XGBRegressor(**best_params)\n",
    "final_xgb_model.fit(train, log_y_df)\n",
    "\n",
    "y_pred_log = final_xgb_model.predict(train)\n",
    "y_pred = np.exp(y_pred_log)\n",
    "\n",
    "feature_importances = final_xgb_model.feature_importances_\n",
    "features = train.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature' : features,\n",
    "    'Importance' : feature_importances}).sort_values(by = 'Importance', ascending = False)\n",
    "\n",
    "print('변수 중요도')\n",
    "print(importance_df)\n",
    "\n",
    "# 변수 중요도 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance (XGBoost)')\n",
    "plt.gca().invert_yaxis()  # 중요도가 높은 순서로 표시\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bd4ba2-6318-4f9e-b330-f82a75668cc2",
   "metadata": {},
   "source": [
    "<div style=\"background-color:red; padding:10px; border-radius:10px; font-size:18px;\">\n",
    "(시도 4)<br><br>\n",
    "군집별 EDA 결과에 기반한 순서인코딩<br>\n",
    "주기성이 있는 sin,cos 파생변수 추가<br>\n",
    "year, month, weekday 그대로 넣고 학습<br>\n",
    "결측치 존재하는 케이스 제외<br>\n",
    "반년 주기 파생변수 추가\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021f8a84-2055-4825-afd7-0571f4d144d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>...</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>year_sin</th>\n",
       "      <th>year_cos</th>\n",
       "      <th>half_year_sin</th>\n",
       "      <th>half_year_cos</th>\n",
       "      <th>group</th>\n",
       "      <th>mapped_weekday</th>\n",
       "      <th>mapped_month</th>\n",
       "      <th>mapped_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  country  store  product  year  month  weekday  day  day_of_week  \\\n",
       "0      1        3      0        4  2010      1        4    1            4   \n",
       "1      2        3      0        3  2010      1        4    1            4   \n",
       "2      3        3      0        1  2010      1        4    1            4   \n",
       "3      4        3      0        2  2010      1        4    1            4   \n",
       "4      5        3      1        0  2010      1        4    1            4   \n",
       "\n",
       "   week_of_year  ...  month_sin  month_cos  year_sin  year_cos  half_year_sin  \\\n",
       "0            53  ...        0.5   0.866025  0.781831   0.62349       0.034422   \n",
       "1            53  ...        0.5   0.866025  0.781831   0.62349       0.034422   \n",
       "2            53  ...        0.5   0.866025  0.781831   0.62349       0.034422   \n",
       "3            53  ...        0.5   0.866025  0.781831   0.62349       0.034422   \n",
       "4            53  ...        0.5   0.866025  0.781831   0.62349       0.034422   \n",
       "\n",
       "   half_year_cos  group  mapped_weekday  mapped_month  mapped_year  \n",
       "0       0.999407      4               1             4            3  \n",
       "1       0.999407      4               1             4            3  \n",
       "2       0.999407      4               1             4            3  \n",
       "3       0.999407      4               1             4            3  \n",
       "4       0.999407      4               1             4            3  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# =================================================================================================================================\n",
    "# ==================================================== 반년 주기 추가 데이터 프레임 ==================================================\n",
    "# =================================================================================================================================\n",
    "\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "train = train.dropna()\n",
    "train = train.reset_index()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------데이터 전처리\n",
    "\n",
    "# 날짜 파생 변수 생성\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "train['year'] = train['date'].dt.year\n",
    "train['month'] = train['date'].dt.month\n",
    "train['weekday'] = train['date'].dt.weekday\n",
    "train['day'] = train['date'].dt.day\n",
    "train['day_of_week'] = train['date'].dt.dayofweek\n",
    "train['week_of_year'] = train['date'].dt.isocalendar().week\n",
    "train['day_sin'] = np.sin(2 * np.pi * train['day'] / 365)\n",
    "train['day_cos'] = np.cos(2 * np.pi * train['day'] / 365)\n",
    "train['month_sin'] = np.sin(2 * np.pi * train['month'] / 12)\n",
    "train['month_cos'] = np.cos(2 * np.pi * train['month'] / 12)\n",
    "train['year_sin'] = np.sin(2 * np.pi * train['year'] / 7)\n",
    "train['year_cos'] = np.cos(2 * np.pi * train['year'] / 7)\n",
    "train['half_year_sin'] = np.sin(2 * np.pi * train['day'] / 182.5)\n",
    "train['half_year_cos'] = np.cos(2 * np.pi * train['day'] / 182.5)\n",
    "train['group'] = (train['year'] - 2010) * 48 + train['month'] * 4 + train['day'] // 7\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------ 인코딩\n",
    "\n",
    "country_mapping = {\n",
    "    'Kenya': 0,\n",
    "    'Italy': 1,\n",
    "    'Finland': 2,\n",
    "    'Canada': 3,\n",
    "    'Singapore': 4,\n",
    "    'Norway': 5}\n",
    "train['country'] = train['country'].map(country_mapping)\n",
    "\n",
    "\n",
    "store_mapping = {\n",
    "    'Discount Stickers' : 0,\n",
    "    'Stickers for Less' : 1,\n",
    "    'Premium Sticker Mart' : 2}\n",
    "train['store'] = train['store'].map(store_mapping)\n",
    "\n",
    "\n",
    "product_mapping = {\n",
    "    'Holographic Goose' : 0,\n",
    "    'Kerneler' : 1,\n",
    "    'Kerneler Dark Mode' : 2,\n",
    "    'Kaggle Tiers' : 3,\n",
    "    'Kaggle' : 4}\n",
    "train['product'] = train['product'].map(product_mapping)\n",
    "\n",
    "weekday_mapping = {\n",
    "    0 : 0,\n",
    "    1 : 0,\n",
    "    2 : 0,\n",
    "    3 : 0,\n",
    "    4 : 1,\n",
    "    5 : 2,\n",
    "    6 : 3}\n",
    "train['mapped_weekday'] = train['weekday'].map(weekday_mapping)\n",
    "\n",
    "month_mapping = {\n",
    "    2: 1, 5: 1, 4: 1, 3: 1,   \n",
    "    9: 2, 10: 2,              \n",
    "    6: 3, 7: 3, 8: 3,         \n",
    "    1: 4, 11: 4,             \n",
    "    12: 5}                    \n",
    "train['mapped_month'] = train['month'].map(month_mapping)   \n",
    "\n",
    "# 연도별 배핑\n",
    "'''\n",
    "year_mapping = {\n",
    "    2011: 1, 2013: 1,  # 2011년, 2013년 → 1\n",
    "    2012: 2, 2014: 2,  # 2012년, 2014년 → 2\n",
    "    2010: 3, 2015: 3, 2016: 3} # 2010년, 2015년, 2016년 → 3\n",
    "train['mapped_year'] = train['year'].map(year_mapping)\n",
    "'''\n",
    "\n",
    "# 반응변수 추출\n",
    "y_df = train['num_sold']\n",
    "log_y_df = np.log1p(y_df)\n",
    "\n",
    "# 필요없는 변수 삭제\n",
    "train = train.drop(['num_sold', 'id', 'date'] , axis = 1)\n",
    "\n",
    "# 데이터 확인\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca9ba2a-8a5b-4c07-ae51-f17534364afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-25 09:48:06,007] A new study created in memory with name: no-name-70ff0698-f065-48a6-8437-339859180146\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   0%|                                                        | 0/50 [00:00<?, ?it/s]C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:48:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-01-25 09:48:13,139] Trial 0 finished with value: 0.07550358254349607 and parameters: {'n_estimators': 936, 'learning_rate': 0.570904244860556, 'max_depth': 5, 'subsample': 0.681407377701325, 'colsample_bytree': 0.8696696259920256, 'min_child_weight': 2, 'gamma': 7.64383959952905, 'reg_alpha': 3.0590569197135196, 'reg_lambda': 2.4522274696062274}. Best is trial 0 with value: 0.07550358254349607.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   2%|▉                                               | 1/50 [00:07<05:49,  7.13s/it][I 2025-01-25 09:48:18,962] Trial 1 finished with value: 0.08821211314429475 and parameters: {'n_estimators': 784, 'learning_rate': 0.5453495380480404, 'max_depth': 3, 'subsample': 0.8932245480251843, 'colsample_bytree': 0.5679327279984618, 'min_child_weight': 4, 'gamma': 2.813726062035423, 'reg_alpha': 5.408522839620726, 'reg_lambda': 4.447243753551341}. Best is trial 0 with value: 0.07550358254349607.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   4%|█▉                                              | 2/50 [00:12<05:05,  6.36s/it][I 2025-01-25 09:48:22,747] Trial 2 finished with value: 0.06802925174549414 and parameters: {'n_estimators': 433, 'learning_rate': 0.392647075695632, 'max_depth': 6, 'subsample': 0.8128205537230394, 'colsample_bytree': 0.8508623245158886, 'min_child_weight': 7, 'gamma': 7.732830746595444, 'reg_alpha': 5.095845538764125, 'reg_lambda': 3.5084508584854035}. Best is trial 2 with value: 0.06802925174549414.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   6%|██▉                                             | 3/50 [00:16<04:03,  5.18s/it][I 2025-01-25 09:48:27,096] Trial 3 finished with value: 0.0659287421720545 and parameters: {'n_estimators': 535, 'learning_rate': 0.548399393018269, 'max_depth': 12, 'subsample': 0.7641506405711564, 'colsample_bytree': 0.6239354951554443, 'min_child_weight': 9, 'gamma': 4.789623997622584, 'reg_alpha': 4.511377194183831, 'reg_lambda': 7.996360593197057}. Best is trial 3 with value: 0.0659287421720545.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   8%|███▊                                            | 4/50 [00:21<03:43,  4.86s/it][I 2025-01-25 09:48:31,977] Trial 4 finished with value: 0.07448271578731488 and parameters: {'n_estimators': 611, 'learning_rate': 0.8223392215216685, 'max_depth': 9, 'subsample': 0.5189791941074199, 'colsample_bytree': 0.8549588424777537, 'min_child_weight': 5, 'gamma': 1.7108866049954674, 'reg_alpha': 9.427230633711707, 'reg_lambda': 4.527692496602639}. Best is trial 3 with value: 0.0659287421720545.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  10%|████▊                                           | 5/50 [00:25<03:38,  4.86s/it][I 2025-01-25 09:48:37,531] Trial 5 finished with value: 0.05708456071796779 and parameters: {'n_estimators': 547, 'learning_rate': 0.1413793054419079, 'max_depth': 14, 'subsample': 0.6322853657033755, 'colsample_bytree': 0.78860751865761, 'min_child_weight': 10, 'gamma': 2.5294822500891154, 'reg_alpha': 1.7215671760660134, 'reg_lambda': 8.068888061075574}. Best is trial 5 with value: 0.05708456071796779.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  12%|█████▊                                          | 6/50 [00:31<03:44,  5.10s/it][I 2025-01-25 09:48:47,158] Trial 6 finished with value: 0.053636842340880175 and parameters: {'n_estimators': 969, 'learning_rate': 0.1439518081898426, 'max_depth': 6, 'subsample': 0.7100322815290762, 'colsample_bytree': 0.7482881821497955, 'min_child_weight': 9, 'gamma': 1.113436908057266, 'reg_alpha': 6.049260898227999, 'reg_lambda': 2.651569563063628}. Best is trial 6 with value: 0.053636842340880175.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  14%|██████▋                                         | 7/50 [00:41<04:42,  6.58s/it][I 2025-01-25 09:48:55,190] Trial 7 finished with value: 0.07696248393865605 and parameters: {'n_estimators': 772, 'learning_rate': 0.26572335816958476, 'max_depth': 3, 'subsample': 0.7011786198802545, 'colsample_bytree': 0.8288262198721136, 'min_child_weight': 8, 'gamma': 0.7425979399304816, 'reg_alpha': 3.3974819440805692, 'reg_lambda': 9.91495568750834}. Best is trial 6 with value: 0.053636842340880175.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  16%|███████▋                                        | 8/50 [00:49<04:55,  7.04s/it][I 2025-01-25 09:49:01,292] Trial 8 finished with value: 0.06539575581536854 and parameters: {'n_estimators': 599, 'learning_rate': 0.1093229563667233, 'max_depth': 5, 'subsample': 0.9388841847914533, 'colsample_bytree': 0.6015382733235178, 'min_child_weight': 10, 'gamma': 9.185911833566076, 'reg_alpha': 9.09684653474875, 'reg_lambda': 6.762075928453234}. Best is trial 6 with value: 0.053636842340880175.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  18%|████████▋                                       | 9/50 [00:55<04:36,  6.75s/it][I 2025-01-25 09:49:08,348] Trial 9 finished with value: 0.07291824737567662 and parameters: {'n_estimators': 294, 'learning_rate': 0.02592022879144728, 'max_depth': 10, 'subsample': 0.8767001630546466, 'colsample_bytree': 0.5370535880496478, 'min_child_weight': 3, 'gamma': 6.809782249522661, 'reg_alpha': 5.378544141603365, 'reg_lambda': 8.526486898502858}. Best is trial 6 with value: 0.053636842340880175.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  20%|█████████▍                                     | 10/50 [01:02<04:33,  6.84s/it][I 2025-01-25 09:49:10,521] Trial 10 finished with value: 0.08072527472222182 and parameters: {'n_estimators': 162, 'learning_rate': 0.8460851629142228, 'max_depth': 8, 'subsample': 0.5640585688567574, 'colsample_bytree': 0.9856082234911634, 'min_child_weight': 7, 'gamma': 4.569989823926066, 'reg_alpha': 7.156174435419236, 'reg_lambda': 0.6904620154972316}. Best is trial 6 with value: 0.053636842340880175.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  22%|██████████▎                                    | 11/50 [01:04<03:31,  5.41s/it][I 2025-01-25 09:49:22,922] Trial 11 finished with value: 0.045598802488498416 and parameters: {'n_estimators': 930, 'learning_rate': 0.2323883300298001, 'max_depth': 15, 'subsample': 0.6217635872616707, 'colsample_bytree': 0.7226176955624591, 'min_child_weight': 10, 'gamma': 0.013779597573820634, 'reg_alpha': 0.2668910030009737, 'reg_lambda': 6.177407979310143}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  24%|███████████▎                                   | 12/50 [01:16<04:46,  7.54s/it][I 2025-01-25 09:49:30,932] Trial 12 finished with value: 0.05170470961300182 and parameters: {'n_estimators': 990, 'learning_rate': 0.3048250206094615, 'max_depth': 15, 'subsample': 0.6130597997942928, 'colsample_bytree': 0.6711265515710056, 'min_child_weight': 8, 'gamma': 0.601130329787452, 'reg_alpha': 0.7287374793909729, 'reg_lambda': 1.6332246140069357}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  26%|████████████▏                                  | 13/50 [01:24<04:44,  7.68s/it][I 2025-01-25 09:49:38,608] Trial 13 finished with value: 0.05064355651637302 and parameters: {'n_estimators': 825, 'learning_rate': 0.3465893728827748, 'max_depth': 15, 'subsample': 0.6023556540334664, 'colsample_bytree': 0.6956202663381846, 'min_child_weight': 7, 'gamma': 0.3227601325994982, 'reg_alpha': 0.045784521964530284, 'reg_lambda': 6.426955601381184}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  28%|█████████████▏                                 | 14/50 [01:32<04:36,  7.68s/it][I 2025-01-25 09:49:45,626] Trial 14 finished with value: 0.06257138331956544 and parameters: {'n_estimators': 800, 'learning_rate': 0.381414286183135, 'max_depth': 13, 'subsample': 0.5036712558568461, 'colsample_bytree': 0.6997805326552277, 'min_child_weight': 6, 'gamma': 3.4097956839720025, 'reg_alpha': 0.019225250504787326, 'reg_lambda': 6.102323937306996}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  30%|██████████████                                 | 15/50 [01:39<04:21,  7.48s/it][I 2025-01-25 09:49:52,226] Trial 15 finished with value: 0.058048309805384814 and parameters: {'n_estimators': 828, 'learning_rate': 0.7196322792933751, 'max_depth': 11, 'subsample': 0.6090324679178418, 'colsample_bytree': 0.7132649877717103, 'min_child_weight': 6, 'gamma': 0.35479139501737766, 'reg_alpha': 1.7884791042852557, 'reg_lambda': 6.0606739497306625}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  32%|███████████████                                | 16/50 [01:46<04:05,  7.22s/it][I 2025-01-25 09:49:58,183] Trial 16 finished with value: 0.05287266287163578 and parameters: {'n_estimators': 694, 'learning_rate': 0.26409631666181704, 'max_depth': 15, 'subsample': 0.9997178574431487, 'colsample_bytree': 0.504511893392817, 'min_child_weight': 8, 'gamma': 1.87598231346968, 'reg_alpha': 1.4998304937031346, 'reg_lambda': 5.469399207431357}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  34%|███████████████▉                               | 17/50 [01:52<03:45,  6.84s/it][I 2025-01-25 09:50:04,806] Trial 17 finished with value: 0.07214338102259407 and parameters: {'n_estimators': 869, 'learning_rate': 0.6875417877911585, 'max_depth': 13, 'subsample': 0.5536655799174376, 'colsample_bytree': 0.953048885629529, 'min_child_weight': 1, 'gamma': 3.9958040003475195, 'reg_alpha': 2.872235059836061, 'reg_lambda': 7.094116765539861}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  36%|████████████████▉                              | 18/50 [01:58<03:36,  6.77s/it][I 2025-01-25 09:50:10,296] Trial 18 finished with value: 0.07799523048906666 and parameters: {'n_estimators': 699, 'learning_rate': 0.9857251368995971, 'max_depth': 15, 'subsample': 0.6513339510161249, 'colsample_bytree': 0.6461269935751348, 'min_child_weight': 5, 'gamma': 6.210172122815311, 'reg_alpha': 0.042781835597921085, 'reg_lambda': 9.42989185992067}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  38%|█████████████████▊                             | 19/50 [02:04<03:18,  6.39s/it][I 2025-01-25 09:50:17,997] Trial 19 finished with value: 0.04803776707655608 and parameters: {'n_estimators': 900, 'learning_rate': 0.4279407003951696, 'max_depth': 12, 'subsample': 0.7532048760211948, 'colsample_bytree': 0.7718438296453546, 'min_child_weight': 10, 'gamma': 0.06294337269307024, 'reg_alpha': 1.129738939053998, 'reg_lambda': 3.9529772159017282}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  40%|██████████████████▊                            | 20/50 [02:11<03:23,  6.78s/it][I 2025-01-25 09:50:24,938] Trial 20 finished with value: 0.05886275360763936 and parameters: {'n_estimators': 901, 'learning_rate': 0.45829928404334974, 'max_depth': 12, 'subsample': 0.7732858410821644, 'colsample_bytree': 0.9165993402656105, 'min_child_weight': 10, 'gamma': 1.835471545554208, 'reg_alpha': 3.80362588930742, 'reg_lambda': 3.685515233601982}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  42%|███████████████████▋                           | 21/50 [02:18<03:18,  6.83s/it][I 2025-01-25 09:50:33,196] Trial 21 finished with value: 0.04687130911579106 and parameters: {'n_estimators': 888, 'learning_rate': 0.3719181070443593, 'max_depth': 13, 'subsample': 0.8152872753083232, 'colsample_bytree': 0.7812246725001415, 'min_child_weight': 9, 'gamma': 0.04040667184224202, 'reg_alpha': 0.9084615482965719, 'reg_lambda': 4.879174636437845}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  44%|████████████████████▋                          | 22/50 [02:27<03:23,  7.26s/it][I 2025-01-25 09:50:39,473] Trial 22 finished with value: 0.05076499098098849 and parameters: {'n_estimators': 721, 'learning_rate': 0.46348978269310537, 'max_depth': 12, 'subsample': 0.8161546099044071, 'colsample_bytree': 0.797928106220861, 'min_child_weight': 9, 'gamma': 0.17685816068276977, 'reg_alpha': 2.2670615688003295, 'reg_lambda': 5.1185360399570685}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  46%|█████████████████████▌                         | 23/50 [02:33<03:08,  6.96s/it][I 2025-01-25 09:50:47,397] Trial 23 finished with value: 0.05295129976432615 and parameters: {'n_estimators': 997, 'learning_rate': 0.22954724830389028, 'max_depth': 13, 'subsample': 0.8362854467641896, 'colsample_bytree': 0.7544788611286446, 'min_child_weight': 10, 'gamma': 1.4036764196280496, 'reg_alpha': 1.1587903480567627, 'reg_lambda': 3.7380101214098396}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  48%|██████████████████████▌                        | 24/50 [02:41<03:08,  7.25s/it][I 2025-01-25 09:50:55,502] Trial 24 finished with value: 0.04705971715248802 and parameters: {'n_estimators': 899, 'learning_rate': 0.18957439141851745, 'max_depth': 10, 'subsample': 0.7333105416806109, 'colsample_bytree': 0.7483779943519654, 'min_child_weight': 9, 'gamma': 0.08792090421235674, 'reg_alpha': 2.36566272057219, 'reg_lambda': 5.314166079482018}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  50%|███████████████████████▌                       | 25/50 [02:49<03:07,  7.51s/it][I 2025-01-25 09:50:59,695] Trial 25 finished with value: 0.05656565651026901 and parameters: {'n_estimators': 407, 'learning_rate': 0.20027376951051623, 'max_depth': 10, 'subsample': 0.7289310592939318, 'colsample_bytree': 0.7332761464447324, 'min_child_weight': 9, 'gamma': 2.3513043767239514, 'reg_alpha': 2.52121213680742, 'reg_lambda': 5.468164042134763}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  52%|████████████████████████▍                      | 26/50 [02:53<02:36,  6.51s/it][I 2025-01-25 09:51:14,234] Trial 26 finished with value: 0.057873621884630445 and parameters: {'n_estimators': 875, 'learning_rate': 0.016062080737205664, 'max_depth': 14, 'subsample': 0.6676579324680182, 'colsample_bytree': 0.8076200048321369, 'min_child_weight': 8, 'gamma': 3.150201890813905, 'reg_alpha': 0.7580363202750482, 'reg_lambda': 6.971238881465779}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  54%|█████████████████████████▍                     | 27/50 [03:08<03:25,  8.92s/it][I 2025-01-25 09:51:19,649] Trial 27 finished with value: 0.05550862422123757 and parameters: {'n_estimators': 655, 'learning_rate': 0.3267515916244723, 'max_depth': 8, 'subsample': 0.782838151908182, 'colsample_bytree': 0.89397365788291, 'min_child_weight': 9, 'gamma': 1.186602252182094, 'reg_alpha': 3.8700117680290287, 'reg_lambda': 7.581680743577469}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  56%|██████████████████████████▎                    | 28/50 [03:13<02:53,  7.87s/it][I 2025-01-25 09:51:25,960] Trial 28 finished with value: 0.06019886678472711 and parameters: {'n_estimators': 748, 'learning_rate': 0.1894446836809099, 'max_depth': 10, 'subsample': 0.8601957908292062, 'colsample_bytree': 0.6654679381503993, 'min_child_weight': 7, 'gamma': 5.608507777413823, 'reg_alpha': 2.4033226793135496, 'reg_lambda': 4.726681192275378}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  58%|███████████████████████████▎                   | 29/50 [03:19<02:35,  7.40s/it][I 2025-01-25 09:51:34,955] Trial 29 finished with value: 0.05889312598368753 and parameters: {'n_estimators': 936, 'learning_rate': 0.08278834260903395, 'max_depth': 14, 'subsample': 0.686195107358868, 'colsample_bytree': 0.7284079812447272, 'min_child_weight': 8, 'gamma': 3.863005439436854, 'reg_alpha': 0.7650518322942855, 'reg_lambda': 2.439800432973709}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  60%|████████████████████████████▏                  | 30/50 [03:28<02:37,  7.88s/it][I 2025-01-25 09:51:42,759] Trial 30 finished with value: 0.05924993132739383 and parameters: {'n_estimators': 921, 'learning_rate': 0.6488494705759489, 'max_depth': 11, 'subsample': 0.9207414949844992, 'colsample_bytree': 0.8968338558541189, 'min_child_weight': 9, 'gamma': 1.0385656102498433, 'reg_alpha': 3.2585579150943653, 'reg_lambda': 5.783905632045345}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  62%|█████████████████████████████▏                 | 31/50 [03:36<02:29,  7.86s/it][I 2025-01-25 09:51:51,614] Trial 31 finished with value: 0.04609015524474985 and parameters: {'n_estimators': 860, 'learning_rate': 0.4546584843367899, 'max_depth': 11, 'subsample': 0.745203251376405, 'colsample_bytree': 0.7746766251955999, 'min_child_weight': 10, 'gamma': 0.013904330144564402, 'reg_alpha': 1.1574500364099163, 'reg_lambda': 4.197096114970019}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  64%|██████████████████████████████                 | 32/50 [03:45<02:26,  8.16s/it][I 2025-01-25 09:52:01,272] Trial 32 finished with value: 0.046866607671050706 and parameters: {'n_estimators': 855, 'learning_rate': 0.4928812227106872, 'max_depth': 11, 'subsample': 0.7366403892219946, 'colsample_bytree': 0.8237315785098369, 'min_child_weight': 10, 'gamma': 0.011658603465452552, 'reg_alpha': 2.0131857983811017, 'reg_lambda': 3.024056882454711}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  66%|███████████████████████████████                | 33/50 [03:55<02:26,  8.61s/it][I 2025-01-25 09:52:09,334] Trial 33 finished with value: 0.0623233237718977 and parameters: {'n_estimators': 848, 'learning_rate': 0.5887335510074183, 'max_depth': 11, 'subsample': 0.809797563724001, 'colsample_bytree': 0.8210862831649539, 'min_child_weight': 10, 'gamma': 2.245591744572311, 'reg_alpha': 0.6125803254368201, 'reg_lambda': 2.9093915462233064}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  68%|███████████████████████████████▉               | 34/50 [04:03<02:15,  8.44s/it][I 2025-01-25 09:52:15,929] Trial 34 finished with value: 0.05615412827954358 and parameters: {'n_estimators': 782, 'learning_rate': 0.530744409236003, 'max_depth': 13, 'subsample': 0.8044432635512457, 'colsample_bytree': 0.8419316506819016, 'min_child_weight': 10, 'gamma': 0.8632731397056644, 'reg_alpha': 1.6417040083537202, 'reg_lambda': 1.9636537774623914}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  70%|████████████████████████████████▉              | 35/50 [04:09<01:58,  7.89s/it][I 2025-01-25 09:52:23,264] Trial 35 finished with value: 0.06883470721245033 and parameters: {'n_estimators': 960, 'learning_rate': 0.5947040378048443, 'max_depth': 9, 'subsample': 0.8509080475097097, 'colsample_bytree': 0.7719859788785537, 'min_child_weight': 10, 'gamma': 8.157492202728259, 'reg_alpha': 4.507556729598448, 'reg_lambda': 3.335912069509087}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  72%|█████████████████████████████████▊             | 36/50 [04:17<01:48,  7.72s/it][I 2025-01-25 09:52:29,750] Trial 36 finished with value: 0.05917131272058303 and parameters: {'n_estimators': 827, 'learning_rate': 0.4955072920395384, 'max_depth': 14, 'subsample': 0.7246204886856994, 'colsample_bytree': 0.8627362897113716, 'min_child_weight': 3, 'gamma': 1.6201281689964233, 'reg_alpha': 1.9951776580962797, 'reg_lambda': 4.310597404239982}. Best is trial 11 with value: 0.045598802488498416.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  74%|██████████████████████████████████▊            | 37/50 [04:23<01:35,  7.35s/it][I 2025-01-25 09:52:35,422] Trial 37 finished with value: 0.04557479381061712 and parameters: {'n_estimators': 483, 'learning_rate': 0.4070828754571607, 'max_depth': 11, 'subsample': 0.788162582050869, 'colsample_bytree': 0.7808790985869158, 'min_child_weight': 9, 'gamma': 0.011373767322021756, 'reg_alpha': 1.3420045872712598, 'reg_lambda': 0.789042825482067}. Best is trial 37 with value: 0.04557479381061712.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  76%|███████████████████████████████████▋           | 38/50 [04:29<01:22,  6.85s/it][I 2025-01-25 09:52:39,628] Trial 38 finished with value: 0.05727526286008329 and parameters: {'n_estimators': 470, 'learning_rate': 0.42077404147621317, 'max_depth': 8, 'subsample': 0.6582609352894879, 'colsample_bytree': 0.6111671154980476, 'min_child_weight': 9, 'gamma': 0.8290320647872381, 'reg_alpha': 6.986188174414472, 'reg_lambda': 0.29770565264942334}. Best is trial 37 with value: 0.04557479381061712.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  78%|████████████████████████████████████▋          | 39/50 [04:33<01:06,  6.06s/it][I 2025-01-25 09:52:43,199] Trial 39 finished with value: 0.06068556447064384 and parameters: {'n_estimators': 382, 'learning_rate': 0.5082129446887221, 'max_depth': 9, 'subsample': 0.7769561664946442, 'colsample_bytree': 0.8115786568901726, 'min_child_weight': 8, 'gamma': 2.818525737037695, 'reg_alpha': 2.906501975392267, 'reg_lambda': 1.0730809421722585}. Best is trial 37 with value: 0.04557479381061712.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  80%|█████████████████████████████████████▌         | 40/50 [04:37<00:53,  5.31s/it][I 2025-01-25 09:52:47,487] Trial 40 finished with value: 0.05679398565911391 and parameters: {'n_estimators': 483, 'learning_rate': 0.29370803263374795, 'max_depth': 6, 'subsample': 0.6934548554451785, 'colsample_bytree': 0.8843063397827119, 'min_child_weight': 10, 'gamma': 1.3451547317505232, 'reg_alpha': 1.3935353370949155, 'reg_lambda': 0.046886454354490126}. Best is trial 37 with value: 0.04557479381061712.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  82%|██████████████████████████████████████▌        | 41/50 [04:41<00:45,  5.00s/it][I 2025-01-25 09:52:53,702] Trial 41 finished with value: 0.04629993043809859 and parameters: {'n_estimators': 618, 'learning_rate': 0.36921238820519087, 'max_depth': 11, 'subsample': 0.7506569082521397, 'colsample_bytree': 0.7762507471161472, 'min_child_weight': 9, 'gamma': 0.029069788637945432, 'reg_alpha': 0.5318096482781491, 'reg_lambda': 4.255066710967322}. Best is trial 37 with value: 0.04557479381061712.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  84%|███████████████████████████████████████▍       | 42/50 [04:47<00:42,  5.37s/it][I 2025-01-25 09:52:57,256] Trial 42 finished with value: 0.05269964928718379 and parameters: {'n_estimators': 346, 'learning_rate': 0.40754324365287475, 'max_depth': 11, 'subsample': 0.748404634551729, 'colsample_bytree': 0.76066529328973, 'min_child_weight': 10, 'gamma': 0.6188470541039446, 'reg_alpha': 0.5306732854950902, 'reg_lambda': 3.138141079514875}. Best is trial 37 with value: 0.04557479381061712.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  86%|████████████████████████████████████████▍      | 43/50 [04:51<00:33,  4.82s/it][I 2025-01-25 09:53:02,154] Trial 43 finished with value: 0.07335733120719785 and parameters: {'n_estimators': 586, 'learning_rate': 0.4657114751005843, 'max_depth': 7, 'subsample': 0.7204985186462596, 'colsample_bytree': 0.8375529765561709, 'min_child_weight': 9, 'gamma': 9.747087519896205, 'reg_alpha': 0.24518654428975362, 'reg_lambda': 4.334702377539705}. Best is trial 37 with value: 0.04557479381061712.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  88%|█████████████████████████████████████████▎     | 44/50 [04:56<00:29,  4.85s/it][I 2025-01-25 09:53:06,800] Trial 44 finished with value: 0.05239914171401605 and parameters: {'n_estimators': 509, 'learning_rate': 0.35796966920698625, 'max_depth': 11, 'subsample': 0.7930040283507418, 'colsample_bytree': 0.791331347681244, 'min_child_weight': 10, 'gamma': 0.6205213523541151, 'reg_alpha': 1.9863774686894156, 'reg_lambda': 2.2430500053082123}. Best is trial 37 with value: 0.04557479381061712.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  90%|██████████████████████████████████████████▎    | 45/50 [05:00<00:23,  4.79s/it][I 2025-01-25 09:53:12,001] Trial 45 finished with value: 0.06000267437658289 and parameters: {'n_estimators': 633, 'learning_rate': 0.5487150046048779, 'max_depth': 12, 'subsample': 0.7528319479965228, 'colsample_bytree': 0.7228346848269621, 'min_child_weight': 8, 'gamma': 2.1252524037044043, 'reg_alpha': 1.331979187699962, 'reg_lambda': 1.4509929860215154}. Best is trial 37 with value: 0.04557479381061712.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  92%|███████████████████████████████████████████▏   | 46/50 [05:05<00:19,  4.91s/it][I 2025-01-25 09:53:14,945] Trial 46 finished with value: 0.06357185935996847 and parameters: {'n_estimators': 288, 'learning_rate': 0.2664672010334729, 'max_depth': 4, 'subsample': 0.5784370898421539, 'colsample_bytree': 0.6859856372609515, 'min_child_weight': 9, 'gamma': 1.2058915282954001, 'reg_alpha': 0.4034566844460949, 'reg_lambda': 4.138130830386368}. Best is trial 37 with value: 0.04557479381061712.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  94%|████████████████████████████████████████████▏  | 47/50 [05:08<00:12,  4.32s/it][I 2025-01-25 09:53:25,702] Trial 47 finished with value: 0.045608234498289685 and parameters: {'n_estimators': 545, 'learning_rate': 0.6408894159447411, 'max_depth': 9, 'subsample': 0.632051213249, 'colsample_bytree': 0.861902216889754, 'min_child_weight': 10, 'gamma': 0.005735556454683222, 'reg_alpha': 1.0541209856213363, 'reg_lambda': 1.0632696945149385}. Best is trial 37 with value: 0.04557479381061712.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  96%|█████████████████████████████████████████████  | 48/50 [05:19<00:12,  6.25s/it][I 2025-01-25 09:53:30,308] Trial 48 finished with value: 0.06097289798254879 and parameters: {'n_estimators': 559, 'learning_rate': 0.6394224099005174, 'max_depth': 9, 'subsample': 0.6331511654324117, 'colsample_bytree': 0.9447479331813315, 'min_child_weight': 7, 'gamma': 0.5158382253868341, 'reg_alpha': 8.820310464274696, 'reg_lambda': 0.9771700865597908}. Best is trial 37 with value: 0.04557479381061712.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  98%|██████████████████████████████████████████████ | 49/50 [05:24<00:05,  5.76s/it][I 2025-01-25 09:53:34,223] Trial 49 finished with value: 0.0664485415508104 and parameters: {'n_estimators': 451, 'learning_rate': 0.8163969659773105, 'max_depth': 7, 'subsample': 0.5383612843868932, 'colsample_bytree': 0.8590772205948343, 'min_child_weight': 6, 'gamma': 1.5926620332016166, 'reg_alpha': 0.9862337334755998, 'reg_lambda': 0.6280286679409142}. Best is trial 37 with value: 0.04557479381061712.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...: 100%|███████████████████████████████████████████████| 50/50 [05:28<00:00,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최고의 MAPE값 0.04557479381061712 \n",
      "\n",
      "최고의 하이퍼 파라미터 {'n_estimators': 483, 'learning_rate': 0.4070828754571607, 'max_depth': 11, 'subsample': 0.788162582050869, 'colsample_bytree': 0.7808790985869158, 'min_child_weight': 9, 'gamma': 0.011373767322021756, 'reg_alpha': 1.3420045872712598, 'reg_lambda': 0.789042825482067} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------- 반년 주기 추가하고 학습  ---------------------------------------------------\n",
    "\n",
    "# ----------------------------------------------------- 데이터 학습 --------------------------------------------------------------\n",
    "\n",
    "# 목적함수 생성\n",
    "def objective(trial):\n",
    "    params = {\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 100, 1000),  # 트리 개수\n",
    "    'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),  # 학습률\n",
    "    'max_depth': trial.suggest_int('max_depth', 3, 15),  # 트리 최대 깊이\n",
    "    'subsample': trial.suggest_float('subsample', 0.5, 1.0),  # 샘플링 비율\n",
    "    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),  # 특성 샘플링 비율\n",
    "    'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),  # 리프 노드 최소 가중치\n",
    "    'gamma': trial.suggest_float('gamma', 0, 10),  # 최소 손실 감소\n",
    "    'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),  # L1 정규화\n",
    "    'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),  # L2 정규화\n",
    "    \"tree_method\": \"hist\",  # 트리 방법\n",
    "    \"device\": \"cuda\",       # GPU 사용\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    'random_state': 1\n",
    "}\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    xgb_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(train):\n",
    "        x_train, x_val = train.iloc[train_index], train.iloc[val_index]\n",
    "        y_train, y_val = log_y_df[train_index], log_y_df[val_index]\n",
    "\n",
    "        # XGBoost 모델 생성\n",
    "        xgb_model = xgb.XGBRegressor(**params)\n",
    "        xgb_model.fit(x_train, y_train)\n",
    "\n",
    "        # 예측 및 RMSLE 계산\n",
    "        y_pred = np.exp(xgb_model.predict(x_val))\n",
    "        mape = mean_absolute_percentage_error(np.exp(y_val), y_pred)\n",
    "        xgb_scores.append(mape)\n",
    "\n",
    "    return np.mean(xgb_scores)\n",
    "\n",
    "# Optuna 하이퍼파라미터 최적화\n",
    "n_trials = 50\n",
    "xgb_study = optuna.create_study(direction='minimize')\n",
    "\n",
    "for _ in tqdm(range(n_trials), desc='XGBoost 하이퍼파라미터 튜닝 중...'):\n",
    "    xgb_study.optimize(objective, n_trials=1, catch=(Exception,))\n",
    "\n",
    "print('최고의 MAPE값', xgb_study.best_value, '\\n')\n",
    "print('최고의 하이퍼 파라미터', xgb_study.best_params, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd7cdbb2-8725-42fe-8007-2d4027323935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변수 중요도\n",
      "           Feature  Importance\n",
      "1          country    0.681168\n",
      "3          product    0.191800\n",
      "2            store    0.106893\n",
      "15        year_cos    0.004626\n",
      "8      day_of_week    0.004200\n",
      "20    mapped_month    0.002264\n",
      "18           group    0.001641\n",
      "5            month    0.001178\n",
      "9     week_of_year    0.001144\n",
      "12       month_sin    0.001131\n",
      "4             year    0.001088\n",
      "13       month_cos    0.000711\n",
      "6          weekday    0.000519\n",
      "21     mapped_year    0.000502\n",
      "0            index    0.000447\n",
      "14        year_sin    0.000392\n",
      "7              day    0.000119\n",
      "10         day_sin    0.000092\n",
      "19  mapped_weekday    0.000066\n",
      "11         day_cos    0.000021\n",
      "16   half_year_sin    0.000000\n",
      "17   half_year_cos    0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = xgb_study.best_params\n",
    "best_params.update({\n",
    "    \"tree_method\": \"hist\",  # 트리 방법\n",
    "    \"device\": \"cuda\",       # GPU 사용\n",
    "    \"objective\": \"reg:squarederror\"})\n",
    "\n",
    "final_xgb_model = xgb.XGBRegressor(**best_params)\n",
    "final_xgb_model.fit(train, log_y_df)\n",
    "\n",
    "y_pred_log = final_xgb_model.predict(train)\n",
    "y_pred = np.exp(y_pred_log)\n",
    "\n",
    "feature_importances = final_xgb_model.feature_importances_\n",
    "features = train.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature' : features,\n",
    "    'Importance' : feature_importances}).sort_values(by = 'Importance', ascending = False)\n",
    "\n",
    "print('변수 중요도')\n",
    "print(importance_df)\n",
    "\n",
    "# 변수 중요도 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance (XGBoost)')\n",
    "plt.gca().invert_yaxis()  # 중요도가 높은 순서로 표시\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77900ef-fd1f-478e-a01b-4b689cd562af",
   "metadata": {},
   "source": [
    "<div style=\"background-color:red; padding:10px; border-radius:10px; font-size:18px;\">\n",
    "(시도 5)<br><br>\n",
    "군집별 EDA 결과에 기반한 순서인코딩<br>\n",
    "주기성이 있는 sin,cos 파생변수 추가<br>\n",
    "year, month, weekday 그대로 넣고 학습<br>\n",
    "결측치 존재하는 케이스 제외<br>\n",
    "반년 주기 파생변수 추가<br>\n",
    "중복 변수 삭제 및 변수 추가\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76107250-f473-42d4-a898-0a59a42b0a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>year_sin</th>\n",
       "      <th>year_cos</th>\n",
       "      <th>group</th>\n",
       "      <th>mapped_weekday</th>\n",
       "      <th>mapped_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  store  product  year  month  weekday  day  week_of_year   day_sin  \\\n",
       "0        3      0        4  2010      1        4    1            53  0.017213   \n",
       "1        3      0        3  2010      1        4    1            53  0.017213   \n",
       "2        3      0        1  2010      1        4    1            53  0.017213   \n",
       "3        3      0        2  2010      1        4    1            53  0.017213   \n",
       "4        3      1        0  2010      1        4    1            53  0.017213   \n",
       "\n",
       "    day_cos  month_sin  month_cos  year_sin  year_cos  group  mapped_weekday  \\\n",
       "0  0.999852        0.5   0.866025  0.781831   0.62349      4               1   \n",
       "1  0.999852        0.5   0.866025  0.781831   0.62349      4               1   \n",
       "2  0.999852        0.5   0.866025  0.781831   0.62349      4               1   \n",
       "3  0.999852        0.5   0.866025  0.781831   0.62349      4               1   \n",
       "4  0.999852        0.5   0.866025  0.781831   0.62349      4               1   \n",
       "\n",
       "   mapped_month  \n",
       "0             4  \n",
       "1             4  \n",
       "2             4  \n",
       "3             4  \n",
       "4             4  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "train = train.dropna()\n",
    "train = train.reset_index()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------데이터 전처리\n",
    "\n",
    "# 날짜 파생 변수 생성\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "train['year'] = train['date'].dt.year\n",
    "train['month'] = train['date'].dt.month\n",
    "train['weekday'] = train['date'].dt.weekday\n",
    "train['day'] = train['date'].dt.day\n",
    "train['day_of_week'] = train['date'].dt.dayofweek\n",
    "train['week_of_year'] = train['date'].dt.isocalendar().week\n",
    "train['day_sin'] = np.sin(2 * np.pi * train['day'] / 365)\n",
    "train['day_cos'] = np.cos(2 * np.pi * train['day'] / 365)\n",
    "train['month_sin'] = np.sin(2 * np.pi * train['month'] / 12)\n",
    "train['month_cos'] = np.cos(2 * np.pi * train['month'] / 12)\n",
    "train['year_sin'] = np.sin(2 * np.pi * train['year'] / 7)\n",
    "train['year_cos'] = np.cos(2 * np.pi * train['year'] / 7)\n",
    "train['group'] = (train['year'] - 2010) * 48 + train['month'] * 4 + train['day'] // 7\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------ 인코딩\n",
    "\n",
    "country_mapping = {\n",
    "    'Kenya': 0,\n",
    "    'Italy': 1,\n",
    "    'Finland': 2,\n",
    "    'Canada': 3,\n",
    "    'Singapore': 4,\n",
    "    'Norway': 5}\n",
    "train['country'] = train['country'].map(country_mapping)\n",
    "\n",
    "\n",
    "store_mapping = {\n",
    "    'Discount Stickers' : 0,\n",
    "    'Stickers for Less' : 1,\n",
    "    'Premium Sticker Mart' : 2}\n",
    "train['store'] = train['store'].map(store_mapping)\n",
    "\n",
    "\n",
    "product_mapping = {\n",
    "    'Holographic Goose' : 0,\n",
    "    'Kerneler' : 1,\n",
    "    'Kerneler Dark Mode' : 2,\n",
    "    'Kaggle Tiers' : 3,\n",
    "    'Kaggle' : 4}\n",
    "train['product'] = train['product'].map(product_mapping)\n",
    "\n",
    "\n",
    "weekday_mapping = {\n",
    "    0 : 0,\n",
    "    1 : 0,\n",
    "    2 : 0,\n",
    "    3 : 0,\n",
    "    4 : 1,\n",
    "    5 : 2,\n",
    "    6 : 3}\n",
    "train['mapped_weekday'] = train['weekday'].map(weekday_mapping)\n",
    "\n",
    "# 월별 매핑\n",
    "month_mapping = {\n",
    "    2: 1, 5: 1, 4: 1, 3: 1,   \n",
    "    9: 2, 10: 2,              \n",
    "    6: 3, 7: 3, 8: 3,         \n",
    "    1: 4, 11: 4,              \n",
    "    12: 5}                     \n",
    "train['mapped_month'] = train['month'].map(month_mapping)   \n",
    "\n",
    "# 연도별 배핑\n",
    "'''\n",
    "year_mapping = {\n",
    "    2011: 1, 2013: 1,  # 2011년, 2013년 → 1\n",
    "    2012: 2, 2014: 2,  # 2012년, 2014년 → 2\n",
    "    2010: 3, 2015: 3, 2016: 3} # 2010년, 2015년, 2016년 → 3\n",
    "train['mapped_year'] = train['year'].map(year_mapping)\n",
    "'''\n",
    "\n",
    "# 반응변수 추출\n",
    "y_df = train['num_sold']\n",
    "log_y_df = np.log1p(y_df)\n",
    "\n",
    "# 필요없는 변수 삭제\n",
    "train = train.drop(['num_sold', 'id', 'date', 'index', 'day_of_week'] , axis = 1)\n",
    "\n",
    "# 데이터 확인\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db246baf-625f-4cb8-9420-e0dcd8884d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-25 11:47:16,706] A new study created in memory with name: no-name-4d0ccf22-87a1-4de9-88f9-dd1a7f19388b\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   0%|                                                        | 0/50 [00:00<?, ?it/s][I 2025-01-25 11:47:22,432] Trial 0 finished with value: 0.06406594291806526 and parameters: {'n_estimators': 480, 'learning_rate': 0.045309387582025865, 'max_depth': 10, 'subsample': 0.7751637541260858, 'colsample_bytree': 0.5278861960742292, 'min_child_weight': 8, 'gamma': 8.974847516004589, 'reg_alpha': 0.4792475950472408, 'reg_lambda': 0.9277863449960511}. Best is trial 0 with value: 0.06406594291806526.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   2%|▉                                               | 1/50 [00:05<04:40,  5.73s/it][I 2025-01-25 11:47:30,760] Trial 1 finished with value: 0.0647685960200798 and parameters: {'n_estimators': 937, 'learning_rate': 0.048147890159824035, 'max_depth': 10, 'subsample': 0.660083261595001, 'colsample_bytree': 0.9111996892041558, 'min_child_weight': 5, 'gamma': 5.243980218334122, 'reg_alpha': 9.382960233126177, 'reg_lambda': 6.298832917411319}. Best is trial 0 with value: 0.06406594291806526.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   4%|█▉                                              | 2/50 [00:14<05:48,  7.26s/it][I 2025-01-25 11:47:32,446] Trial 2 finished with value: 0.0669477812228435 and parameters: {'n_estimators': 138, 'learning_rate': 0.6490264517162202, 'max_depth': 7, 'subsample': 0.9653228461193495, 'colsample_bytree': 0.9395322610985147, 'min_child_weight': 10, 'gamma': 1.9436809352577655, 'reg_alpha': 9.443384943967255, 'reg_lambda': 8.22201959954796}. Best is trial 0 with value: 0.06406594291806526.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   6%|██▉                                             | 3/50 [00:15<03:41,  4.71s/it][I 2025-01-25 11:47:38,070] Trial 3 finished with value: 0.0559844105011408 and parameters: {'n_estimators': 700, 'learning_rate': 0.22936692350143298, 'max_depth': 12, 'subsample': 0.6892462385153983, 'colsample_bytree': 0.9635028609584638, 'min_child_weight': 5, 'gamma': 1.63870411743812, 'reg_alpha': 1.7644884205134914, 'reg_lambda': 5.427419012687099}. Best is trial 3 with value: 0.0559844105011408.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   8%|███▊                                            | 4/50 [00:21<03:53,  5.07s/it][I 2025-01-25 11:47:41,013] Trial 4 finished with value: 0.0599649401421757 and parameters: {'n_estimators': 327, 'learning_rate': 0.3670807407584007, 'max_depth': 14, 'subsample': 0.625049400750999, 'colsample_bytree': 0.5036738971634083, 'min_child_weight': 9, 'gamma': 1.5260633108668609, 'reg_alpha': 8.529456916905465, 'reg_lambda': 8.130383475596636}. Best is trial 3 with value: 0.0559844105011408.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  10%|████▊                                           | 5/50 [00:24<03:13,  4.30s/it][I 2025-01-25 11:47:45,506] Trial 5 finished with value: 0.07075034157343413 and parameters: {'n_estimators': 588, 'learning_rate': 0.6540762125888955, 'max_depth': 9, 'subsample': 0.6845992907709966, 'colsample_bytree': 0.9212823389847125, 'min_child_weight': 10, 'gamma': 2.6747672378721568, 'reg_alpha': 7.639225188622464, 'reg_lambda': 5.734635605312409}. Best is trial 3 with value: 0.0559844105011408.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  12%|█████▊                                          | 6/50 [00:28<03:12,  4.37s/it][I 2025-01-25 11:47:48,743] Trial 6 finished with value: 0.051092749801731195 and parameters: {'n_estimators': 315, 'learning_rate': 0.19072913901873392, 'max_depth': 7, 'subsample': 0.9857185994149769, 'colsample_bytree': 0.7286676551167224, 'min_child_weight': 9, 'gamma': 0.7310901653632984, 'reg_alpha': 1.253935909312759, 'reg_lambda': 3.0996470512030063}. Best is trial 6 with value: 0.051092749801731195.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  14%|██████▋                                         | 7/50 [00:32<02:51,  4.00s/it][I 2025-01-25 11:47:50,584] Trial 7 finished with value: 0.08130147417692324 and parameters: {'n_estimators': 164, 'learning_rate': 0.674527238570656, 'max_depth': 5, 'subsample': 0.8729668038429528, 'colsample_bytree': 0.8797571793069714, 'min_child_weight': 1, 'gamma': 7.554304093078224, 'reg_alpha': 8.074917280179545, 'reg_lambda': 8.977263490085235}. Best is trial 6 with value: 0.051092749801731195.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  16%|███████▋                                        | 8/50 [00:33<02:19,  3.31s/it][I 2025-01-25 11:47:57,782] Trial 8 finished with value: 0.06587211674763867 and parameters: {'n_estimators': 920, 'learning_rate': 0.09802103195308806, 'max_depth': 12, 'subsample': 0.7635857910532304, 'colsample_bytree': 0.5840777515567137, 'min_child_weight': 3, 'gamma': 9.794779206359715, 'reg_alpha': 5.008478511308598, 'reg_lambda': 7.461413992176315}. Best is trial 6 with value: 0.051092749801731195.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  18%|████████▋                                       | 9/50 [00:41<03:05,  4.53s/it][I 2025-01-25 11:48:04,937] Trial 9 finished with value: 0.057968671474755776 and parameters: {'n_estimators': 914, 'learning_rate': 0.12180789259816917, 'max_depth': 12, 'subsample': 0.9473727725665537, 'colsample_bytree': 0.6328248972720438, 'min_child_weight': 6, 'gamma': 4.189581492039267, 'reg_alpha': 6.832610454829023, 'reg_lambda': 2.1033921455498783}. Best is trial 6 with value: 0.051092749801731195.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  20%|█████████▍                                     | 10/50 [00:48<03:33,  5.34s/it][I 2025-01-25 11:48:08,027] Trial 10 finished with value: 0.059948482618517304 and parameters: {'n_estimators': 335, 'learning_rate': 0.9982277522459572, 'max_depth': 3, 'subsample': 0.8616484731112466, 'colsample_bytree': 0.7280663949945492, 'min_child_weight': 7, 'gamma': 0.20481956986404315, 'reg_alpha': 2.9923965997208466, 'reg_lambda': 3.21976943265631}. Best is trial 6 with value: 0.051092749801731195.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  22%|██████████▎                                    | 11/50 [00:51<03:01,  4.65s/it][I 2025-01-25 11:48:16,337] Trial 11 finished with value: 0.07574028888243031 and parameters: {'n_estimators': 700, 'learning_rate': 0.3222364501068995, 'max_depth': 15, 'subsample': 0.518987420417499, 'colsample_bytree': 0.7764162824339855, 'min_child_weight': 4, 'gamma': 0.05360791245590546, 'reg_alpha': 0.4416488360240842, 'reg_lambda': 3.838890675220614}. Best is trial 6 with value: 0.051092749801731195.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  24%|███████████▎                                   | 12/50 [00:59<03:39,  5.76s/it][I 2025-01-25 11:48:21,730] Trial 12 finished with value: 0.06337342243832403 and parameters: {'n_estimators': 722, 'learning_rate': 0.2943301460026976, 'max_depth': 7, 'subsample': 0.5654384685483511, 'colsample_bytree': 0.7771112735477964, 'min_child_weight': 7, 'gamma': 3.5645391082786926, 'reg_alpha': 2.5751053339551957, 'reg_lambda': 4.330606860084178}. Best is trial 6 with value: 0.051092749801731195.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  26%|████████████▏                                  | 13/50 [01:05<03:29,  5.65s/it][I 2025-01-25 11:48:25,426] Trial 13 finished with value: 0.06219844533282444 and parameters: {'n_estimators': 413, 'learning_rate': 0.22061589546438498, 'max_depth': 7, 'subsample': 0.8454935378860984, 'colsample_bytree': 0.6975556126184111, 'min_child_weight': 3, 'gamma': 6.085375215965482, 'reg_alpha': 2.3887681405212, 'reg_lambda': 2.311334199949542}. Best is trial 6 with value: 0.051092749801731195.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  28%|█████████████▏                                 | 14/50 [01:08<03:02,  5.06s/it][I 2025-01-25 11:48:30,394] Trial 14 finished with value: 0.05744022491780816 and parameters: {'n_estimators': 641, 'learning_rate': 0.4595216444867223, 'max_depth': 12, 'subsample': 0.7142415025085864, 'colsample_bytree': 0.992960570739782, 'min_child_weight': 5, 'gamma': 1.0362309293885996, 'reg_alpha': 3.9948141449226515, 'reg_lambda': 0.12744718867790894}. Best is trial 6 with value: 0.051092749801731195.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  30%|██████████████                                 | 15/50 [01:13<02:56,  5.03s/it][I 2025-01-25 11:48:36,270] Trial 15 finished with value: 0.061231316315678505 and parameters: {'n_estimators': 770, 'learning_rate': 0.20389362327902297, 'max_depth': 5, 'subsample': 0.7984056823618744, 'colsample_bytree': 0.8082613735044338, 'min_child_weight': 8, 'gamma': 2.721773524480566, 'reg_alpha': 1.4973679292043975, 'reg_lambda': 5.290599081817976}. Best is trial 6 with value: 0.051092749801731195.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  32%|███████████████                                | 16/50 [01:19<02:59,  5.29s/it][I 2025-01-25 11:48:38,815] Trial 16 finished with value: 0.06363030852953082 and parameters: {'n_estimators': 266, 'learning_rate': 0.49578690445902995, 'max_depth': 8, 'subsample': 0.9230745450845996, 'colsample_bytree': 0.8387880462578999, 'min_child_weight': 1, 'gamma': 3.496592396801269, 'reg_alpha': 5.239772124251671, 'reg_lambda': 6.593956489775533}. Best is trial 6 with value: 0.051092749801731195.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  34%|███████████████▉                               | 17/50 [01:22<02:27,  4.46s/it][I 2025-01-25 11:48:43,404] Trial 17 finished with value: 0.057677416978088016 and parameters: {'n_estimators': 492, 'learning_rate': 0.18770451597163482, 'max_depth': 13, 'subsample': 0.6055591588118414, 'colsample_bytree': 0.7001084381789721, 'min_child_weight': 6, 'gamma': 1.192184292534899, 'reg_alpha': 1.3664147215749034, 'reg_lambda': 4.620864526816744}. Best is trial 6 with value: 0.051092749801731195.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  36%|████████████████▉                              | 18/50 [01:26<02:24,  4.50s/it][I 2025-01-25 11:48:49,541] Trial 18 finished with value: 0.06646741294928256 and parameters: {'n_estimators': 841, 'learning_rate': 0.3979731119167315, 'max_depth': 10, 'subsample': 0.725576916155135, 'colsample_bytree': 0.6475681067296336, 'min_child_weight': 4, 'gamma': 6.049298578582471, 'reg_alpha': 3.626124631944333, 'reg_lambda': 2.6144428435697287}. Best is trial 6 with value: 0.051092749801731195.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  38%|█████████████████▊                             | 19/50 [01:32<02:34,  4.99s/it][I 2025-01-25 11:48:53,758] Trial 19 finished with value: 0.07036927085104565 and parameters: {'n_estimators': 543, 'learning_rate': 0.9511972687018633, 'max_depth': 4, 'subsample': 0.9861231410311881, 'colsample_bytree': 0.9862052402975154, 'min_child_weight': 8, 'gamma': 2.7644584939454644, 'reg_alpha': 6.103831062663344, 'reg_lambda': 1.4920467646985336}. Best is trial 6 with value: 0.051092749801731195.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  40%|██████████████████▊                            | 20/50 [01:37<02:22,  4.76s/it][I 2025-01-25 11:48:56,864] Trial 20 finished with value: 0.05320698394629321 and parameters: {'n_estimators': 262, 'learning_rate': 0.2572170671519033, 'max_depth': 11, 'subsample': 0.8106775312253742, 'colsample_bytree': 0.8514924467076157, 'min_child_weight': 3, 'gamma': 0.5811449810882694, 'reg_alpha': 1.6416712261497874, 'reg_lambda': 9.915578929133925}. Best is trial 6 with value: 0.051092749801731195.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  42%|███████████████████▋                           | 21/50 [01:40<02:03,  4.26s/it][I 2025-01-25 11:48:59,628] Trial 21 finished with value: 0.05274010136455085 and parameters: {'n_estimators': 212, 'learning_rate': 0.2673547362067336, 'max_depth': 11, 'subsample': 0.8098581455781709, 'colsample_bytree': 0.8550106935760821, 'min_child_weight': 2, 'gamma': 0.5678064431493786, 'reg_alpha': 1.5307503926252464, 'reg_lambda': 9.704502414672167}. Best is trial 6 with value: 0.051092749801731195.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  44%|████████████████████▋                          | 22/50 [01:42<01:46,  3.81s/it][I 2025-01-25 11:49:01,966] Trial 22 finished with value: 0.06156652767513039 and parameters: {'n_estimators': 226, 'learning_rate': 0.5613824857813672, 'max_depth': 9, 'subsample': 0.8147732071605986, 'colsample_bytree': 0.8520837954838097, 'min_child_weight': 2, 'gamma': 0.6520003809533681, 'reg_alpha': 0.10955657672341057, 'reg_lambda': 9.94214447304096}. Best is trial 6 with value: 0.051092749801731195.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  46%|█████████████████████▌                         | 23/50 [01:45<01:31,  3.37s/it][I 2025-01-25 11:49:03,814] Trial 23 finished with value: 0.056937848250850874 and parameters: {'n_estimators': 104, 'learning_rate': 0.288679642360574, 'max_depth': 11, 'subsample': 0.906918628183529, 'colsample_bytree': 0.8080799479014364, 'min_child_weight': 2, 'gamma': 2.017563591159327, 'reg_alpha': 3.873495482911184, 'reg_lambda': 9.983634592328784}. Best is trial 6 with value: 0.051092749801731195.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  48%|██████████████████████▌                        | 24/50 [01:47<01:15,  2.91s/it][I 2025-01-25 11:49:07,951] Trial 24 finished with value: 0.05017049243728091 and parameters: {'n_estimators': 389, 'learning_rate': 0.14078549897368828, 'max_depth': 8, 'subsample': 0.8371432119520548, 'colsample_bytree': 0.8733249423345134, 'min_child_weight': 3, 'gamma': 0.5311736562904439, 'reg_alpha': 1.1274486234582717, 'reg_lambda': 9.192165010253524}. Best is trial 24 with value: 0.05017049243728091.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  50%|███████████████████████▌                       | 25/50 [01:51<01:22,  3.28s/it][I 2025-01-25 11:49:12,064] Trial 25 finished with value: 0.0491188229271793 and parameters: {'n_estimators': 401, 'learning_rate': 0.13528473758009274, 'max_depth': 6, 'subsample': 0.8982409778002113, 'colsample_bytree': 0.8808519186576231, 'min_child_weight': 2, 'gamma': 0.1655818965088537, 'reg_alpha': 0.9747679414553947, 'reg_lambda': 8.997772474807027}. Best is trial 25 with value: 0.0491188229271793.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  52%|████████████████████████▍                      | 26/50 [01:55<01:24,  3.53s/it][I 2025-01-25 11:49:15,994] Trial 26 finished with value: 0.05512883926562172 and parameters: {'n_estimators': 401, 'learning_rate': 0.11795418456477719, 'max_depth': 6, 'subsample': 0.9009932812101769, 'colsample_bytree': 0.7408248327879723, 'min_child_weight': 4, 'gamma': 2.210758729892808, 'reg_alpha': 0.6346714377588598, 'reg_lambda': 7.370355255885871}. Best is trial 25 with value: 0.0491188229271793.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  54%|█████████████████████████▍                     | 27/50 [01:59<01:23,  3.65s/it][I 2025-01-25 11:49:23,033] Trial 27 finished with value: 0.05390973809400083 and parameters: {'n_estimators': 394, 'learning_rate': 0.02569915811891764, 'max_depth': 6, 'subsample': 0.99733454884761, 'colsample_bytree': 0.9051926923993889, 'min_child_weight': 1, 'gamma': 1.2472462736984768, 'reg_alpha': 0.9546679723594718, 'reg_lambda': 8.957029113923529}. Best is trial 25 with value: 0.0491188229271793.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  56%|██████████████████████████▎                    | 28/50 [02:06<01:42,  4.67s/it][I 2025-01-25 11:49:28,123] Trial 28 finished with value: 0.04525799803839885 and parameters: {'n_estimators': 345, 'learning_rate': 0.1330004281834499, 'max_depth': 8, 'subsample': 0.946508080529431, 'colsample_bytree': 0.8014864838752842, 'min_child_weight': 2, 'gamma': 0.017671059071366346, 'reg_alpha': 3.1517620062413902, 'reg_lambda': 3.676038975936166}. Best is trial 28 with value: 0.04525799803839885.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  58%|███████████████████████████▎                   | 29/50 [02:11<01:40,  4.79s/it][I 2025-01-25 11:49:37,588] Trial 29 finished with value: 0.06387882355070935 and parameters: {'n_estimators': 522, 'learning_rate': 0.016289611530581394, 'max_depth': 8, 'subsample': 0.9367578393582288, 'colsample_bytree': 0.8096080797007836, 'min_child_weight': 2, 'gamma': 8.276273811125257, 'reg_alpha': 2.38974216270315, 'reg_lambda': 8.783462292212985}. Best is trial 28 with value: 0.04525799803839885.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  60%|████████████████████████████▏                  | 30/50 [02:20<02:03,  6.20s/it][I 2025-01-25 11:49:43,056] Trial 30 finished with value: 0.04759882514913126 and parameters: {'n_estimators': 427, 'learning_rate': 0.1062825661625849, 'max_depth': 9, 'subsample': 0.8990139779977506, 'colsample_bytree': 0.8893991885229944, 'min_child_weight': 3, 'gamma': 0.1517099146677076, 'reg_alpha': 3.439369045858416, 'reg_lambda': 7.1738620781863816}. Best is trial 28 with value: 0.04525799803839885.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  62%|█████████████████████████████▏                 | 31/50 [02:26<01:53,  5.98s/it][I 2025-01-25 11:49:47,828] Trial 31 finished with value: 0.04916410146603324 and parameters: {'n_estimators': 460, 'learning_rate': 0.14262490693494162, 'max_depth': 9, 'subsample': 0.8860316654566583, 'colsample_bytree': 0.887232727865757, 'min_child_weight': 3, 'gamma': 0.3477090701187413, 'reg_alpha': 3.2270518456377966, 'reg_lambda': 7.310488910244559}. Best is trial 28 with value: 0.04525799803839885.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  64%|██████████████████████████████                 | 32/50 [02:31<01:41,  5.62s/it][I 2025-01-25 11:49:58,342] Trial 32 finished with value: 0.043960694841799194 and parameters: {'n_estimators': 463, 'learning_rate': 0.07986115420116802, 'max_depth': 10, 'subsample': 0.8802837273216751, 'colsample_bytree': 0.900167513749665, 'min_child_weight': 2, 'gamma': 0.0059702090121105614, 'reg_alpha': 3.312339261946142, 'reg_lambda': 7.033865824347269}. Best is trial 32 with value: 0.043960694841799194.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  66%|███████████████████████████████                | 33/50 [02:41<02:00,  7.08s/it][I 2025-01-25 11:50:05,280] Trial 33 finished with value: 0.05348143452930282 and parameters: {'n_estimators': 586, 'learning_rate': 0.06127626172576482, 'max_depth': 10, 'subsample': 0.9559800610380186, 'colsample_bytree': 0.9549835383283171, 'min_child_weight': 1, 'gamma': 1.3660388534777623, 'reg_alpha': 4.383490922944497, 'reg_lambda': 6.604364281388083}. Best is trial 32 with value: 0.043960694841799194.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  68%|███████████████████████████████▉               | 34/50 [02:48<01:52,  7.04s/it][I 2025-01-25 11:50:12,160] Trial 34 finished with value: 0.04738598972618637 and parameters: {'n_estimators': 465, 'learning_rate': 0.07281954669427251, 'max_depth': 9, 'subsample': 0.9083850333446319, 'colsample_bytree': 0.9296461981333461, 'min_child_weight': 2, 'gamma': 0.13002005366034913, 'reg_alpha': 4.465394061251394, 'reg_lambda': 5.996347121645087}. Best is trial 32 with value: 0.043960694841799194.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  70%|████████████████████████████████▉              | 35/50 [02:55<01:44,  6.99s/it][I 2025-01-25 11:50:22,643] Trial 35 finished with value: 0.045393693335954985 and parameters: {'n_estimators': 611, 'learning_rate': 0.06796270166831828, 'max_depth': 10, 'subsample': 0.9393646873986878, 'colsample_bytree': 0.9245252870203974, 'min_child_weight': 4, 'gamma': 0.019000444854425425, 'reg_alpha': 5.574734938911915, 'reg_lambda': 6.117172739500319}. Best is trial 32 with value: 0.043960694841799194.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  72%|█████████████████████████████████▊             | 36/50 [03:05<01:52,  8.04s/it][I 2025-01-25 11:50:28,936] Trial 36 finished with value: 0.054720781754250505 and parameters: {'n_estimators': 486, 'learning_rate': 0.05889086911850232, 'max_depth': 10, 'subsample': 0.9579541802082346, 'colsample_bytree': 0.9376902145598275, 'min_child_weight': 4, 'gamma': 1.8733386735266242, 'reg_alpha': 5.799872757370338, 'reg_lambda': 5.944113971528181}. Best is trial 32 with value: 0.043960694841799194.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  74%|██████████████████████████████████▊            | 37/50 [03:12<01:37,  7.52s/it][I 2025-01-25 11:50:34,476] Trial 37 finished with value: 0.06047656483871662 and parameters: {'n_estimators': 585, 'learning_rate': 0.07407454201502639, 'max_depth': 8, 'subsample': 0.9302652967103364, 'colsample_bytree': 0.9317726535127526, 'min_child_weight': 5, 'gamma': 4.965319245918541, 'reg_alpha': 4.4811918300281945, 'reg_lambda': 4.848873313224015}. Best is trial 32 with value: 0.043960694841799194.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  76%|███████████████████████████████████▋           | 38/50 [03:17<01:23,  6.92s/it][I 2025-01-25 11:50:39,513] Trial 38 finished with value: 0.06652160804733642 and parameters: {'n_estimators': 674, 'learning_rate': 0.7106030154005998, 'max_depth': 11, 'subsample': 0.9736359863796401, 'colsample_bytree': 0.9647147998709329, 'min_child_weight': 2, 'gamma': 2.348728968103832, 'reg_alpha': 5.700953186889195, 'reg_lambda': 6.182156513830682}. Best is trial 32 with value: 0.043960694841799194.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  78%|████████████████████████████████████▋          | 39/50 [03:22<01:09,  6.36s/it][I 2025-01-25 11:50:59,129] Trial 39 finished with value: 0.05492997485041971 and parameters: {'n_estimators': 637, 'learning_rate': 0.010594412097324507, 'max_depth': 13, 'subsample': 0.8625680403059168, 'colsample_bytree': 0.9146082202150562, 'min_child_weight': 1, 'gamma': 1.0274737645846967, 'reg_alpha': 6.944661713970283, 'reg_lambda': 8.021595388118683}. Best is trial 32 with value: 0.043960694841799194.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  80%|█████████████████████████████████████▌         | 40/50 [03:42<01:43, 10.33s/it][I 2025-01-25 11:51:02,170] Trial 40 finished with value: 0.06385106120176066 and parameters: {'n_estimators': 351, 'learning_rate': 0.7630582152503662, 'max_depth': 10, 'subsample': 0.9246942617802585, 'colsample_bytree': 0.9652389870879121, 'min_child_weight': 4, 'gamma': 1.4968501298486525, 'reg_alpha': 4.60392347722604, 'reg_lambda': 4.086652471218515}. Best is trial 32 with value: 0.043960694841799194.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  82%|██████████████████████████████████████▌        | 41/50 [03:45<01:13,  8.15s/it][I 2025-01-25 11:51:08,279] Trial 41 finished with value: 0.04456455383005649 and parameters: {'n_estimators': 451, 'learning_rate': 0.18090341668306514, 'max_depth': 9, 'subsample': 0.8720671390470719, 'colsample_bytree': 0.9115009447261146, 'min_child_weight': 3, 'gamma': 0.007384277263747605, 'reg_alpha': 3.2764134460460625, 'reg_lambda': 6.950902063361813}. Best is trial 32 with value: 0.043960694841799194.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  84%|███████████████████████████████████████▍       | 42/50 [03:51<01:00,  7.54s/it][I 2025-01-25 11:51:13,901] Trial 42 finished with value: 0.05216737983872034 and parameters: {'n_estimators': 457, 'learning_rate': 0.07705332497896059, 'max_depth': 9, 'subsample': 0.8415589800844206, 'colsample_bytree': 0.9228360090822009, 'min_child_weight': 2, 'gamma': 0.9142651438075928, 'reg_alpha': 5.212888706262092, 'reg_lambda': 5.430367514467552}. Best is trial 32 with value: 0.043960694841799194.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  86%|████████████████████████████████████████▍      | 43/50 [03:57<00:48,  6.96s/it][I 2025-01-25 11:51:18,769] Trial 43 finished with value: 0.0547804172794563 and parameters: {'n_estimators': 550, 'learning_rate': 0.17179620195702258, 'max_depth': 8, 'subsample': 0.7758105687157436, 'colsample_bytree': 0.9036956813888237, 'min_child_weight': 3, 'gamma': 1.5466923910667725, 'reg_alpha': 2.9243295041829014, 'reg_lambda': 6.7806889568228375}. Best is trial 32 with value: 0.043960694841799194.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  88%|█████████████████████████████████████████▎     | 44/50 [04:02<00:38,  6.33s/it][I 2025-01-25 11:51:24,319] Trial 44 finished with value: 0.045063439675868996 and parameters: {'n_estimators': 521, 'learning_rate': 0.3378125854075147, 'max_depth': 9, 'subsample': 0.8748820707464052, 'colsample_bytree': 0.9466030234947824, 'min_child_weight': 4, 'gamma': 0.008374102950887087, 'reg_alpha': 2.1357271573719516, 'reg_lambda': 7.771330164293231}. Best is trial 32 with value: 0.043960694841799194.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  90%|██████████████████████████████████████████▎    | 45/50 [04:07<00:30,  6.10s/it][I 2025-01-25 11:51:27,709] Trial 45 finished with value: 0.05332367389763548 and parameters: {'n_estimators': 359, 'learning_rate': 0.3750897916254448, 'max_depth': 10, 'subsample': 0.8770271425814727, 'colsample_bytree': 0.9973105761962949, 'min_child_weight': 5, 'gamma': 0.7876077730971967, 'reg_alpha': 2.0858119155152015, 'reg_lambda': 7.863605026230758}. Best is trial 32 with value: 0.043960694841799194.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  92%|███████████████████████████████████████████▏   | 46/50 [04:11<00:21,  5.29s/it][I 2025-01-25 11:51:30,904] Trial 46 finished with value: 0.050091573454239445 and parameters: {'n_estimators': 295, 'learning_rate': 0.3318991184060178, 'max_depth': 7, 'subsample': 0.9622674632406971, 'colsample_bytree': 0.950715434900402, 'min_child_weight': 4, 'gamma': 0.0685341118180182, 'reg_alpha': 9.817750003425818, 'reg_lambda': 8.247562595940144}. Best is trial 32 with value: 0.043960694841799194.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  94%|████████████████████████████████████████████▏  | 47/50 [04:14<00:13,  4.66s/it][I 2025-01-25 11:51:35,707] Trial 47 finished with value: 0.06479754101504175 and parameters: {'n_estimators': 625, 'learning_rate': 0.422856897207214, 'max_depth': 11, 'subsample': 0.7815013835143294, 'colsample_bytree': 0.8293381975379803, 'min_child_weight': 3, 'gamma': 3.3626954460920166, 'reg_alpha': 3.033387164365937, 'reg_lambda': 6.969486042890596}. Best is trial 32 with value: 0.043960694841799194.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  96%|█████████████████████████████████████████████  | 48/50 [04:19<00:09,  4.70s/it][I 2025-01-25 11:51:41,770] Trial 48 finished with value: 0.05588283560074884 and parameters: {'n_estimators': 761, 'learning_rate': 0.1672389712014304, 'max_depth': 8, 'subsample': 0.7452619409887942, 'colsample_bytree': 0.9768363628330357, 'min_child_weight': 6, 'gamma': 1.739080423929872, 'reg_alpha': 2.7006928401953094, 'reg_lambda': 3.6741297640861124}. Best is trial 32 with value: 0.043960694841799194.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  98%|██████████████████████████████████████████████ | 49/50 [04:25<00:05,  5.11s/it][I 2025-01-25 11:51:46,004] Trial 49 finished with value: 0.06677784741745321 and parameters: {'n_estimators': 509, 'learning_rate': 0.237966631508924, 'max_depth': 9, 'subsample': 0.834072788554682, 'colsample_bytree': 0.7736182528590387, 'min_child_weight': 5, 'gamma': 9.515715904941251, 'reg_alpha': 1.9975083507494382, 'reg_lambda': 5.523432608306646}. Best is trial 32 with value: 0.043960694841799194.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...: 100%|███████████████████████████████████████████████| 50/50 [04:29<00:00,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최고의 MAPE값 0.043960694841799194 \n",
      "\n",
      "최고의 하이퍼 파라미터 {'n_estimators': 463, 'learning_rate': 0.07986115420116802, 'max_depth': 10, 'subsample': 0.8802837273216751, 'colsample_bytree': 0.900167513749665, 'min_child_weight': 2, 'gamma': 0.0059702090121105614, 'reg_alpha': 3.312339261946142, 'reg_lambda': 7.033865824347269} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# --------------------------------------------- 중복변수 삭제 및 변수 추가  ---------------------------------------------------\n",
    "\n",
    "# ----------------------------------------------------- 데이터 학습 --------------------------------------------------------------\n",
    "\n",
    "# 목적함수 생성\n",
    "def objective(trial):\n",
    "    params = {\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 100, 1000),  # 트리 개수\n",
    "    'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),  # 학습률\n",
    "    'max_depth': trial.suggest_int('max_depth', 3, 15),  # 트리 최대 깊이\n",
    "    'subsample': trial.suggest_float('subsample', 0.5, 1.0),  # 샘플링 비율\n",
    "    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),  # 특성 샘플링 비율\n",
    "    'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),  # 리프 노드 최소 가중치\n",
    "    'gamma': trial.suggest_float('gamma', 0, 10),  # 최소 손실 감소\n",
    "    'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),  # L1 정규화\n",
    "    'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),  # L2 정규화\n",
    "    \"tree_method\": \"hist\",  # 트리 방법\n",
    "    \"device\": \"cuda\",       # GPU 사용\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    'random_state': 1\n",
    "}\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    xgb_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(train):\n",
    "        x_train, x_val = train.iloc[train_index], train.iloc[val_index]\n",
    "        y_train, y_val = log_y_df[train_index], log_y_df[val_index]\n",
    "\n",
    "        # XGBoost 모델 생성\n",
    "        xgb_model = xgb.XGBRegressor(**params)\n",
    "        xgb_model.fit(x_train, y_train)\n",
    "\n",
    "        # 예측 및 RMSLE 계산\n",
    "        y_pred = np.exp(xgb_model.predict(x_val))\n",
    "        mape = mean_absolute_percentage_error(np.exp(y_val), y_pred)\n",
    "        xgb_scores.append(mape)\n",
    "\n",
    "    return np.mean(xgb_scores)\n",
    "\n",
    "# Optuna 하이퍼파라미터 최적화\n",
    "n_trials = 50\n",
    "xgb_study = optuna.create_study(direction='minimize')\n",
    "\n",
    "for _ in tqdm(range(n_trials), desc='XGBoost 하이퍼파라미터 튜닝 중...'):\n",
    "    xgb_study.optimize(objective, n_trials=1, catch=(Exception,))\n",
    "\n",
    "print('최고의 MAPE값', xgb_study.best_value, '\\n')\n",
    "print('최고의 하이퍼 파라미터', xgb_study.best_params, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d90978d3-d7f8-46c2-94eb-0c89062cefd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변수 중요도\n",
      "           Feature  Importance\n",
      "0          country    0.701473\n",
      "1            store    0.143670\n",
      "2          product    0.140071\n",
      "13        year_cos    0.003651\n",
      "5          weekday    0.002068\n",
      "16    mapped_month    0.001834\n",
      "10       month_sin    0.001363\n",
      "3             year    0.001180\n",
      "4            month    0.001010\n",
      "15  mapped_weekday    0.000870\n",
      "11       month_cos    0.000797\n",
      "7     week_of_year    0.000786\n",
      "14           group    0.000742\n",
      "12        year_sin    0.000342\n",
      "8          day_sin    0.000079\n",
      "6              day    0.000063\n",
      "9          day_cos    0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_params = xgb_study.best_params\n",
    "best_params.update({\n",
    "    \"tree_method\": \"hist\",  # 트리 방법\n",
    "    \"device\": \"cuda\",       # GPU 사용\n",
    "    \"objective\": \"reg:squarederror\"})\n",
    "\n",
    "final_xgb_model = xgb.XGBRegressor(**best_params)\n",
    "final_xgb_model.fit(train, log_y_df)\n",
    "\n",
    "y_pred_log = final_xgb_model.predict(train)\n",
    "y_pred = np.exp(y_pred_log)\n",
    "\n",
    "feature_importances = final_xgb_model.feature_importances_\n",
    "features = train.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature' : features,\n",
    "    'Importance' : feature_importances}).sort_values(by = 'Importance', ascending = False)\n",
    "\n",
    "print('변수 중요도')\n",
    "print(importance_df)\n",
    "\n",
    "# 변수 중요도 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance (XGBoost)')\n",
    "plt.gca().invert_yaxis()  # 중요도가 높은 순서로 표시\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42355b51-2bcf-4311-93e8-56f4e08627f6",
   "metadata": {},
   "source": [
    "<div style=\"background-color:red; padding:10px; border-radius:10px; font-size:18px;\">\n",
    "(시도 6)<br><br>\n",
    "군집별 EDA 결과에 기반한 순서인코딩<br>\n",
    "주기성이 있는 sin,cos 파생변수 추가<br>\n",
    "year, month, weekday 그대로 넣고 학습<br>\n",
    "결측치 존재하는 케이스 제외<br>\n",
    "반년 주기 파생변수 추가<br>\n",
    "중복 변수 삭제 및 변수 추가<br>\n",
    "하이퍼 파라미터 탐색공간 확장\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a007939a-086b-4775-a9a4-90170bba2976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-25 11:51:48,526] A new study created in memory with name: no-name-24fa1339-0659-41b1-865f-e89a50abd7ee\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   0%|                                                       | 0/200 [00:00<?, ?it/s][I 2025-01-25 11:51:58,504] Trial 0 finished with value: 0.05570785759142087 and parameters: {'n_estimators': 1397, 'learning_rate': 0.26069487328913904, 'max_depth': 11, 'subsample': 0.9226407803609522, 'colsample_bytree': 0.5540990607457641, 'min_child_weight': 8, 'gamma': 2.0748377311154877, 'reg_alpha': 8.24033027237687, 'reg_lambda': 9.89652652653403}. Best is trial 0 with value: 0.05570785759142087.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   0%|▏                                              | 1/200 [00:09<33:05,  9.98s/it][I 2025-01-25 11:52:09,431] Trial 1 finished with value: 0.06496460387898735 and parameters: {'n_estimators': 1609, 'learning_rate': 0.4674879818637594, 'max_depth': 13, 'subsample': 0.6027801222373435, 'colsample_bytree': 0.7012507180613532, 'min_child_weight': 3, 'gamma': 1.106109238670857, 'reg_alpha': 4.741751419004032, 'reg_lambda': 7.015793760370821}. Best is trial 0 with value: 0.05570785759142087.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   1%|▍                                              | 2/200 [00:20<34:45, 10.54s/it][I 2025-01-25 11:52:21,855] Trial 2 finished with value: 0.0729678221908467 and parameters: {'n_estimators': 1807, 'learning_rate': 0.5456190736477716, 'max_depth': 6, 'subsample': 0.6679492268421998, 'colsample_bytree': 0.8828274840033179, 'min_child_weight': 1, 'gamma': 5.423097080066607, 'reg_alpha': 7.5474648853403945, 'reg_lambda': 9.806125589227843}. Best is trial 0 with value: 0.05570785759142087.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   2%|▋                                              | 3/200 [00:33<37:25, 11.40s/it][I 2025-01-25 11:52:30,676] Trial 3 finished with value: 0.06797069886107195 and parameters: {'n_estimators': 1263, 'learning_rate': 0.6042233137346866, 'max_depth': 11, 'subsample': 0.6759332066793715, 'colsample_bytree': 0.6030929531016394, 'min_child_weight': 3, 'gamma': 5.130481736321578, 'reg_alpha': 4.811231491784788, 'reg_lambda': 0.24543756784077164}. Best is trial 0 with value: 0.05570785759142087.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   2%|▉                                              | 4/200 [00:42<33:54, 10.38s/it][I 2025-01-25 11:52:40,672] Trial 4 finished with value: 0.06464245652843428 and parameters: {'n_estimators': 1436, 'learning_rate': 0.14255162063766588, 'max_depth': 15, 'subsample': 0.9669735848425476, 'colsample_bytree': 0.9901489977882147, 'min_child_weight': 7, 'gamma': 7.660126835016063, 'reg_alpha': 8.655372741535233, 'reg_lambda': 8.36266867314601}. Best is trial 0 with value: 0.05570785759142087.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   2%|█▏                                             | 5/200 [00:52<33:17, 10.24s/it][I 2025-01-25 11:52:51,229] Trial 5 finished with value: 0.07905567525540359 and parameters: {'n_estimators': 1529, 'learning_rate': 0.9810343265945769, 'max_depth': 4, 'subsample': 0.785109245718986, 'colsample_bytree': 0.837335914315207, 'min_child_weight': 5, 'gamma': 2.8314183994349573, 'reg_alpha': 5.9359814135270454, 'reg_lambda': 0.005110241785757363}. Best is trial 0 with value: 0.05570785759142087.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   3%|█▍                                             | 6/200 [01:02<33:27, 10.35s/it][I 2025-01-25 11:53:04,128] Trial 6 finished with value: 0.05973470252446933 and parameters: {'n_estimators': 1908, 'learning_rate': 0.47743123463533677, 'max_depth': 9, 'subsample': 0.8148274071537778, 'colsample_bytree': 0.7658141074885314, 'min_child_weight': 2, 'gamma': 0.9032426154130202, 'reg_alpha': 3.3513717163815904, 'reg_lambda': 5.619875986594835}. Best is trial 0 with value: 0.05570785759142087.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   4%|█▋                                             | 7/200 [01:15<35:58, 11.18s/it][I 2025-01-25 11:53:12,733] Trial 7 finished with value: 0.07676265246199092 and parameters: {'n_estimators': 1227, 'learning_rate': 0.9667924001335553, 'max_depth': 14, 'subsample': 0.8739894755298739, 'colsample_bytree': 0.6861018123162181, 'min_child_weight': 10, 'gamma': 8.871859038815446, 'reg_alpha': 5.367905418924924, 'reg_lambda': 8.005887480346901}. Best is trial 0 with value: 0.05570785759142087.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   4%|█▉                                             | 8/200 [01:24<33:09, 10.36s/it][I 2025-01-25 11:53:22,502] Trial 8 finished with value: 0.06617339524743654 and parameters: {'n_estimators': 1448, 'learning_rate': 0.6325016272487427, 'max_depth': 9, 'subsample': 0.7448381919474312, 'colsample_bytree': 0.6849412591944781, 'min_child_weight': 10, 'gamma': 3.071824487497504, 'reg_alpha': 0.8877903911856933, 'reg_lambda': 7.108165940983487}. Best is trial 0 with value: 0.05570785759142087.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   4%|██                                             | 9/200 [01:33<32:23, 10.18s/it][I 2025-01-25 11:53:30,874] Trial 9 finished with value: 0.07024711047063707 and parameters: {'n_estimators': 1188, 'learning_rate': 0.3290201403655039, 'max_depth': 7, 'subsample': 0.6816684125664347, 'colsample_bytree': 0.7467187991786703, 'min_child_weight': 3, 'gamma': 8.915631380339866, 'reg_alpha': 3.6937870058174727, 'reg_lambda': 2.109143596295442}. Best is trial 0 with value: 0.05570785759142087.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   5%|██▎                                           | 10/200 [01:42<30:27,  9.62s/it][I 2025-01-25 11:53:41,883] Trial 10 finished with value: 0.05550064204184797 and parameters: {'n_estimators': 702, 'learning_rate': 0.021510976925608577, 'max_depth': 12, 'subsample': 0.9985521080071624, 'colsample_bytree': 0.5169872364219978, 'min_child_weight': 7, 'gamma': 3.123699111969618, 'reg_alpha': 9.801334414625279, 'reg_lambda': 3.9507558352216856}. Best is trial 10 with value: 0.05550064204184797.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   6%|██▌                                           | 11/200 [01:53<31:38, 10.04s/it][I 2025-01-25 11:53:54,998] Trial 11 finished with value: 0.0798203023105179 and parameters: {'n_estimators': 593, 'learning_rate': 0.01104044387254191, 'max_depth': 12, 'subsample': 0.9986693371576633, 'colsample_bytree': 0.5162882028075882, 'min_child_weight': 7, 'gamma': 2.9141694172890347, 'reg_alpha': 9.07256262868528, 'reg_lambda': 3.3811341959721486}. Best is trial 10 with value: 0.05550064204184797.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   6%|██▊                                           | 12/200 [02:06<34:23, 10.98s/it][I 2025-01-25 11:54:00,526] Trial 12 finished with value: 0.05836074216855366 and parameters: {'n_estimators': 668, 'learning_rate': 0.2001992998167588, 'max_depth': 11, 'subsample': 0.9062313485810979, 'colsample_bytree': 0.5054687423957593, 'min_child_weight': 8, 'gamma': 3.844583304866638, 'reg_alpha': 9.706483042038903, 'reg_lambda': 4.7749433559437815}. Best is trial 10 with value: 0.05550064204184797.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   6%|██▉                                           | 13/200 [02:11<29:04,  9.33s/it][I 2025-01-25 11:54:06,989] Trial 13 finished with value: 0.2416208994816186 and parameters: {'n_estimators': 181, 'learning_rate': 0.017665622202681558, 'max_depth': 10, 'subsample': 0.9166778017590361, 'colsample_bytree': 0.5815012272739293, 'min_child_weight': 8, 'gamma': 0.3225421612947561, 'reg_alpha': 7.387694623344673, 'reg_lambda': 3.8885246320398696}. Best is trial 10 with value: 0.05550064204184797.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   7%|███▏                                          | 14/200 [02:18<26:14,  8.46s/it][I 2025-01-25 11:54:13,054] Trial 14 finished with value: 0.055854145321339366 and parameters: {'n_estimators': 786, 'learning_rate': 0.25660587181206074, 'max_depth': 13, 'subsample': 0.8570884707295906, 'colsample_bytree': 0.5948413484085942, 'min_child_weight': 5, 'gamma': 1.6744638545133261, 'reg_alpha': 7.3834643493501835, 'reg_lambda': 2.098977884279374}. Best is trial 10 with value: 0.05550064204184797.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   8%|███▍                                          | 15/200 [02:24<23:51,  7.74s/it][I 2025-01-25 11:54:19,846] Trial 15 finished with value: 0.061779354655226285 and parameters: {'n_estimators': 914, 'learning_rate': 0.3230752601188054, 'max_depth': 7, 'subsample': 0.9529820468760128, 'colsample_bytree': 0.5628486466343812, 'min_child_weight': 6, 'gamma': 6.571631705846913, 'reg_alpha': 9.807103182759459, 'reg_lambda': 5.763025125707727}. Best is trial 10 with value: 0.05550064204184797.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   8%|███▋                                          | 16/200 [02:31<22:51,  7.45s/it][I 2025-01-25 11:54:24,160] Trial 16 finished with value: 0.05839259851501712 and parameters: {'n_estimators': 411, 'learning_rate': 0.11041036735282021, 'max_depth': 15, 'subsample': 0.9968257803778094, 'colsample_bytree': 0.6489232589880671, 'min_child_weight': 9, 'gamma': 4.294056096164351, 'reg_alpha': 8.165312015562225, 'reg_lambda': 9.726096556983993}. Best is trial 10 with value: 0.05550064204184797.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   8%|███▉                                          | 17/200 [02:35<19:51,  6.51s/it][I 2025-01-25 11:54:31,174] Trial 17 finished with value: 0.06320883860437161 and parameters: {'n_estimators': 986, 'learning_rate': 0.747734645698125, 'max_depth': 10, 'subsample': 0.8413415260371467, 'colsample_bytree': 0.5014417431419479, 'min_child_weight': 6, 'gamma': 1.5998055586751547, 'reg_alpha': 6.497432989550082, 'reg_lambda': 1.7650526646381879}. Best is trial 10 with value: 0.05550064204184797.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:   9%|████▏                                         | 18/200 [02:42<20:12,  6.66s/it][I 2025-01-25 11:54:34,621] Trial 18 finished with value: 0.0621407243450882 and parameters: {'n_estimators': 391, 'learning_rate': 0.399130542834679, 'max_depth': 12, 'subsample': 0.9224601087845316, 'colsample_bytree': 0.622954505368015, 'min_child_weight': 8, 'gamma': 6.255325186920602, 'reg_alpha': 1.4737182788307424, 'reg_lambda': 3.552519543161419}. Best is trial 10 with value: 0.05550064204184797.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  10%|████▎                                         | 19/200 [02:46<17:10,  5.70s/it][I 2025-01-25 11:54:42,812] Trial 19 finished with value: 0.059053064305590784 and parameters: {'n_estimators': 1080, 'learning_rate': 0.12893589664043548, 'max_depth': 9, 'subsample': 0.506456207331113, 'colsample_bytree': 0.5545438595052905, 'min_child_weight': 9, 'gamma': 2.2928021975749155, 'reg_alpha': 8.894278606091266, 'reg_lambda': 4.799354457157441}. Best is trial 10 with value: 0.05550064204184797.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  10%|████▌                                         | 20/200 [02:54<19:20,  6.45s/it][I 2025-01-25 11:54:54,368] Trial 20 finished with value: 0.08403571842186289 and parameters: {'n_estimators': 1710, 'learning_rate': 0.25054975153732795, 'max_depth': 3, 'subsample': 0.7769547669170024, 'colsample_bytree': 0.801927000716876, 'min_child_weight': 7, 'gamma': 4.091212068688552, 'reg_alpha': 9.915995010816124, 'reg_lambda': 6.540533446851827}. Best is trial 10 with value: 0.05550064204184797.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  10%|████▊                                         | 21/200 [03:05<23:48,  7.98s/it][I 2025-01-25 11:55:00,475] Trial 21 finished with value: 0.05562400886160547 and parameters: {'n_estimators': 775, 'learning_rate': 0.2634195294614503, 'max_depth': 12, 'subsample': 0.86588129628946, 'colsample_bytree': 0.548739908903608, 'min_child_weight': 5, 'gamma': 1.7807872672145564, 'reg_alpha': 7.049019698536868, 'reg_lambda': 1.7836256570154587}. Best is trial 10 with value: 0.05550064204184797.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  11%|█████                                         | 22/200 [03:11<22:00,  7.42s/it][I 2025-01-25 11:55:06,991] Trial 22 finished with value: 0.05069156831174145 and parameters: {'n_estimators': 803, 'learning_rate': 0.3571949957961932, 'max_depth': 13, 'subsample': 0.8876622505540356, 'colsample_bytree': 0.5588720825872063, 'min_child_weight': 4, 'gamma': 0.061880636900273345, 'reg_alpha': 6.607216005164979, 'reg_lambda': 0.9231531012365537}. Best is trial 22 with value: 0.05069156831174145.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  12%|█████▎                                        | 23/200 [03:18<21:05,  7.15s/it][I 2025-01-25 11:55:14,422] Trial 23 finished with value: 0.04836874657376446 and parameters: {'n_estimators': 784, 'learning_rate': 0.3969039824875858, 'max_depth': 13, 'subsample': 0.8857062547848734, 'colsample_bytree': 0.6431099579968259, 'min_child_weight': 4, 'gamma': 0.006458768347079813, 'reg_alpha': 6.5667109478194, 'reg_lambda': 1.1772074026738726}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  12%|█████▌                                        | 24/200 [03:25<21:12,  7.23s/it][I 2025-01-25 11:55:18,824] Trial 24 finished with value: 0.06476968394389596 and parameters: {'n_estimators': 546, 'learning_rate': 0.7854453409399356, 'max_depth': 14, 'subsample': 0.9535731280560739, 'colsample_bytree': 0.6501656131101641, 'min_child_weight': 4, 'gamma': 0.29647388079456005, 'reg_alpha': 3.393153136919868, 'reg_lambda': 0.9557978884274849}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  12%|█████▊                                        | 25/200 [03:30<18:36,  6.38s/it][I 2025-01-25 11:55:25,605] Trial 25 finished with value: 0.05576069965914075 and parameters: {'n_estimators': 853, 'learning_rate': 0.43116122282293234, 'max_depth': 13, 'subsample': 0.7344602641524395, 'colsample_bytree': 0.6515816214812745, 'min_child_weight': 4, 'gamma': 0.0942665333249213, 'reg_alpha': 5.9837561157940895, 'reg_lambda': 2.7442225806609204}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  13%|█████▉                                        | 26/200 [03:37<18:51,  6.50s/it][I 2025-01-25 11:55:29,278] Trial 26 finished with value: 0.055387550713525156 and parameters: {'n_estimators': 397, 'learning_rate': 0.3632676113256675, 'max_depth': 14, 'subsample': 0.9067197175420549, 'colsample_bytree': 0.6205000339183058, 'min_child_weight': 4, 'gamma': 0.9419547584840464, 'reg_alpha': 3.984462391947419, 'reg_lambda': 0.89978887168438}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  14%|██████▏                                       | 27/200 [03:40<16:18,  5.65s/it][I 2025-01-25 11:55:31,297] Trial 27 finished with value: 0.06404112260396208 and parameters: {'n_estimators': 112, 'learning_rate': 0.3741786845231684, 'max_depth': 14, 'subsample': 0.817663958503466, 'colsample_bytree': 0.7113438706340268, 'min_child_weight': 4, 'gamma': 0.9952073865267852, 'reg_alpha': 2.2348023042870278, 'reg_lambda': 0.8312811174902557}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  14%|██████▍                                       | 28/200 [03:42<13:04,  4.56s/it][I 2025-01-25 11:55:34,287] Trial 28 finished with value: 0.06887899506876916 and parameters: {'n_estimators': 323, 'learning_rate': 0.5673692231526826, 'max_depth': 15, 'subsample': 0.8818939722446464, 'colsample_bytree': 0.6242145301322627, 'min_child_weight': 2, 'gamma': 9.9108883720869, 'reg_alpha': 4.464433319977122, 'reg_lambda': 0.8143662535748676}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  14%|██████▋                                       | 29/200 [03:45<11:39,  4.09s/it][I 2025-01-25 11:55:38,115] Trial 29 finished with value: 0.06726787284921651 and parameters: {'n_estimators': 269, 'learning_rate': 0.7068418213980903, 'max_depth': 14, 'subsample': 0.8951120556425258, 'colsample_bytree': 0.7324612909045606, 'min_child_weight': 4, 'gamma': 0.025314326538011377, 'reg_alpha': 2.625039396703233, 'reg_lambda': 2.6377792935901248}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  15%|██████▉                                       | 30/200 [03:49<11:22,  4.01s/it][I 2025-01-25 11:55:42,040] Trial 30 finished with value: 0.05845495809683195 and parameters: {'n_estimators': 469, 'learning_rate': 0.5131920676034476, 'max_depth': 11, 'subsample': 0.8351877241812204, 'colsample_bytree': 0.6244527718431907, 'min_child_weight': 2, 'gamma': 0.9165263795168463, 'reg_alpha': 5.682185251751433, 'reg_lambda': 1.2431119664272814}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  16%|███████▏                                      | 31/200 [03:53<11:13,  3.99s/it][I 2025-01-25 11:55:47,406] Trial 31 finished with value: 0.05760910728766596 and parameters: {'n_estimators': 681, 'learning_rate': 0.35150559409799564, 'max_depth': 13, 'subsample': 0.9476763539711462, 'colsample_bytree': 0.5360883188031538, 'min_child_weight': 6, 'gamma': 2.3818612473580707, 'reg_alpha': 6.546556753134145, 'reg_lambda': 1.4932657241408314}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  16%|███████▎                                      | 32/200 [03:58<12:19,  4.40s/it][I 2025-01-25 11:55:55,193] Trial 32 finished with value: 0.05575048418188825 and parameters: {'n_estimators': 1060, 'learning_rate': 0.4261969331273017, 'max_depth': 12, 'subsample': 0.9783785701874518, 'colsample_bytree': 0.5699222545982611, 'min_child_weight': 3, 'gamma': 1.309057051056199, 'reg_alpha': 4.0949554104263, 'reg_lambda': 2.9215489966983372}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  16%|███████▌                                      | 33/200 [04:06<15:04,  5.42s/it][I 2025-01-25 11:56:01,302] Trial 33 finished with value: 0.051123009856249756 and parameters: {'n_estimators': 694, 'learning_rate': 0.19105158889943058, 'max_depth': 13, 'subsample': 0.9348742308876937, 'colsample_bytree': 0.5924493543880482, 'min_child_weight': 5, 'gamma': 0.5925736703926727, 'reg_alpha': 5.275370873971871, 'reg_lambda': 4.0799218739992105}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  17%|███████▊                                      | 34/200 [04:12<15:33,  5.62s/it][I 2025-01-25 11:56:05,963] Trial 34 finished with value: 0.05287272435001705 and parameters: {'n_estimators': 532, 'learning_rate': 0.30930870355216505, 'max_depth': 14, 'subsample': 0.9361228278435354, 'colsample_bytree': 0.6638067013487624, 'min_child_weight': 5, 'gamma': 0.6486561618833756, 'reg_alpha': 5.152801886742439, 'reg_lambda': 0.3262187571763119}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  18%|████████                                      | 35/200 [04:17<14:40,  5.33s/it][I 2025-01-25 11:56:10,921] Trial 35 finished with value: 0.05157978262467031 and parameters: {'n_estimators': 538, 'learning_rate': 0.2215536546757637, 'max_depth': 15, 'subsample': 0.926127885765715, 'colsample_bytree': 0.6699585252183036, 'min_child_weight': 5, 'gamma': 0.5803146602545022, 'reg_alpha': 5.12022600729338, 'reg_lambda': 0.35277382043270133}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  18%|████████▎                                     | 36/200 [04:22<14:16,  5.22s/it][I 2025-01-25 11:56:17,996] Trial 36 finished with value: 0.055750053818597656 and parameters: {'n_estimators': 914, 'learning_rate': 0.20808706565816723, 'max_depth': 15, 'subsample': 0.8850730998379972, 'colsample_bytree': 0.5917204896544003, 'min_child_weight': 5, 'gamma': 2.2599158461929036, 'reg_alpha': 6.437885831105942, 'reg_lambda': 0.46802356698501324}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  18%|████████▌                                     | 37/200 [04:29<15:41,  5.78s/it][I 2025-01-25 11:56:24,746] Trial 37 finished with value: 0.05208327407751647 and parameters: {'n_estimators': 823, 'learning_rate': 0.2169105669674087, 'max_depth': 13, 'subsample': 0.7847681026313755, 'colsample_bytree': 0.9730668610745877, 'min_child_weight': 3, 'gamma': 0.5797282251896839, 'reg_alpha': 4.884090716037637, 'reg_lambda': 0.09213270942057705}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  19%|████████▋                                     | 38/200 [04:36<16:23,  6.07s/it][I 2025-01-25 11:56:30,886] Trial 38 finished with value: 0.05381798419575967 and parameters: {'n_estimators': 627, 'learning_rate': 0.09838425988790939, 'max_depth': 10, 'subsample': 0.9246754276463292, 'colsample_bytree': 0.7185406176712986, 'min_child_weight': 1, 'gamma': 1.4134405527634273, 'reg_alpha': 8.086996745445877, 'reg_lambda': 2.211030433333435}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  20%|████████▉                                     | 39/200 [04:42<16:20,  6.09s/it][I 2025-01-25 11:56:40,542] Trial 39 finished with value: 0.05964077883948948 and parameters: {'n_estimators': 1329, 'learning_rate': 0.16003897585728544, 'max_depth': 15, 'subsample': 0.7202755486062526, 'colsample_bytree': 0.6883184237592059, 'min_child_weight': 6, 'gamma': 3.5924865736558167, 'reg_alpha': 5.702092006050556, 'reg_lambda': 4.255012676873637}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  20%|█████████▏                                    | 40/200 [04:52<19:05,  7.16s/it][I 2025-01-25 11:56:47,681] Trial 40 finished with value: 0.06803722827253941 and parameters: {'n_estimators': 967, 'learning_rate': 0.47110186486708594, 'max_depth': 11, 'subsample': 0.5246293937983499, 'colsample_bytree': 0.7901313532016079, 'min_child_weight': 4, 'gamma': 0.6125214916654927, 'reg_alpha': 6.768610285851729, 'reg_lambda': 1.2662220349230406}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  20%|█████████▍                                    | 41/200 [04:59<18:57,  7.15s/it][I 2025-01-25 11:56:54,168] Trial 41 finished with value: 0.051006915360123896 and parameters: {'n_estimators': 760, 'learning_rate': 0.20062446037662385, 'max_depth': 13, 'subsample': 0.7998566884213488, 'colsample_bytree': 0.9316230804664826, 'min_child_weight': 3, 'gamma': 0.5616528959616124, 'reg_alpha': 4.751938922912245, 'reg_lambda': 0.12176411455420402}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  21%|█████████▋                                    | 42/200 [05:05<18:18,  6.95s/it][I 2025-01-25 11:56:59,958] Trial 42 finished with value: 0.056514789634934705 and parameters: {'n_estimators': 734, 'learning_rate': 0.2741954718635715, 'max_depth': 13, 'subsample': 0.8130859248736013, 'colsample_bytree': 0.9366158907533064, 'min_child_weight': 3, 'gamma': 1.935771623164086, 'reg_alpha': 4.715532335175803, 'reg_lambda': 0.09421175881119148}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  22%|█████████▉                                    | 43/200 [05:11<17:16,  6.60s/it][I 2025-01-25 11:57:09,614] Trial 43 finished with value: 0.04852467219050529 and parameters: {'n_estimators': 1123, 'learning_rate': 0.1679930728891097, 'max_depth': 13, 'subsample': 0.8483962814722701, 'colsample_bytree': 0.8188689762174646, 'min_child_weight': 2, 'gamma': 0.10006013145034381, 'reg_alpha': 5.415168211856535, 'reg_lambda': 0.6198254580703266}. Best is trial 23 with value: 0.04836874657376446.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  22%|██████████                                    | 44/200 [05:21<19:33,  7.52s/it][I 2025-01-25 11:57:20,789] Trial 44 finished with value: 0.04565823601701728 and parameters: {'n_estimators': 1151, 'learning_rate': 0.15672590672144818, 'max_depth': 13, 'subsample': 0.8482449198257467, 'colsample_bytree': 0.8965065593299243, 'min_child_weight': 2, 'gamma': 0.014198834967673594, 'reg_alpha': 6.0209748554284594, 'reg_lambda': 1.4733188075311343}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  22%|██████████▎                                   | 45/200 [05:32<22:15,  8.62s/it][I 2025-01-25 11:57:33,588] Trial 45 finished with value: 0.04767375223692313 and parameters: {'n_estimators': 1141, 'learning_rate': 0.06588362373704335, 'max_depth': 11, 'subsample': 0.7719941022815732, 'colsample_bytree': 0.896012359447254, 'min_child_weight': 2, 'gamma': 0.10117392954445026, 'reg_alpha': 6.21340489582723, 'reg_lambda': 1.3976998260395381}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  23%|██████████▌                                   | 46/200 [05:45<25:20,  9.87s/it][I 2025-01-25 11:57:46,055] Trial 46 finished with value: 0.047340375650360283 and parameters: {'n_estimators': 1251, 'learning_rate': 0.09348520660101006, 'max_depth': 11, 'subsample': 0.7086439771340082, 'colsample_bytree': 0.853053793021556, 'min_child_weight': 1, 'gamma': 0.05763561829369568, 'reg_alpha': 6.06735945787817, 'reg_lambda': 2.343290904209979}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  24%|██████████▊                                   | 47/200 [05:57<27:09, 10.65s/it][I 2025-01-25 11:57:56,678] Trial 47 finished with value: 0.05524216253731153 and parameters: {'n_estimators': 1155, 'learning_rate': 0.05958320752792878, 'max_depth': 11, 'subsample': 0.6354530178310875, 'colsample_bytree': 0.862421911360599, 'min_child_weight': 1, 'gamma': 1.3227055289238168, 'reg_alpha': 6.214691896024837, 'reg_lambda': 2.339261249836291}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  24%|███████████                                   | 48/200 [06:08<26:57, 10.64s/it][I 2025-01-25 11:58:09,212] Trial 48 finished with value: 0.047268026009417694 and parameters: {'n_estimators': 1337, 'learning_rate': 0.07788409093485087, 'max_depth': 8, 'subsample': 0.712413066226631, 'colsample_bytree': 0.9047685865838108, 'min_child_weight': 1, 'gamma': 0.05200240220500518, 'reg_alpha': 7.702393852936092, 'reg_lambda': 1.7075409741196323}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  24%|███████████▎                                  | 49/200 [06:20<28:12, 11.21s/it][I 2025-01-25 11:58:21,974] Trial 49 finished with value: 0.054101515908450006 and parameters: {'n_estimators': 1553, 'learning_rate': 0.06606792888099815, 'max_depth': 8, 'subsample': 0.7165810042865562, 'colsample_bytree': 0.8848560984788175, 'min_child_weight': 1, 'gamma': 1.137584672540664, 'reg_alpha': 7.119044590087719, 'reg_lambda': 3.1180928710653326}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  25%|███████████▌                                  | 50/200 [06:33<29:11, 11.68s/it][I 2025-01-25 11:58:32,186] Trial 50 finished with value: 0.06789408889319747 and parameters: {'n_estimators': 1288, 'learning_rate': 0.06337752150450249, 'max_depth': 6, 'subsample': 0.6897687274902162, 'colsample_bytree': 0.9004173758140929, 'min_child_weight': 2, 'gamma': 7.8350244087483665, 'reg_alpha': 7.845634356139093, 'reg_lambda': 1.6559175624363136}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  26%|███████████▋                                  | 51/200 [06:43<27:54, 11.24s/it][I 2025-01-25 11:58:43,057] Trial 51 finished with value: 0.048244380460095285 and parameters: {'n_estimators': 1391, 'learning_rate': 0.1493955990169505, 'max_depth': 7, 'subsample': 0.755568079141115, 'colsample_bytree': 0.8350988978784519, 'min_child_weight': 2, 'gamma': 0.0913127399294354, 'reg_alpha': 5.730656808486397, 'reg_lambda': 1.9463521330396594}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  26%|███████████▉                                  | 52/200 [06:54<27:26, 11.13s/it][I 2025-01-25 11:58:53,948] Trial 52 finished with value: 0.05029009316351418 and parameters: {'n_estimators': 1384, 'learning_rate': 0.11214026739366487, 'max_depth': 8, 'subsample': 0.761335979921229, 'colsample_bytree': 0.8444723516137096, 'min_child_weight': 1, 'gamma': 0.35154741149348634, 'reg_alpha': 7.718841065623852, 'reg_lambda': 1.9341968067311979}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  26%|████████████▏                                 | 53/200 [07:05<27:05, 11.06s/it][I 2025-01-25 11:59:03,061] Trial 53 finished with value: 0.06670392865824322 and parameters: {'n_estimators': 1215, 'learning_rate': 0.07268565128144838, 'max_depth': 5, 'subsample': 0.6318765246083655, 'colsample_bytree': 0.9219749350043193, 'min_child_weight': 2, 'gamma': 5.03000269434273, 'reg_alpha': 8.449011828849539, 'reg_lambda': 1.383124397822034}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  27%|████████████▍                                 | 54/200 [07:14<25:29, 10.47s/it][I 2025-01-25 11:59:13,846] Trial 54 finished with value: 0.053268171169300715 and parameters: {'n_estimators': 1464, 'learning_rate': 0.14684328413716513, 'max_depth': 8, 'subsample': 0.763400205870603, 'colsample_bytree': 0.8549864680642687, 'min_child_weight': 1, 'gamma': 0.985600952145583, 'reg_alpha': 6.058482425807715, 'reg_lambda': 3.487374759277633}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  28%|████████████▋                                 | 55/200 [07:25<25:32, 10.57s/it][I 2025-01-25 11:59:28,043] Trial 55 finished with value: 0.05568280093253053 and parameters: {'n_estimators': 1665, 'learning_rate': 0.03279783256228576, 'max_depth': 7, 'subsample': 0.6924678148532069, 'colsample_bytree': 0.9627401558898591, 'min_child_weight': 2, 'gamma': 1.5849673807194495, 'reg_alpha': 0.042082693211964894, 'reg_lambda': 2.574080572462118}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  28%|████████████▉                                 | 56/200 [07:39<27:58, 11.66s/it][I 2025-01-25 11:59:38,579] Trial 56 finished with value: 0.04868724921201738 and parameters: {'n_estimators': 1334, 'learning_rate': 0.10214196356145902, 'max_depth': 6, 'subsample': 0.6692657936671497, 'colsample_bytree': 0.8785854995499682, 'min_child_weight': 1, 'gamma': 0.08805532730748022, 'reg_alpha': 7.007441685960359, 'reg_lambda': 2.0195588341797093}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  28%|█████████████                                 | 57/200 [07:50<26:58, 11.32s/it][I 2025-01-25 11:59:47,642] Trial 57 finished with value: 0.0591303487187223 and parameters: {'n_estimators': 1230, 'learning_rate': 0.14465739548881337, 'max_depth': 9, 'subsample': 0.6358950917116414, 'colsample_bytree': 0.7700925611619145, 'min_child_weight': 2, 'gamma': 2.6671126611658904, 'reg_alpha': 7.470584867409747, 'reg_lambda': 3.106478429558033}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  29%|█████████████▎                                | 58/200 [07:59<25:11, 10.64s/it][I 2025-01-25 11:59:58,200] Trial 58 finished with value: 0.06907198605565416 and parameters: {'n_estimators': 1512, 'learning_rate': 0.8692477780188355, 'max_depth': 9, 'subsample': 0.7394714647362086, 'colsample_bytree': 0.8211325582824847, 'min_child_weight': 1, 'gamma': 0.3965552220831454, 'reg_alpha': 5.874720609383003, 'reg_lambda': 2.430690432672168}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  30%|█████████████▌                                | 59/200 [08:09<24:57, 10.62s/it][I 2025-01-25 12:00:11,225] Trial 59 finished with value: 0.06541790519855119 and parameters: {'n_estimators': 997, 'learning_rate': 0.017419843897298504, 'max_depth': 10, 'subsample': 0.7108947677143326, 'colsample_bytree': 0.906346198806815, 'min_child_weight': 2, 'gamma': 6.1239304623443145, 'reg_alpha': 9.322031053031662, 'reg_lambda': 1.4294034365032213}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  30%|█████████████▊                                | 60/200 [08:22<26:27, 11.34s/it][I 2025-01-25 12:00:21,092] Trial 60 finished with value: 0.054614240374889655 and parameters: {'n_estimators': 1395, 'learning_rate': 0.2877113053882337, 'max_depth': 7, 'subsample': 0.7689436942871566, 'colsample_bytree': 0.8712417563573152, 'min_child_weight': 3, 'gamma': 0.8175054150052965, 'reg_alpha': 6.229338600201778, 'reg_lambda': 5.543527333772353}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  30%|██████████████                                | 61/200 [08:32<25:14, 10.90s/it][I 2025-01-25 12:00:30,772] Trial 61 finished with value: 0.0474080443623421 and parameters: {'n_estimators': 1126, 'learning_rate': 0.17167648083907677, 'max_depth': 12, 'subsample': 0.8549499773293552, 'colsample_bytree': 0.826567676753349, 'min_child_weight': 2, 'gamma': 0.04652603679227947, 'reg_alpha': 5.53946669291026, 'reg_lambda': 0.7616002592978968}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  31%|██████████████▎                               | 62/200 [08:42<24:13, 10.53s/it][I 2025-01-25 12:00:39,689] Trial 62 finished with value: 0.05081101144938248 and parameters: {'n_estimators': 1126, 'learning_rate': 0.1734798930792426, 'max_depth': 12, 'subsample': 0.8015470482936139, 'colsample_bytree': 0.8289571254307596, 'min_child_weight': 1, 'gamma': 0.3030489409941367, 'reg_alpha': 6.807821252038327, 'reg_lambda': 1.0842752258952344}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  32%|██████████████▍                               | 63/200 [08:51<22:56, 10.05s/it][I 2025-01-25 12:00:50,034] Trial 63 finished with value: 0.05374236456713584 and parameters: {'n_estimators': 1260, 'learning_rate': 0.08447961202322513, 'max_depth': 11, 'subsample': 0.8348354534003002, 'colsample_bytree': 0.9481413460189424, 'min_child_weight': 2, 'gamma': 1.1447077922869222, 'reg_alpha': 5.554664412569946, 'reg_lambda': 1.6292704738454793}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  32%|██████████████▋                               | 64/200 [09:01<22:58, 10.14s/it][I 2025-01-25 12:01:04,274] Trial 64 finished with value: 0.0470044650180929 and parameters: {'n_estimators': 1890, 'learning_rate': 0.24670361629224707, 'max_depth': 12, 'subsample': 0.6529950985988999, 'colsample_bytree': 0.8989879232102554, 'min_child_weight': 3, 'gamma': 0.015235775740698121, 'reg_alpha': 7.151356048823752, 'reg_lambda': 1.9391692978660133}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  32%|██████████████▉                               | 65/200 [09:15<25:34, 11.37s/it][I 2025-01-25 12:01:17,705] Trial 65 finished with value: 0.05730480102392155 and parameters: {'n_estimators': 1920, 'learning_rate': 0.12856316687811775, 'max_depth': 10, 'subsample': 0.6530187790372518, 'colsample_bytree': 0.9016746109377848, 'min_child_weight': 3, 'gamma': 1.9111948394772051, 'reg_alpha': 7.16246973824224, 'reg_lambda': 1.9770672911209362}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  33%|███████████████▏                              | 66/200 [09:29<26:46, 11.99s/it][I 2025-01-25 12:01:26,870] Trial 66 finished with value: 0.05427707887028972 and parameters: {'n_estimators': 1178, 'learning_rate': 0.12657072122592417, 'max_depth': 12, 'subsample': 0.579351474878428, 'colsample_bytree': 0.8456803762762692, 'min_child_weight': 2, 'gamma': 0.8314425774126939, 'reg_alpha': 4.4572655537558585, 'reg_lambda': 0.6576609042170679}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  34%|███████████████▍                              | 67/200 [09:38<24:41, 11.14s/it][I 2025-01-25 12:01:40,132] Trial 67 finished with value: 0.06272689286653013 and parameters: {'n_estimators': 1739, 'learning_rate': 0.046265310200600984, 'max_depth': 8, 'subsample': 0.6103016903075278, 'colsample_bytree': 0.8007614310755029, 'min_child_weight': 1, 'gamma': 4.545520598862614, 'reg_alpha': 6.27222919511808, 'reg_lambda': 7.670586680698069}. Best is trial 44 with value: 0.04565823601701728.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  34%|███████████████▋                              | 68/200 [09:51<25:54, 11.78s/it][I 2025-01-25 12:02:19,697] Trial 68 finished with value: 0.04430132477084398 and parameters: {'n_estimators': 1849, 'learning_rate': 0.23619555366740572, 'max_depth': 12, 'subsample': 0.7053202060823919, 'colsample_bytree': 0.8918928252431026, 'min_child_weight': 2, 'gamma': 0.0007316943780470708, 'reg_alpha': 5.839693640728954, 'reg_lambda': 8.999722672972526}. Best is trial 68 with value: 0.04430132477084398.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  34%|███████████████▊                              | 69/200 [10:31<43:54, 20.11s/it][I 2025-01-25 12:02:33,572] Trial 69 finished with value: 0.051951897512812616 and parameters: {'n_estimators': 1788, 'learning_rate': 0.2407302831255145, 'max_depth': 12, 'subsample': 0.6929355200550261, 'colsample_bytree': 0.8899458629326269, 'min_child_weight': 3, 'gamma': 0.409855621352485, 'reg_alpha': 7.8853403500938, 'reg_lambda': 8.419692797915838}. Best is trial 68 with value: 0.04430132477084398.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  35%|████████████████                              | 70/200 [10:45<39:31, 18.24s/it][I 2025-01-25 12:02:46,856] Trial 70 finished with value: 0.055961141155376114 and parameters: {'n_estimators': 1789, 'learning_rate': 0.18067615585697683, 'max_depth': 11, 'subsample': 0.7066517674773451, 'colsample_bytree': 0.9998774378345948, 'min_child_weight': 1, 'gamma': 1.2779978417876845, 'reg_alpha': 7.404709800771142, 'reg_lambda': 8.377159347701076}. Best is trial 68 with value: 0.04430132477084398.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  36%|████████████████▎                             | 71/200 [10:58<36:01, 16.75s/it][I 2025-01-25 12:03:00,958] Trial 71 finished with value: 0.04843048765908057 and parameters: {'n_estimators': 1843, 'learning_rate': 0.23350091943276602, 'max_depth': 12, 'subsample': 0.7357610566076151, 'colsample_bytree': 0.9191815872910141, 'min_child_weight': 2, 'gamma': 0.0759979116157139, 'reg_alpha': 5.8386549450446035, 'reg_lambda': 9.46597025910601}. Best is trial 68 with value: 0.04430132477084398.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  36%|████████████████▌                             | 72/200 [11:12<34:02, 15.96s/it][I 2025-01-25 12:03:12,797] Trial 72 finished with value: 0.05360261657814003 and parameters: {'n_estimators': 1619, 'learning_rate': 0.29820913240401065, 'max_depth': 11, 'subsample': 0.7490677328394921, 'colsample_bytree': 0.8659084264979022, 'min_child_weight': 2, 'gamma': 0.28603244475082357, 'reg_alpha': 6.802633261809738, 'reg_lambda': 6.334788979783106}. Best is trial 68 with value: 0.04430132477084398.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  36%|████████████████▊                             | 73/200 [11:24<31:09, 14.72s/it][I 2025-01-25 12:03:21,714] Trial 73 finished with value: 0.05262444076956231 and parameters: {'n_estimators': 1039, 'learning_rate': 0.14641753065052066, 'max_depth': 12, 'subsample': 0.6670483539581162, 'colsample_bytree': 0.8912684991614914, 'min_child_weight': 2, 'gamma': 0.7714483250237889, 'reg_alpha': 5.310786497263336, 'reg_lambda': 1.8096582470063443}. Best is trial 68 with value: 0.04430132477084398.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  37%|█████████████████                             | 74/200 [11:33<27:15, 12.98s/it][I 2025-01-25 12:03:40,581] Trial 74 finished with value: 0.04401107554299673 and parameters: {'n_estimators': 1840, 'learning_rate': 0.09489944914143593, 'max_depth': 5, 'subsample': 0.7291180338456958, 'colsample_bytree': 0.9126398709414348, 'min_child_weight': 1, 'gamma': 0.0037078372836131662, 'reg_alpha': 5.610447054064146, 'reg_lambda': 8.934007129056122}. Best is trial 74 with value: 0.04401107554299673.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  38%|█████████████████▎                            | 75/200 [11:52<30:43, 14.75s/it][I 2025-01-25 12:03:55,004] Trial 75 finished with value: 0.072177933315163 and parameters: {'n_estimators': 1999, 'learning_rate': 0.08660509386479665, 'max_depth': 3, 'subsample': 0.7266061901326245, 'colsample_bytree': 0.9105725148734853, 'min_child_weight': 1, 'gamma': 0.34527238089352347, 'reg_alpha': 6.152710902813525, 'reg_lambda': 9.088598950644382}. Best is trial 74 with value: 0.04401107554299673.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  38%|█████████████████▍                            | 76/200 [12:06<30:16, 14.65s/it][I 2025-01-25 12:04:13,204] Trial 76 finished with value: 0.07061030138135733 and parameters: {'n_estimators': 1906, 'learning_rate': 0.012316624873794646, 'max_depth': 4, 'subsample': 0.6557290802995921, 'colsample_bytree': 0.9486424840362706, 'min_child_weight': 1, 'gamma': 1.5966435968300123, 'reg_alpha': 5.5244269851864525, 'reg_lambda': 8.700559195991092}. Best is trial 74 with value: 0.04401107554299673.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  38%|█████████████████▋                            | 77/200 [12:24<32:12, 15.71s/it][I 2025-01-25 12:04:27,201] Trial 77 finished with value: 0.055986075375785725 and parameters: {'n_estimators': 1970, 'learning_rate': 0.11753230111972163, 'max_depth': 5, 'subsample': 0.7009879873121452, 'colsample_bytree': 0.9257514512127742, 'min_child_weight': 1, 'gamma': 0.7630038047035006, 'reg_alpha': 4.976900693427583, 'reg_lambda': 9.257643202947335}. Best is trial 74 with value: 0.04401107554299673.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  39%|█████████████████▉                            | 78/200 [12:38<30:54, 15.20s/it][I 2025-01-25 12:04:34,855] Trial 78 finished with value: 0.05261412111494773 and parameters: {'n_estimators': 928, 'learning_rate': 0.18522699384021146, 'max_depth': 10, 'subsample': 0.6820846108823813, 'colsample_bytree': 0.876230583442539, 'min_child_weight': 2, 'gamma': 0.4992258258294813, 'reg_alpha': 6.442415760733393, 'reg_lambda': 9.703774224134873}. Best is trial 74 with value: 0.04401107554299673.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  40%|██████████████████▏                           | 79/200 [12:46<26:05, 12.94s/it][I 2025-01-25 12:05:02,475] Trial 79 finished with value: 0.04576574788133904 and parameters: {'n_estimators': 1855, 'learning_rate': 0.039543528508724356, 'max_depth': 12, 'subsample': 0.8670290322650381, 'colsample_bytree': 0.9758212617818515, 'min_child_weight': 3, 'gamma': 0.008606333602854122, 'reg_alpha': 8.748905212690392, 'reg_lambda': 9.979772510396009}. Best is trial 74 with value: 0.04401107554299673.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  40%|██████████████████▍                           | 80/200 [13:13<34:40, 17.34s/it][I 2025-01-25 12:05:18,568] Trial 80 finished with value: 0.06325827378970156 and parameters: {'n_estimators': 1857, 'learning_rate': 0.03899707870779151, 'max_depth': 12, 'subsample': 0.8726265718101257, 'colsample_bytree': 0.9704808680467134, 'min_child_weight': 3, 'gamma': 5.431326740684559, 'reg_alpha': 8.766466315629199, 'reg_lambda': 9.937217294387505}. Best is trial 74 with value: 0.04401107554299673.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  40%|██████████████████▋                           | 81/200 [13:30<33:39, 16.97s/it][I 2025-01-25 12:05:33,229] Trial 81 finished with value: 0.04981470183814883 and parameters: {'n_estimators': 1689, 'learning_rate': 0.08906423680575934, 'max_depth': 11, 'subsample': 0.8213724630852479, 'colsample_bytree': 0.9472293567154199, 'min_child_weight': 3, 'gamma': 0.23183641929257642, 'reg_alpha': 8.459556819521389, 'reg_lambda': 7.834698803675369}. Best is trial 74 with value: 0.04401107554299673.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  41%|██████████████████▊                           | 82/200 [13:44<32:00, 16.27s/it][I 2025-01-25 12:05:47,769] Trial 82 finished with value: 0.053820433412193655 and parameters: {'n_estimators': 1910, 'learning_rate': 0.10730109048029554, 'max_depth': 11, 'subsample': 0.8508331119284313, 'colsample_bytree': 0.9842767411219963, 'min_child_weight': 1, 'gamma': 1.0824457296988015, 'reg_alpha': 8.223898880964759, 'reg_lambda': 8.89556178305465}. Best is trial 74 with value: 0.04401107554299673.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  42%|███████████████████                           | 83/200 [13:59<30:43, 15.75s/it][I 2025-01-25 12:06:18,423] Trial 83 finished with value: 0.04395348266902842 and parameters: {'n_estimators': 1735, 'learning_rate': 0.047728162214790565, 'max_depth': 12, 'subsample': 0.9057125109216521, 'colsample_bytree': 0.8572251007434795, 'min_child_weight': 2, 'gamma': 0.002018000677611335, 'reg_alpha': 5.948268406387103, 'reg_lambda': 9.578684556863058}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  42%|███████████████████▎                          | 84/200 [14:29<39:06, 20.22s/it][I 2025-01-25 12:06:34,355] Trial 84 finished with value: 0.05193931632799772 and parameters: {'n_estimators': 1752, 'learning_rate': 0.05110799179872242, 'max_depth': 12, 'subsample': 0.8626124224021239, 'colsample_bytree': 0.8520741926510926, 'min_child_weight': 3, 'gamma': 0.7030850830319706, 'reg_alpha': 9.446324460610821, 'reg_lambda': 9.42854440026005}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  42%|███████████████████▌                          | 85/200 [14:45<36:17, 18.94s/it][I 2025-01-25 12:06:47,603] Trial 85 finished with value: 0.05077143023019255 and parameters: {'n_estimators': 1858, 'learning_rate': 0.2502027697752571, 'max_depth': 13, 'subsample': 0.8972063126920232, 'colsample_bytree': 0.915963289804536, 'min_child_weight': 2, 'gamma': 0.48107475350018936, 'reg_alpha': 4.401236611353447, 'reg_lambda': 9.677226943020745}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  43%|███████████████████▊                          | 86/200 [14:59<32:44, 17.23s/it][I 2025-01-25 12:07:19,122] Trial 86 finished with value: 0.04443463100062396 and parameters: {'n_estimators': 1629, 'learning_rate': 0.16801373479652604, 'max_depth': 14, 'subsample': 0.5736836739401449, 'colsample_bytree': 0.9353064853760027, 'min_child_weight': 1, 'gamma': 0.0017476481073246462, 'reg_alpha': 5.958626889290083, 'reg_lambda': 8.674840326792342}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  44%|████████████████████                          | 87/200 [15:30<40:31, 21.52s/it][I 2025-01-25 12:07:34,359] Trial 87 finished with value: 0.055045140953149774 and parameters: {'n_estimators': 1643, 'learning_rate': 0.03780169589078859, 'max_depth': 14, 'subsample': 0.5462321648027053, 'colsample_bytree': 0.9401485010696025, 'min_child_weight': 1, 'gamma': 0.9640722447416241, 'reg_alpha': 6.8363060585296465, 'reg_lambda': 8.57936870483259}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  44%|████████████████████▏                         | 88/200 [15:45<36:38, 19.63s/it][I 2025-01-25 12:07:45,017] Trial 88 finished with value: 0.06559870125304353 and parameters: {'n_estimators': 1579, 'learning_rate': 0.6188329251483342, 'max_depth': 14, 'subsample': 0.5685634386233444, 'colsample_bytree': 0.9571708159832049, 'min_child_weight': 1, 'gamma': 1.468157055648442, 'reg_alpha': 9.099480625136904, 'reg_lambda': 8.088253056872949}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  44%|████████████████████▍                         | 89/200 [15:56<31:20, 16.94s/it][I 2025-01-25 12:07:57,781] Trial 89 finished with value: 0.05165046203426821 and parameters: {'n_estimators': 1728, 'learning_rate': 0.20066490478500726, 'max_depth': 13, 'subsample': 0.723451941039999, 'colsample_bytree': 0.9327345939398483, 'min_child_weight': 1, 'gamma': 0.5261156497332786, 'reg_alpha': 5.972772760571656, 'reg_lambda': 7.292706283520484}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  45%|████████████████████▋                         | 90/200 [16:09<28:45, 15.69s/it][I 2025-01-25 12:08:14,742] Trial 90 finished with value: 0.04630704325408275 and parameters: {'n_estimators': 1814, 'learning_rate': 0.12767403147500242, 'max_depth': 14, 'subsample': 0.6010534179852547, 'colsample_bytree': 0.9804035471339713, 'min_child_weight': 1, 'gamma': 0.012701506170013317, 'reg_alpha': 7.184920375955099, 'reg_lambda': 8.958369401501773}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  46%|████████████████████▉                         | 91/200 [16:26<29:11, 16.07s/it][I 2025-01-25 12:08:33,862] Trial 91 finished with value: 0.046270180808208945 and parameters: {'n_estimators': 1832, 'learning_rate': 0.0846602816044578, 'max_depth': 13, 'subsample': 0.5811745442093161, 'colsample_bytree': 0.9755182225932371, 'min_child_weight': 1, 'gamma': 0.0130494627892, 'reg_alpha': 7.257448728714076, 'reg_lambda': 8.957351515679193}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  46%|█████████████████████▏                        | 92/200 [16:45<30:34, 16.98s/it][I 2025-01-25 12:08:47,570] Trial 92 finished with value: 0.05150698677902148 and parameters: {'n_estimators': 1838, 'learning_rate': 0.1297405748136446, 'max_depth': 14, 'subsample': 0.5975363543242241, 'colsample_bytree': 0.9878831754777793, 'min_child_weight': 1, 'gamma': 0.3005020203223265, 'reg_alpha': 7.687497570929024, 'reg_lambda': 9.000358882804598}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  46%|█████████████████████▍                        | 93/200 [16:59<28:32, 16.00s/it][I 2025-01-25 12:09:00,570] Trial 93 finished with value: 0.05128955642975598 and parameters: {'n_estimators': 1797, 'learning_rate': 0.22092875741055018, 'max_depth': 14, 'subsample': 0.6087220476142687, 'colsample_bytree': 0.9740676543735979, 'min_child_weight': 1, 'gamma': 0.24722247574293316, 'reg_alpha': 7.16882428074326, 'reg_lambda': 8.77016977620862}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  47%|█████████████████████▌                        | 94/200 [17:12<26:40, 15.10s/it][I 2025-01-25 12:09:38,903] Trial 94 finished with value: 0.044864457423010436 and parameters: {'n_estimators': 1952, 'learning_rate': 0.07694342687744636, 'max_depth': 15, 'subsample': 0.5688605082320564, 'colsample_bytree': 0.998258285138452, 'min_child_weight': 2, 'gamma': 0.0016247963699356498, 'reg_alpha': 8.43730832766831, 'reg_lambda': 9.427170816168472}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  48%|█████████████████████▊                        | 95/200 [17:50<38:37, 22.07s/it][I 2025-01-25 12:09:52,966] Trial 95 finished with value: 0.055127628850037726 and parameters: {'n_estimators': 1953, 'learning_rate': 0.15654546216361837, 'max_depth': 15, 'subsample': 0.5630734051358418, 'colsample_bytree': 0.9806732259183496, 'min_child_weight': 2, 'gamma': 0.695475106319234, 'reg_alpha': 8.475444395420592, 'reg_lambda': 9.318242954641125}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  48%|██████████████████████                        | 96/200 [18:04<34:05, 19.67s/it][I 2025-01-25 12:10:08,863] Trial 96 finished with value: 0.05341708925309602 and parameters: {'n_estimators': 1761, 'learning_rate': 0.05236161461555244, 'max_depth': 15, 'subsample': 0.5343478402543989, 'colsample_bytree': 0.9996813195864374, 'min_child_weight': 3, 'gamma': 0.4884874374899635, 'reg_alpha': 7.979800025806069, 'reg_lambda': 9.100773548625222}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  48%|██████████████████████▎                       | 97/200 [18:20<31:49, 18.54s/it][I 2025-01-25 12:10:22,131] Trial 97 finished with value: 0.07094318757631506 and parameters: {'n_estimators': 1884, 'learning_rate': 0.3207895183374283, 'max_depth': 14, 'subsample': 0.583053111972228, 'colsample_bytree': 0.9606151711342453, 'min_child_weight': 2, 'gamma': 7.81283146949105, 'reg_alpha': 6.487361965435094, 'reg_lambda': 8.092466245294556}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  49%|██████████████████████▌                       | 98/200 [18:33<28:49, 16.96s/it][I 2025-01-25 12:10:35,935] Trial 98 finished with value: 0.051141406238964085 and parameters: {'n_estimators': 1701, 'learning_rate': 0.6750529810040148, 'max_depth': 13, 'subsample': 0.6239185064045917, 'colsample_bytree': 0.968803180050045, 'min_child_weight': 2, 'gamma': 0.00961864076397469, 'reg_alpha': 9.078911299574234, 'reg_lambda': 9.974510386770309}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  50%|██████████████████████▊                       | 99/200 [18:47<26:57, 16.01s/it][I 2025-01-25 12:10:49,814] Trial 99 finished with value: 0.06435653799867244 and parameters: {'n_estimators': 1947, 'learning_rate': 0.2674546021229988, 'max_depth': 14, 'subsample': 0.5512417610717286, 'colsample_bytree': 0.9802973901970187, 'min_child_weight': 4, 'gamma': 3.3620128160621587, 'reg_alpha': 7.303686454754791, 'reg_lambda': 9.491759897471953}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  50%|██████████████████████▌                      | 100/200 [19:01<25:37, 15.37s/it][I 2025-01-25 12:11:03,841] Trial 100 finished with value: 0.05562305390329762 and parameters: {'n_estimators': 1814, 'learning_rate': 0.10896610011125349, 'max_depth': 15, 'subsample': 0.5109448834843987, 'colsample_bytree': 0.9501751478627789, 'min_child_weight': 2, 'gamma': 0.9293039161278728, 'reg_alpha': 5.135289972056205, 'reg_lambda': 9.659664196973443}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  50%|██████████████████████▋                      | 101/200 [19:15<24:41, 14.97s/it][I 2025-01-25 12:11:19,685] Trial 101 finished with value: 0.05050291448456758 and parameters: {'n_estimators': 1883, 'learning_rate': 0.07738106010407059, 'max_depth': 13, 'subsample': 0.578423332059776, 'colsample_bytree': 0.9082744749561006, 'min_child_weight': 1, 'gamma': 0.22354891049684514, 'reg_alpha': 7.627557197025199, 'reg_lambda': 9.219260828497365}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  51%|██████████████████████▉                      | 102/200 [19:31<24:52, 15.23s/it][I 2025-01-25 12:11:40,732] Trial 102 finished with value: 0.05319513070507363 and parameters: {'n_estimators': 1819, 'learning_rate': 0.021380233043716043, 'max_depth': 14, 'subsample': 0.5908822999671689, 'colsample_bytree': 0.9282411896123067, 'min_child_weight': 1, 'gamma': 0.603607803695752, 'reg_alpha': 8.213550802712563, 'reg_lambda': 8.562770356809661}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  52%|███████████████████████▏                     | 103/200 [19:52<27:26, 16.98s/it][I 2025-01-25 12:11:55,916] Trial 103 finished with value: 0.05134376461546043 and parameters: {'n_estimators': 2000, 'learning_rate': 0.08344294899557478, 'max_depth': 4, 'subsample': 0.6191044315868303, 'colsample_bytree': 0.9392299537763743, 'min_child_weight': 9, 'gamma': 0.037501081809024735, 'reg_alpha': 8.622496499148122, 'reg_lambda': 8.880692156640869}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  52%|███████████████████████▍                     | 104/200 [20:07<26:18, 16.44s/it][I 2025-01-25 12:12:08,467] Trial 104 finished with value: 0.05126097438334056 and parameters: {'n_estimators': 1660, 'learning_rate': 0.1349767175140501, 'max_depth': 13, 'subsample': 0.5604327550816149, 'colsample_bytree': 0.9942259916843714, 'min_child_weight': 1, 'gamma': 0.26654364376534234, 'reg_alpha': 6.619106653668392, 'reg_lambda': 9.541276390174197}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  52%|███████████████████████▋                     | 105/200 [20:19<24:10, 15.27s/it][I 2025-01-25 12:12:21,024] Trial 105 finished with value: 0.055526920932382574 and parameters: {'n_estimators': 1480, 'learning_rate': 0.06509910495964799, 'max_depth': 13, 'subsample': 0.6438208421721326, 'colsample_bytree': 0.9584128132544495, 'min_child_weight': 1, 'gamma': 1.119001166133619, 'reg_alpha': 7.042221956341642, 'reg_lambda': 9.822780513341192}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  53%|███████████████████████▊                     | 106/200 [20:32<22:39, 14.46s/it][I 2025-01-25 12:12:34,362] Trial 106 finished with value: 0.05295660377771734 and parameters: {'n_estimators': 1767, 'learning_rate': 0.16480375955027846, 'max_depth': 15, 'subsample': 0.5931280409256154, 'colsample_bytree': 0.9679525677308961, 'min_child_weight': 3, 'gamma': 0.4633815761459048, 'reg_alpha': 7.562069982646186, 'reg_lambda': 8.250564527932253}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  54%|████████████████████████                     | 107/200 [20:45<21:53, 14.12s/it][I 2025-01-25 12:12:49,144] Trial 107 finished with value: 0.0474165693963566 and parameters: {'n_estimators': 1917, 'learning_rate': 0.11161034137748586, 'max_depth': 5, 'subsample': 0.9149414708538699, 'colsample_bytree': 0.8831329393220277, 'min_child_weight': 2, 'gamma': 0.014202645164797972, 'reg_alpha': 7.284308746574188, 'reg_lambda': 9.048332566573952}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  54%|████████████████████████▎                    | 108/200 [21:00<21:57, 14.32s/it][I 2025-01-25 12:13:02,981] Trial 108 finished with value: 0.06962691268463625 and parameters: {'n_estimators': 1612, 'learning_rate': 0.030023236821483112, 'max_depth': 12, 'subsample': 0.550080401001768, 'colsample_bytree': 0.9156469319413524, 'min_child_weight': 2, 'gamma': 7.2597315593413825, 'reg_alpha': 8.009557526886317, 'reg_lambda': 8.738675412924135}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  55%|████████████████████████▌                    | 109/200 [21:14<21:29, 14.17s/it][I 2025-01-25 12:13:15,253] Trial 109 finished with value: 0.054880166166163126 and parameters: {'n_estimators': 1712, 'learning_rate': 0.19331792839963546, 'max_depth': 13, 'subsample': 0.5727795045889513, 'colsample_bytree': 0.8956858535144444, 'min_child_weight': 1, 'gamma': 0.7601760005430878, 'reg_alpha': 8.900407583011544, 'reg_lambda': 7.359955135475399}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  55%|████████████████████████▊                    | 110/200 [21:26<20:24, 13.60s/it][I 2025-01-25 12:13:50,030] Trial 110 finished with value: 0.049526935539576926 and parameters: {'n_estimators': 1878, 'learning_rate': 0.011027475635950523, 'max_depth': 12, 'subsample': 0.6171194380351677, 'colsample_bytree': 0.9384577316873317, 'min_child_weight': 2, 'gamma': 0.21314221007759482, 'reg_alpha': 5.780740365211444, 'reg_lambda': 6.685497844653799}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  56%|████████████████████████▉                    | 111/200 [22:01<29:36, 19.96s/it][I 2025-01-25 12:14:04,674] Trial 111 finished with value: 0.05096903581335044 and parameters: {'n_estimators': 1942, 'learning_rate': 0.09563765300042151, 'max_depth': 12, 'subsample': 0.6750232237098756, 'colsample_bytree': 0.9023670153513801, 'min_child_weight': 1, 'gamma': 0.41006600095226364, 'reg_alpha': 6.007131761707991, 'reg_lambda': 2.2457838094008618}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  56%|█████████████████████████▏                   | 112/200 [22:16<26:55, 18.36s/it][I 2025-01-25 12:14:19,620] Trial 112 finished with value: 0.04570253274916174 and parameters: {'n_estimators': 1339, 'learning_rate': 0.12432377525148813, 'max_depth': 14, 'subsample': 0.7444621605261799, 'colsample_bytree': 0.8695637277883812, 'min_child_weight': 1, 'gamma': 0.005724907637048526, 'reg_alpha': 6.935831059217545, 'reg_lambda': 5.115972098072406}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  56%|█████████████████████████▍                   | 113/200 [22:31<25:08, 17.34s/it][I 2025-01-25 12:14:33,365] Trial 113 finished with value: 0.05019349828129852 and parameters: {'n_estimators': 1823, 'learning_rate': 0.1228468922198292, 'max_depth': 14, 'subsample': 0.7451874918182133, 'colsample_bytree': 0.8645753886103736, 'min_child_weight': 1, 'gamma': 0.25815695262639227, 'reg_alpha': 6.859510842783628, 'reg_lambda': 9.285409591763003}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  57%|█████████████████████████▋                   | 114/200 [22:44<23:18, 16.26s/it][I 2025-01-25 12:14:42,163] Trial 114 finished with value: 0.07960596664284358 and parameters: {'n_estimators': 1305, 'learning_rate': 0.5052316255053428, 'max_depth': 15, 'subsample': 0.5298270739480039, 'colsample_bytree': 0.8833757862605811, 'min_child_weight': 1, 'gamma': 9.892477966740206, 'reg_alpha': 6.65029057180948, 'reg_lambda': 6.00999566596427}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  57%|█████████████████████████▊                   | 115/200 [22:53<19:51, 14.02s/it][I 2025-01-25 12:14:55,318] Trial 115 finished with value: 0.051849683849680805 and parameters: {'n_estimators': 1551, 'learning_rate': 0.06737218259165537, 'max_depth': 14, 'subsample': 0.7852653230048713, 'colsample_bytree': 0.988576873193651, 'min_child_weight': 2, 'gamma': 0.6315265548110551, 'reg_alpha': 6.341567276980301, 'reg_lambda': 5.051244259912648}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  58%|██████████████████████████                   | 116/200 [23:06<19:15, 13.76s/it][I 2025-01-25 12:15:08,661] Trial 116 finished with value: 0.049660898503113574 and parameters: {'n_estimators': 1781, 'learning_rate': 0.13624419345591307, 'max_depth': 15, 'subsample': 0.7278617662276868, 'colsample_bytree': 0.9207237157196878, 'min_child_weight': 1, 'gamma': 0.20272073823844056, 'reg_alpha': 7.857811194212299, 'reg_lambda': 4.269951944715696}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  58%|██████████████████████████▎                  | 117/200 [23:20<18:51, 13.64s/it][I 2025-01-25 12:15:29,336] Trial 117 finished with value: 0.04398256801448003 and parameters: {'n_estimators': 1343, 'learning_rate': 0.09791232257381972, 'max_depth': 13, 'subsample': 0.9665546404131798, 'colsample_bytree': 0.8936369613631219, 'min_child_weight': 1, 'gamma': 0.00044703524599897654, 'reg_alpha': 6.933013660452867, 'reg_lambda': 9.839064990916548}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  59%|██████████████████████████▌                  | 118/200 [23:40<21:31, 15.75s/it][I 2025-01-25 12:15:39,469] Trial 118 finished with value: 0.060297259845665196 and parameters: {'n_estimators': 1505, 'learning_rate': 0.576058350653368, 'max_depth': 14, 'subsample': 0.9713682219653832, 'colsample_bytree': 0.8768645864900932, 'min_child_weight': 2, 'gamma': 0.8582195009435079, 'reg_alpha': 6.94163314857834, 'reg_lambda': 9.987935591166082}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  60%|██████████████████████████▊                  | 119/200 [23:50<18:59, 14.06s/it][I 2025-01-25 12:15:55,381] Trial 119 finished with value: 0.045367565850592796 and parameters: {'n_estimators': 1973, 'learning_rate': 0.17245307628452977, 'max_depth': 13, 'subsample': 0.8998154795863462, 'colsample_bytree': 0.8922810659466676, 'min_child_weight': 3, 'gamma': 0.010043689860454053, 'reg_alpha': 5.4320911606174205, 'reg_lambda': 9.762189228678112}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  60%|███████████████████████████                  | 120/200 [24:06<19:29, 14.62s/it][I 2025-01-25 12:16:09,739] Trial 120 finished with value: 0.050621499487518706 and parameters: {'n_estimators': 1992, 'learning_rate': 0.16487760461254533, 'max_depth': 13, 'subsample': 0.9022850257089666, 'colsample_bytree': 0.97813655267785, 'min_child_weight': 1, 'gamma': 0.4396800461098402, 'reg_alpha': 5.370267976932242, 'reg_lambda': 9.777747069373152}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  60%|███████████████████████████▏                 | 121/200 [24:21<19:08, 14.54s/it][I 2025-01-25 12:16:24,550] Trial 121 finished with value: 0.04555518319960854 and parameters: {'n_estimators': 1857, 'learning_rate': 0.21260939363438972, 'max_depth': 13, 'subsample': 0.9809052780196695, 'colsample_bytree': 0.8938497631019214, 'min_child_weight': 3, 'gamma': 0.008486108757269248, 'reg_alpha': 5.539312728408677, 'reg_lambda': 9.543951709521139}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  61%|███████████████████████████▍                 | 122/200 [24:36<19:00, 14.62s/it][I 2025-01-25 12:16:34,997] Trial 122 finished with value: 0.04986848724117949 and parameters: {'n_estimators': 1423, 'learning_rate': 0.20809490456330065, 'max_depth': 13, 'subsample': 0.995513461077211, 'colsample_bytree': 0.8875394357768647, 'min_child_weight': 3, 'gamma': 0.38599520282745986, 'reg_alpha': 5.635573750868472, 'reg_lambda': 9.561912977556151}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  62%|███████████████████████████▋                 | 123/200 [24:46<17:09, 13.37s/it][I 2025-01-25 12:16:49,430] Trial 123 finished with value: 0.0484867215416783 and parameters: {'n_estimators': 1947, 'learning_rate': 0.14183769663526857, 'max_depth': 13, 'subsample': 0.981837949247562, 'colsample_bytree': 0.8691214076045553, 'min_child_weight': 4, 'gamma': 0.20149772782208558, 'reg_alpha': 4.818703830260597, 'reg_lambda': 9.316911940778063}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  62%|███████████████████████████▉                 | 124/200 [25:00<17:20, 13.69s/it][I 2025-01-25 12:17:03,128] Trial 124 finished with value: 0.051142800850286975 and parameters: {'n_estimators': 1840, 'learning_rate': 0.10746252793095101, 'max_depth': 14, 'subsample': 0.9483133622035782, 'colsample_bytree': 0.9289373290170606, 'min_child_weight': 3, 'gamma': 0.7050484680184826, 'reg_alpha': 5.270511133325894, 'reg_lambda': 9.131662664211937}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  62%|████████████████████████████▏                | 125/200 [25:14<17:06, 13.69s/it][I 2025-01-25 12:17:17,963] Trial 125 finished with value: 0.04582658797185862 and parameters: {'n_estimators': 1731, 'learning_rate': 0.1846834971875309, 'max_depth': 13, 'subsample': 0.9129106869109294, 'colsample_bytree': 0.8552642645182318, 'min_child_weight': 1, 'gamma': 0.0063178843181736525, 'reg_alpha': 5.862044874202396, 'reg_lambda': 9.787734416711833}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  63%|████████████████████████████▎                | 126/200 [25:29<17:18, 14.03s/it][I 2025-01-25 12:17:30,303] Trial 126 finished with value: 0.05096601684212289 and parameters: {'n_estimators': 1737, 'learning_rate': 0.18571097126563424, 'max_depth': 13, 'subsample': 0.9549917141183176, 'colsample_bytree': 0.8449785882422977, 'min_child_weight': 2, 'gamma': 0.5408479293339236, 'reg_alpha': 5.903536291099093, 'reg_lambda': 9.722215319226647}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  64%|████████████████████████████▌                | 127/200 [25:41<16:27, 13.53s/it][I 2025-01-25 12:17:42,847] Trial 127 finished with value: 0.04905586495314761 and parameters: {'n_estimators': 1687, 'learning_rate': 0.15800751188690093, 'max_depth': 13, 'subsample': 0.9380896074997267, 'colsample_bytree': 0.8582724477347534, 'min_child_weight': 3, 'gamma': 0.22880858886035285, 'reg_alpha': 5.487270295059907, 'reg_lambda': 9.431191155552915}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  64%|████████████████████████████▊                | 128/200 [25:54<15:52, 13.23s/it][I 2025-01-25 12:17:55,622] Trial 128 finished with value: 0.054197367781126146 and parameters: {'n_estimators': 1866, 'learning_rate': 0.2142316685102552, 'max_depth': 13, 'subsample': 0.8806376230993487, 'colsample_bytree': 0.8079529436571333, 'min_child_weight': 2, 'gamma': 1.2411014898331378, 'reg_alpha': 5.08872634812285, 'reg_lambda': 9.829272939926218}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  64%|█████████████████████████████                | 129/200 [26:07<15:29, 13.09s/it][I 2025-01-25 12:18:12,157] Trial 129 finished with value: 0.049800286126644146 and parameters: {'n_estimators': 1930, 'learning_rate': 0.05437080565301389, 'max_depth': 12, 'subsample': 0.9094704761019801, 'colsample_bytree': 0.8936513340763731, 'min_child_weight': 1, 'gamma': 0.41159677230666625, 'reg_alpha': 5.679884815650037, 'reg_lambda': 9.998528043728856}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  65%|█████████████████████████████▎               | 130/200 [26:23<16:28, 14.13s/it][I 2025-01-25 12:18:24,965] Trial 130 finished with value: 0.04661109925100213 and parameters: {'n_estimators': 1586, 'learning_rate': 0.18664942129079415, 'max_depth': 13, 'subsample': 0.9633818123045782, 'colsample_bytree': 0.836367912268883, 'min_child_weight': 7, 'gamma': 0.020465267133698624, 'reg_alpha': 6.143009845491951, 'reg_lambda': 9.459753237888863}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  66%|█████████████████████████████▍               | 131/200 [26:36<15:47, 13.73s/it][I 2025-01-25 12:18:37,843] Trial 131 finished with value: 0.05060237719267539 and parameters: {'n_estimators': 1806, 'learning_rate': 0.23322981626229738, 'max_depth': 14, 'subsample': 0.8920935392192132, 'colsample_bytree': 0.8745488326614242, 'min_child_weight': 1, 'gamma': 0.19353202764784883, 'reg_alpha': 6.377188364485548, 'reg_lambda': 8.93708207239486}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  66%|█████████████████████████████▋               | 132/200 [26:49<15:16, 13.47s/it][I 2025-01-25 12:18:55,484] Trial 132 finished with value: 0.044953157114505767 and parameters: {'n_estimators': 1766, 'learning_rate': 0.10111429604831508, 'max_depth': 14, 'subsample': 0.9182746859040664, 'colsample_bytree': 0.9100355750619975, 'min_child_weight': 1, 'gamma': 0.007945166343383825, 'reg_alpha': 5.9614569340644925, 'reg_lambda': 8.650177694010083}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  66%|█████████████████████████████▉               | 133/200 [27:06<16:26, 14.73s/it][I 2025-01-25 12:19:08,988] Trial 133 finished with value: 0.05066792424569633 and parameters: {'n_estimators': 1740, 'learning_rate': 0.09237339839482948, 'max_depth': 14, 'subsample': 0.9297123316992003, 'colsample_bytree': 0.910325730190181, 'min_child_weight': 1, 'gamma': 0.5411015847617665, 'reg_alpha': 5.839721257148511, 'reg_lambda': 8.582735611232495}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  67%|██████████████████████████████▏              | 134/200 [27:20<15:47, 14.36s/it][I 2025-01-25 12:19:28,517] Trial 134 finished with value: 0.045565289818165405 and parameters: {'n_estimators': 1075, 'learning_rate': 0.03825190714321074, 'max_depth': 13, 'subsample': 0.9204438980147464, 'colsample_bytree': 0.8902094461434807, 'min_child_weight': 1, 'gamma': 0.02116150300108704, 'reg_alpha': 6.049616146926906, 'reg_lambda': 9.638551711869107}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  68%|██████████████████████████████▍              | 135/200 [27:39<17:14, 15.91s/it][I 2025-01-25 12:19:44,596] Trial 135 finished with value: 0.04940235727366794 and parameters: {'n_estimators': 1642, 'learning_rate': 0.04277385294545828, 'max_depth': 13, 'subsample': 0.8742738743877972, 'colsample_bytree': 0.8897961928776591, 'min_child_weight': 2, 'gamma': 0.3420665606274173, 'reg_alpha': 5.3889139593090984, 'reg_lambda': 9.662774260364237}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  68%|██████████████████████████████▌              | 136/200 [27:56<17:01, 15.96s/it][I 2025-01-25 12:19:57,665] Trial 136 finished with value: 0.051598513611375484 and parameters: {'n_estimators': 1097, 'learning_rate': 0.03302066375681288, 'max_depth': 12, 'subsample': 0.9196048985691165, 'colsample_bytree': 0.861369619193475, 'min_child_weight': 1, 'gamma': 0.7861845866997361, 'reg_alpha': 6.10910857433078, 'reg_lambda': 9.267486535498158}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  68%|██████████████████████████████▊              | 137/200 [28:09<15:50, 15.09s/it][I 2025-01-25 12:20:14,869] Trial 137 finished with value: 0.04472823805145436 and parameters: {'n_estimators': 1187, 'learning_rate': 0.06731157262475429, 'max_depth': 13, 'subsample': 0.8992373562388652, 'colsample_bytree': 0.9117763281940351, 'min_child_weight': 3, 'gamma': 0.007151238784864944, 'reg_alpha': 5.705181237150253, 'reg_lambda': 9.548538717830768}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  69%|███████████████████████████████              | 138/200 [28:26<16:15, 15.73s/it][I 2025-01-25 12:20:26,235] Trial 138 finished with value: 0.05217408996545374 and parameters: {'n_estimators': 1093, 'learning_rate': 0.0450297008301745, 'max_depth': 14, 'subsample': 0.940218808362489, 'colsample_bytree': 0.9167732631998863, 'min_child_weight': 4, 'gamma': 0.9892623010879649, 'reg_alpha': 4.977321575799379, 'reg_lambda': 9.505308452011048}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  70%|███████████████████████████████▎             | 139/200 [28:37<14:39, 14.42s/it][I 2025-01-25 12:20:33,532] Trial 139 finished with value: 0.06036721961757716 and parameters: {'n_estimators': 1035, 'learning_rate': 0.9439225102049291, 'max_depth': 15, 'subsample': 0.8969393685376502, 'colsample_bytree': 0.9038893578710844, 'min_child_weight': 3, 'gamma': 0.24068768635736604, 'reg_alpha': 4.560988794104066, 'reg_lambda': 9.191964766724452}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  70%|███████████████████████████████▍             | 140/200 [28:45<12:16, 12.28s/it][I 2025-01-25 12:20:44,302] Trial 140 finished with value: 0.05164715793400233 and parameters: {'n_estimators': 1190, 'learning_rate': 0.06610206253468398, 'max_depth': 12, 'subsample': 0.8858885124950443, 'colsample_bytree': 0.8796689816605182, 'min_child_weight': 3, 'gamma': 0.6171395740220718, 'reg_alpha': 9.626432244817085, 'reg_lambda': 8.441427837538937}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  70%|███████████████████████████████▋             | 141/200 [28:55<11:37, 11.83s/it][I 2025-01-25 12:20:55,316] Trial 141 finished with value: 0.048704641115782814 and parameters: {'n_estimators': 1282, 'learning_rate': 0.10280682695315446, 'max_depth': 13, 'subsample': 0.9116919386587549, 'colsample_bytree': 0.8967825591459626, 'min_child_weight': 4, 'gamma': 0.22177011676201885, 'reg_alpha': 5.7477975618798185, 'reg_lambda': 9.817947820746822}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  71%|███████████████████████████████▉             | 142/200 [29:06<11:11, 11.58s/it][I 2025-01-25 12:21:05,235] Trial 142 finished with value: 0.04993573055887775 and parameters: {'n_estimators': 1236, 'learning_rate': 0.14416710797697857, 'max_depth': 13, 'subsample': 0.9191626007423876, 'colsample_bytree': 0.8703829762781526, 'min_child_weight': 2, 'gamma': 0.3825744113480542, 'reg_alpha': 5.580531668643935, 'reg_lambda': 9.619001509432717}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  72%|████████████████████████████████▏            | 143/200 [29:16<10:31, 11.08s/it][I 2025-01-25 12:21:16,478] Trial 143 finished with value: 0.04561942901238709 and parameters: {'n_estimators': 1171, 'learning_rate': 0.17343726668553094, 'max_depth': 14, 'subsample': 0.986459654054182, 'colsample_bytree': 0.911118035373313, 'min_child_weight': 3, 'gamma': 0.011456957334379356, 'reg_alpha': 5.938765497274914, 'reg_lambda': 9.381138202111302}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  72%|████████████████████████████████▍            | 144/200 [29:27<10:23, 11.13s/it][I 2025-01-25 12:21:27,805] Trial 144 finished with value: 0.04836593016454994 and parameters: {'n_estimators': 1161, 'learning_rate': 0.07755926465727614, 'max_depth': 14, 'subsample': 0.9842960304547553, 'colsample_bytree': 0.911682644970723, 'min_child_weight': 3, 'gamma': 0.19534602266965112, 'reg_alpha': 6.36169466168843, 'reg_lambda': 8.725943013897929}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  72%|████████████████████████████████▋            | 145/200 [29:39<10:15, 11.19s/it][I 2025-01-25 12:21:39,383] Trial 145 finished with value: 0.04597231680972182 and parameters: {'n_estimators': 1198, 'learning_rate': 0.12589549978929818, 'max_depth': 14, 'subsample': 0.9703685239935979, 'colsample_bytree': 0.9247849762113876, 'min_child_weight': 3, 'gamma': 0.02457349802614329, 'reg_alpha': 6.07871558730095, 'reg_lambda': 9.324501807311874}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  73%|████████████████████████████████▊            | 146/200 [29:50<10:10, 11.31s/it][I 2025-01-25 12:21:47,929] Trial 146 finished with value: 0.05005348645422101 and parameters: {'n_estimators': 1054, 'learning_rate': 0.15478203152021847, 'max_depth': 15, 'subsample': 0.9521370557776976, 'colsample_bytree': 0.8875426544663748, 'min_child_weight': 3, 'gamma': 0.45561862877691367, 'reg_alpha': 5.209530362816077, 'reg_lambda': 9.149028293450206}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  74%|█████████████████████████████████            | 147/200 [29:59<09:15, 10.48s/it][I 2025-01-25 12:21:58,907] Trial 147 finished with value: 0.05092462516110261 and parameters: {'n_estimators': 1361, 'learning_rate': 0.10186208375293843, 'max_depth': 14, 'subsample': 0.9911334664727465, 'colsample_bytree': 0.9431273801955901, 'min_child_weight': 3, 'gamma': 0.6214037710986032, 'reg_alpha': 5.5281047613689545, 'reg_lambda': 9.589379606900604}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  74%|█████████████████████████████████▎           | 148/200 [30:10<09:12, 10.63s/it][I 2025-01-25 12:22:16,386] Trial 148 finished with value: 0.044860000989203785 and parameters: {'n_estimators': 882, 'learning_rate': 0.053854553876437866, 'max_depth': 14, 'subsample': 0.8677383124970635, 'colsample_bytree': 0.9019889255024919, 'min_child_weight': 2, 'gamma': 0.008301352601209637, 'reg_alpha': 5.987963412045989, 'reg_lambda': 5.381183328363719}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  74%|█████████████████████████████████▌           | 149/200 [30:27<10:46, 12.68s/it][I 2025-01-25 12:22:23,559] Trial 149 finished with value: 0.049958497348655276 and parameters: {'n_estimators': 846, 'learning_rate': 0.16987139926601508, 'max_depth': 14, 'subsample': 0.9304642122874953, 'colsample_bytree': 0.9034956027876205, 'min_child_weight': 2, 'gamma': 0.3666487875263709, 'reg_alpha': 6.59966189930613, 'reg_lambda': 4.772352481915225}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  75%|█████████████████████████████████▊           | 150/200 [30:35<09:11, 11.03s/it][I 2025-01-25 12:22:33,448] Trial 150 finished with value: 0.05175237932649229 and parameters: {'n_estimators': 985, 'learning_rate': 0.060315104214919577, 'max_depth': 15, 'subsample': 0.9659625749204093, 'colsample_bytree': 0.9207793732088791, 'min_child_weight': 2, 'gamma': 0.8588876428167727, 'reg_alpha': 6.244951281913935, 'reg_lambda': 5.599413698529218}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  76%|█████████████████████████████████▉           | 151/200 [30:44<08:43, 10.69s/it][I 2025-01-25 12:22:44,884] Trial 151 finished with value: 0.04607056504007816 and parameters: {'n_estimators': 879, 'learning_rate': 0.08018517973939268, 'max_depth': 14, 'subsample': 0.8402274674447081, 'colsample_bytree': 0.8984367527157774, 'min_child_weight': 2, 'gamma': 0.03272656110466304, 'reg_alpha': 5.918170244941917, 'reg_lambda': 4.690288946071624}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  76%|██████████████████████████████████▏          | 152/200 [30:56<08:43, 10.91s/it][I 2025-01-25 12:23:01,119] Trial 152 finished with value: 0.04813955507791991 and parameters: {'n_estimators': 947, 'learning_rate': 0.029114484341551332, 'max_depth': 13, 'subsample': 0.8655835062534227, 'colsample_bytree': 0.9099190832774058, 'min_child_weight': 3, 'gamma': 0.18137361261135618, 'reg_alpha': 5.439749953905384, 'reg_lambda': 4.9484634823838105}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  76%|██████████████████████████████████▍          | 153/200 [31:12<09:47, 12.51s/it][I 2025-01-25 12:23:14,211] Trial 153 finished with value: 0.04560335908350661 and parameters: {'n_estimators': 1167, 'learning_rate': 0.11762350809592308, 'max_depth': 14, 'subsample': 0.8294607932648043, 'colsample_bytree': 0.8790641601044471, 'min_child_weight': 3, 'gamma': 0.009564630055310252, 'reg_alpha': 5.99791048236189, 'reg_lambda': 8.801310879586316}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  77%|██████████████████████████████████▋          | 154/200 [31:25<09:43, 12.68s/it][I 2025-01-25 12:23:23,710] Trial 154 finished with value: 0.05028460820534471 and parameters: {'n_estimators': 1127, 'learning_rate': 0.12048706338543154, 'max_depth': 14, 'subsample': 0.8280656906221163, 'colsample_bytree': 0.8808371784887729, 'min_child_weight': 2, 'gamma': 0.38696226466886635, 'reg_alpha': 5.7113469595179325, 'reg_lambda': 8.822163190238465}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  78%|██████████████████████████████████▉          | 155/200 [31:35<08:47, 11.73s/it][I 2025-01-25 12:23:36,478] Trial 155 finished with value: 0.04522800777523227 and parameters: {'n_estimators': 1014, 'learning_rate': 0.09520832491990874, 'max_depth': 14, 'subsample': 0.90006269842245, 'colsample_bytree': 0.8937546719684883, 'min_child_weight': 4, 'gamma': 0.01128487558887483, 'reg_alpha': 6.130775288578626, 'reg_lambda': 8.203598948930882}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  78%|███████████████████████████████████          | 156/200 [31:47<08:49, 12.04s/it][I 2025-01-25 12:23:46,130] Trial 156 finished with value: 0.048738375265472894 and parameters: {'n_estimators': 1022, 'learning_rate': 0.0934535368725722, 'max_depth': 15, 'subsample': 0.9047145259448388, 'colsample_bytree': 0.8903611231003572, 'min_child_weight': 4, 'gamma': 0.22209763271402358, 'reg_alpha': 5.957745791678236, 'reg_lambda': 8.297871776835258}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  78%|███████████████████████████████████▎         | 157/200 [31:57<08:06, 11.32s/it][I 2025-01-25 12:24:11,888] Trial 157 finished with value: 0.05080793205846965 and parameters: {'n_estimators': 1080, 'learning_rate': 0.011296926938359667, 'max_depth': 14, 'subsample': 0.861969395925811, 'colsample_bytree': 0.9329627867238217, 'min_child_weight': 5, 'gamma': 0.5410305849066183, 'reg_alpha': 6.2354470708094825, 'reg_lambda': 3.775784564324218}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  79%|███████████████████████████████████▌         | 158/200 [32:23<10:57, 15.65s/it][I 2025-01-25 12:24:21,269] Trial 158 finished with value: 0.061899860321390554 and parameters: {'n_estimators': 1165, 'learning_rate': 0.06599740445953053, 'max_depth': 13, 'subsample': 0.8791873490231865, 'colsample_bytree': 0.9122624211161402, 'min_child_weight': 4, 'gamma': 5.492095184920466, 'reg_alpha': 6.040186649147328, 'reg_lambda': 8.615002899145804}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  80%|███████████████████████████████████▊         | 159/200 [32:32<09:24, 13.77s/it][I 2025-01-25 12:24:31,208] Trial 159 finished with value: 0.04879038507217108 and parameters: {'n_estimators': 1224, 'learning_rate': 0.14557391618943577, 'max_depth': 14, 'subsample': 0.8452303247508977, 'colsample_bytree': 0.9002464050872934, 'min_child_weight': 3, 'gamma': 0.1943738488841061, 'reg_alpha': 5.653588481708512, 'reg_lambda': 7.919672968273506}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  80%|████████████████████████████████████         | 160/200 [32:42<08:24, 12.62s/it][I 2025-01-25 12:24:40,311] Trial 160 finished with value: 0.049949051997674555 and parameters: {'n_estimators': 1007, 'learning_rate': 0.1129189565696114, 'max_depth': 15, 'subsample': 0.8909998693562394, 'colsample_bytree': 0.9239626208931997, 'min_child_weight': 3, 'gamma': 0.3916567852632556, 'reg_alpha': 6.449188647820344, 'reg_lambda': 8.251578653777127}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  80%|████████████████████████████████████▏        | 161/200 [32:51<07:31, 11.57s/it][I 2025-01-25 12:24:49,019] Trial 161 finished with value: 0.04899500388007854 and parameters: {'n_estimators': 900, 'learning_rate': 0.1192864725776583, 'max_depth': 14, 'subsample': 0.8078692405903294, 'colsample_bytree': 0.8707126102148208, 'min_child_weight': 2, 'gamma': 0.17878766096639098, 'reg_alpha': 5.792044797861259, 'reg_lambda': 8.993213535110694}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  81%|████████████████████████████████████▍        | 162/200 [33:00<06:46, 10.71s/it][I 2025-01-25 12:24:58,490] Trial 162 finished with value: 0.04750883408046854 and parameters: {'n_estimators': 1121, 'learning_rate': 0.20340406364575267, 'max_depth': 14, 'subsample': 0.7871497446413165, 'colsample_bytree': 0.8832907672031552, 'min_child_weight': 1, 'gamma': 0.05168677804439249, 'reg_alpha': 6.2189111727384105, 'reg_lambda': 5.821630708025463}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  82%|████████████████████████████████████▋        | 163/200 [33:09<06:22, 10.34s/it][I 2025-01-25 12:25:30,864] Trial 163 finished with value: 0.04463320690164314 and parameters: {'n_estimators': 1280, 'learning_rate': 0.1704249853513048, 'max_depth': 13, 'subsample': 0.7536549074826684, 'colsample_bytree': 0.7721966990694988, 'min_child_weight': 2, 'gamma': 0.0006176080584326948, 'reg_alpha': 5.348402067806234, 'reg_lambda': 9.38824129943044}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  82%|████████████████████████████████████▉        | 164/200 [33:42<10:10, 16.95s/it][I 2025-01-25 12:25:42,605] Trial 164 finished with value: 0.045383747857247456 and parameters: {'n_estimators': 1262, 'learning_rate': 0.1757526465133728, 'max_depth': 13, 'subsample': 0.978906250868981, 'colsample_bytree': 0.8949677365500527, 'min_child_weight': 2, 'gamma': 0.009320426373779203, 'reg_alpha': 5.371302428792422, 'reg_lambda': 9.38122663787907}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  82%|█████████████████████████████████████▏       | 165/200 [33:54<08:58, 15.39s/it][I 2025-01-25 12:25:54,292] Trial 165 finished with value: 0.0457495682996389 and parameters: {'n_estimators': 1240, 'learning_rate': 0.23133683114037706, 'max_depth': 13, 'subsample': 0.9795619237782371, 'colsample_bytree': 0.7596884528725679, 'min_child_weight': 2, 'gamma': 0.0033031598411469255, 'reg_alpha': 5.248715115808238, 'reg_lambda': 9.373207549815278}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  83%|█████████████████████████████████████▎       | 166/200 [34:05<08:05, 14.28s/it][I 2025-01-25 12:26:03,964] Trial 166 finished with value: 0.050766524986179964 and parameters: {'n_estimators': 1292, 'learning_rate': 0.1754821408110267, 'max_depth': 13, 'subsample': 0.9999048433652094, 'colsample_bytree': 0.704242584346835, 'min_child_weight': 3, 'gamma': 0.599536516867164, 'reg_alpha': 5.017614733033452, 'reg_lambda': 9.153641168109033}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  84%|█████████████████████████████████████▌       | 167/200 [34:15<07:05, 12.90s/it][I 2025-01-25 12:26:13,123] Trial 167 finished with value: 0.050342187163853316 and parameters: {'n_estimators': 1260, 'learning_rate': 0.2769579870363964, 'max_depth': 13, 'subsample': 0.9606232705299657, 'colsample_bytree': 0.8926466094816342, 'min_child_weight': 2, 'gamma': 0.33411737267256597, 'reg_alpha': 5.392891364731458, 'reg_lambda': 8.8341070188082}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  84%|█████████████████████████████████████▊       | 168/200 [34:24<06:16, 11.77s/it][I 2025-01-25 12:26:23,807] Trial 168 finished with value: 0.04919113184252208 and parameters: {'n_estimators': 1181, 'learning_rate': 0.08508209653571487, 'max_depth': 13, 'subsample': 0.9246792713925865, 'colsample_bytree': 0.7830903602815493, 'min_child_weight': 2, 'gamma': 0.3236747846833284, 'reg_alpha': 5.574298927913827, 'reg_lambda': 9.392895613086976}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  84%|██████████████████████████████████████       | 169/200 [34:35<05:54, 11.45s/it][I 2025-01-25 12:26:32,371] Trial 169 finished with value: 0.054617526471311385 and parameters: {'n_estimators': 1207, 'learning_rate': 0.4495757038499371, 'max_depth': 14, 'subsample': 0.9427784363539355, 'colsample_bytree': 0.9049703009714363, 'min_child_weight': 3, 'gamma': 0.6754313066133346, 'reg_alpha': 5.21365233489179, 'reg_lambda': 9.580968973703511}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  85%|██████████████████████████████████████▎      | 170/200 [34:43<05:17, 10.58s/it][I 2025-01-25 12:26:42,823] Trial 170 finished with value: 0.045434234456467645 and parameters: {'n_estimators': 1096, 'learning_rate': 0.19730712129372313, 'max_depth': 13, 'subsample': 0.9765729311059034, 'colsample_bytree': 0.9143159551050065, 'min_child_weight': 4, 'gamma': 0.00954399509888091, 'reg_alpha': 4.662313553260705, 'reg_lambda': 9.05764454382593}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  86%|██████████████████████████████████████▍      | 171/200 [34:54<05:05, 10.54s/it][I 2025-01-25 12:26:51,699] Trial 171 finished with value: 0.04785041713176395 and parameters: {'n_estimators': 1101, 'learning_rate': 0.19969822241946222, 'max_depth': 13, 'subsample': 0.9786034560404071, 'colsample_bytree': 0.9179091112674362, 'min_child_weight': 4, 'gamma': 0.1527929526001558, 'reg_alpha': 4.042991617179436, 'reg_lambda': 9.007117680773767}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  86%|██████████████████████████████████████▋      | 172/200 [35:03<04:41, 10.04s/it][I 2025-01-25 12:27:02,151] Trial 172 finished with value: 0.04565098106009648 and parameters: {'n_estimators': 1078, 'learning_rate': 0.22579046055942398, 'max_depth': 13, 'subsample': 0.9815951446447474, 'colsample_bytree': 0.7402077044447422, 'min_child_weight': 5, 'gamma': 0.00301633809158457, 'reg_alpha': 5.821603505261932, 'reg_lambda': 9.190980860996596}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  86%|██████████████████████████████████████▉      | 173/200 [35:13<04:34, 10.17s/it][I 2025-01-25 12:27:08,765] Trial 173 finished with value: 0.04947590474215868 and parameters: {'n_estimators': 730, 'learning_rate': 0.1552085073018855, 'max_depth': 13, 'subsample': 0.9925186532412574, 'colsample_bytree': 0.9090425663891215, 'min_child_weight': 4, 'gamma': 0.39499931559548657, 'reg_alpha': 4.610683383097724, 'reg_lambda': 9.454754687051066}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  87%|███████████████████████████████████████▏     | 174/200 [35:20<03:56,  9.10s/it][I 2025-01-25 12:27:16,882] Trial 174 finished with value: 0.07239818707649268 and parameters: {'n_estimators': 966, 'learning_rate': 0.052918655783864024, 'max_depth': 3, 'subsample': 0.9005920470322907, 'colsample_bytree': 0.9331493094333455, 'min_child_weight': 3, 'gamma': 0.2553154971429126, 'reg_alpha': 4.83683668320875, 'reg_lambda': 8.45731189847024}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  88%|███████████████████████████████████████▍     | 175/200 [35:28<03:40,  8.81s/it][I 2025-01-25 12:27:25,754] Trial 175 finished with value: 0.04978317864201766 and parameters: {'n_estimators': 1134, 'learning_rate': 0.17412482943742613, 'max_depth': 12, 'subsample': 0.9675162468273513, 'colsample_bytree': 0.8943712560807644, 'min_child_weight': 6, 'gamma': 0.4660744912785835, 'reg_alpha': 3.568313498956354, 'reg_lambda': 8.740139987684767}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  88%|███████████████████████████████████████▌     | 176/200 [35:37<03:31,  8.82s/it][I 2025-01-25 12:27:41,301] Trial 176 finished with value: 0.049504616555872905 and parameters: {'n_estimators': 1898, 'learning_rate': 0.2076590902570864, 'max_depth': 14, 'subsample': 0.951950440513587, 'colsample_bytree': 0.8798025612031607, 'min_child_weight': 2, 'gamma': 0.21644825420460104, 'reg_alpha': 4.2111711580311, 'reg_lambda': 9.769106787642569}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  88%|███████████████████████████████████████▊     | 177/200 [35:52<04:09, 10.84s/it][I 2025-01-25 12:27:50,751] Trial 177 finished with value: 0.05124689119118183 and parameters: {'n_estimators': 1270, 'learning_rate': 0.2575573697735056, 'max_depth': 6, 'subsample': 0.9730897781729149, 'colsample_bytree': 0.8881006619861477, 'min_child_weight': 3, 'gamma': 0.19276769835958998, 'reg_alpha': 5.374654309801532, 'reg_lambda': 9.086869530115752}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  89%|████████████████████████████████████████     | 178/200 [36:02<03:49, 10.42s/it][I 2025-01-25 12:27:59,752] Trial 178 finished with value: 0.04588765110605279 and parameters: {'n_estimators': 814, 'learning_rate': 0.13818773764985845, 'max_depth': 13, 'subsample': 0.9878680381198135, 'colsample_bytree': 0.9175874564664793, 'min_child_weight': 10, 'gamma': 0.02668024250560303, 'reg_alpha': 4.98878313299495, 'reg_lambda': 9.339830486991385}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  90%|████████████████████████████████████████▎    | 179/200 [36:11<03:29, 10.00s/it][I 2025-01-25 12:28:10,540] Trial 179 finished with value: 0.05054927671283597 and parameters: {'n_estimators': 1301, 'learning_rate': 0.10033169334078014, 'max_depth': 12, 'subsample': 0.9339795561717171, 'colsample_bytree': 0.9009486986062946, 'min_child_weight': 2, 'gamma': 0.5293936120726886, 'reg_alpha': 5.9748048987038915, 'reg_lambda': 9.614887505318652}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  90%|████████████████████████████████████████▌    | 180/200 [36:22<03:24, 10.23s/it][I 2025-01-25 12:28:26,024] Trial 180 finished with value: 0.051279644784747704 and parameters: {'n_estimators': 1974, 'learning_rate': 0.07161776459426987, 'max_depth': 14, 'subsample': 0.9063862008491537, 'colsample_bytree': 0.926820629483851, 'min_child_weight': 2, 'gamma': 0.6834327156840969, 'reg_alpha': 5.709579895260945, 'reg_lambda': 8.873710230396066}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  90%|████████████████████████████████████████▋    | 181/200 [36:37<03:44, 11.81s/it][I 2025-01-25 12:28:36,215] Trial 181 finished with value: 0.0464554998142719 and parameters: {'n_estimators': 1157, 'learning_rate': 0.22263852335847262, 'max_depth': 13, 'subsample': 0.9584515938957467, 'colsample_bytree': 0.7464171039884521, 'min_child_weight': 5, 'gamma': 0.012181371402316142, 'reg_alpha': 5.859567349987062, 'reg_lambda': 9.19124290689312}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  91%|████████████████████████████████████████▉    | 182/200 [36:47<03:23, 11.32s/it][I 2025-01-25 12:28:45,467] Trial 182 finished with value: 0.04691124913456027 and parameters: {'n_estimators': 1067, 'learning_rate': 0.24646350430797645, 'max_depth': 13, 'subsample': 0.9848428394073978, 'colsample_bytree': 0.7323172549191332, 'min_child_weight': 5, 'gamma': 0.016120808897664096, 'reg_alpha': 5.555119104449738, 'reg_lambda': 9.283302024505755}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  92%|█████████████████████████████████████████▏   | 183/200 [36:56<03:01, 10.70s/it][I 2025-01-25 12:28:54,209] Trial 183 finished with value: 0.0493294253459778 and parameters: {'n_estimators': 1081, 'learning_rate': 0.17502714872060937, 'max_depth': 13, 'subsample': 0.9762058783359753, 'colsample_bytree': 0.7788104551725635, 'min_child_weight': 6, 'gamma': 0.2751542472204563, 'reg_alpha': 6.041356202290967, 'reg_lambda': 9.829327105074844}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  92%|█████████████████████████████████████████▍   | 184/200 [37:05<02:41, 10.11s/it][I 2025-01-25 12:29:02,805] Trial 184 finished with value: 0.049962727328996606 and parameters: {'n_estimators': 1055, 'learning_rate': 0.19518490842956046, 'max_depth': 13, 'subsample': 0.888253714495698, 'colsample_bytree': 0.7147101978000606, 'min_child_weight': 5, 'gamma': 0.2406922192416692, 'reg_alpha': 5.726233636339067, 'reg_lambda': 8.619875274975405}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  92%|█████████████████████████████████████████▋   | 185/200 [37:14<02:24,  9.66s/it][I 2025-01-25 12:29:25,798] Trial 185 finished with value: 0.04455085795337829 and parameters: {'n_estimators': 1194, 'learning_rate': 0.0455743173942026, 'max_depth': 14, 'subsample': 0.9181954413642645, 'colsample_bytree': 0.907322369969067, 'min_child_weight': 4, 'gamma': 0.006280888666199297, 'reg_alpha': 5.458187772524385, 'reg_lambda': 9.106426473061187}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  93%|█████████████████████████████████████████▊   | 186/200 [37:37<03:11, 13.66s/it][I 2025-01-25 12:29:42,278] Trial 186 finished with value: 0.04983779298810039 and parameters: {'n_estimators': 1336, 'learning_rate': 0.03015231490031134, 'max_depth': 14, 'subsample': 0.9204274334678197, 'colsample_bytree': 0.9083458192019247, 'min_child_weight': 4, 'gamma': 0.43944809239422317, 'reg_alpha': 5.242827889181232, 'reg_lambda': 9.539581585987829}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  94%|██████████████████████████████████████████   | 187/200 [37:53<03:08, 14.50s/it][I 2025-01-25 12:29:56,340] Trial 187 finished with value: 0.04794108625272552 and parameters: {'n_estimators': 1221, 'learning_rate': 0.04837877161764714, 'max_depth': 14, 'subsample': 0.8956672114493714, 'colsample_bytree': 0.8978045194149059, 'min_child_weight': 4, 'gamma': 0.15965387664412073, 'reg_alpha': 5.443997130802061, 'reg_lambda': 9.022320393608139}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  94%|██████████████████████████████████████████▎  | 188/200 [38:07<02:52, 14.37s/it][I 2025-01-25 12:30:05,331] Trial 188 finished with value: 0.05968867223612233 and parameters: {'n_estimators': 1176, 'learning_rate': 0.09682565817366116, 'max_depth': 15, 'subsample': 0.9079324159437873, 'colsample_bytree': 0.8774002590513507, 'min_child_weight': 3, 'gamma': 4.724228406669559, 'reg_alpha': 4.837229257909295, 'reg_lambda': 7.656713007385081}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  94%|██████████████████████████████████████████▌  | 189/200 [38:16<02:20, 12.76s/it][I 2025-01-25 12:30:25,512] Trial 189 finished with value: 0.04499877715959493 and parameters: {'n_estimators': 1782, 'learning_rate': 0.07146401589464402, 'max_depth': 14, 'subsample': 0.874479235557327, 'colsample_bytree': 0.8879116099422646, 'min_child_weight': 4, 'gamma': 0.008385440318984548, 'reg_alpha': 6.1986267454533746, 'reg_lambda': 9.98553952139521}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  95%|██████████████████████████████████████████▊  | 190/200 [38:36<02:29, 14.98s/it][I 2025-01-25 12:30:39,858] Trial 190 finished with value: 0.04979656167798671 and parameters: {'n_estimators': 1780, 'learning_rate': 0.06807065130503956, 'max_depth': 9, 'subsample': 0.8813888295376658, 'colsample_bytree': 0.8669568504989047, 'min_child_weight': 4, 'gamma': 0.39542557389751537, 'reg_alpha': 6.343057177447236, 'reg_lambda': 9.946279940881729}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  96%|██████████████████████████████████████████▉  | 191/200 [38:51<02:13, 14.79s/it][I 2025-01-25 12:31:00,638] Trial 191 finished with value: 0.04475320967347736 and parameters: {'n_estimators': 1862, 'learning_rate': 0.08141204928445497, 'max_depth': 14, 'subsample': 0.8684256410280882, 'colsample_bytree': 0.8834337766537392, 'min_child_weight': 3, 'gamma': 0.005751271837218828, 'reg_alpha': 6.171893780934661, 'reg_lambda': 9.722716610021495}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  96%|███████████████████████████████████████████▏ | 192/200 [39:12<02:12, 16.59s/it][I 2025-01-25 12:31:16,078] Trial 192 finished with value: 0.059752254394667956 and parameters: {'n_estimators': 1864, 'learning_rate': 0.0409843390367973, 'max_depth': 14, 'subsample': 0.865454557166126, 'colsample_bytree': 0.8866668219963353, 'min_child_weight': 4, 'gamma': 3.9481582244443154, 'reg_alpha': 6.6526196387703465, 'reg_lambda': 9.829145006618571}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  96%|███████████████████████████████████████████▍ | 193/200 [39:27<01:53, 16.24s/it][I 2025-01-25 12:31:36,955] Trial 193 finished with value: 0.045093234532445035 and parameters: {'n_estimators': 1918, 'learning_rate': 0.07274077786988925, 'max_depth': 14, 'subsample': 0.8540882286496781, 'colsample_bytree': 0.8918596073343003, 'min_child_weight': 4, 'gamma': 0.009809689404999572, 'reg_alpha': 6.174863444113311, 'reg_lambda': 9.592131570469558}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  97%|███████████████████████████████████████████▋ | 194/200 [39:48<01:45, 17.63s/it][I 2025-01-25 12:31:52,905] Trial 194 finished with value: 0.0487257820862176 and parameters: {'n_estimators': 1928, 'learning_rate': 0.07545402456096714, 'max_depth': 14, 'subsample': 0.873552521551728, 'colsample_bytree': 0.8942538690983677, 'min_child_weight': 4, 'gamma': 0.2229882880865542, 'reg_alpha': 6.183847881324555, 'reg_lambda': 9.659894400871783}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  98%|███████████████████████████████████████████▉ | 195/200 [40:04<01:25, 17.13s/it][I 2025-01-25 12:32:10,259] Trial 195 finished with value: 0.04854039558677899 and parameters: {'n_estimators': 1968, 'learning_rate': 0.06039374534284698, 'max_depth': 15, 'subsample': 0.8931594384158345, 'colsample_bytree': 0.9031155937558027, 'min_child_weight': 4, 'gamma': 0.20684247402206835, 'reg_alpha': 6.386196016821598, 'reg_lambda': 9.644803665783922}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  98%|████████████████████████████████████████████ | 196/200 [40:21<01:08, 17.20s/it][I 2025-01-25 12:32:28,778] Trial 196 finished with value: 0.057349825298649994 and parameters: {'n_estimators': 1906, 'learning_rate': 0.022480843346833437, 'max_depth': 14, 'subsample': 0.873506623033871, 'colsample_bytree': 0.9197044126132679, 'min_child_weight': 4, 'gamma': 2.6925215666756923, 'reg_alpha': 5.591037390781507, 'reg_lambda': 9.475256541852065}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  98%|████████████████████████████████████████████▎| 197/200 [40:40<00:52, 17.59s/it][I 2025-01-25 12:32:43,626] Trial 197 finished with value: 0.049921877904272174 and parameters: {'n_estimators': 1832, 'learning_rate': 0.08319162644177455, 'max_depth': 13, 'subsample': 0.9146586589829754, 'colsample_bytree': 0.8875121153240055, 'min_child_weight': 4, 'gamma': 0.4392318645750575, 'reg_alpha': 5.080816110584589, 'reg_lambda': 9.92013910955443}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...:  99%|████████████████████████████████████████████▌| 198/200 [40:55<00:33, 16.77s/it][I 2025-01-25 12:33:07,607] Trial 198 finished with value: 0.0455109519297563 and parameters: {'n_estimators': 1879, 'learning_rate': 0.04577686419588782, 'max_depth': 14, 'subsample': 0.7561394903059376, 'colsample_bytree': 0.8980953944265001, 'min_child_weight': 4, 'gamma': 0.015330396022621987, 'reg_alpha': 6.5368828353479564, 'reg_lambda': 9.801002303116753}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...: 100%|████████████████████████████████████████████▊| 199/200 [41:19<00:18, 18.93s/it][I 2025-01-25 12:33:24,317] Trial 199 finished with value: 0.049976143860631136 and parameters: {'n_estimators': 1876, 'learning_rate': 0.05428045302759186, 'max_depth': 14, 'subsample': 0.7704829409624072, 'colsample_bytree': 0.9104249389531904, 'min_child_weight': 4, 'gamma': 0.3195159926364575, 'reg_alpha': 6.55040525910983, 'reg_lambda': 9.764218594474011}. Best is trial 83 with value: 0.04395348266902842.\n",
      "XGBoost 하이퍼파라미터 튜닝 중...: 100%|█████████████████████████████████████████████| 200/200 [41:35<00:00, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최고의 MAPE값 0.04395348266902842 \n",
      "\n",
      "최고의 하이퍼 파라미터 {'n_estimators': 1735, 'learning_rate': 0.047728162214790565, 'max_depth': 12, 'subsample': 0.9057125109216521, 'colsample_bytree': 0.8572251007434795, 'min_child_weight': 2, 'gamma': 0.002018000677611335, 'reg_alpha': 5.948268406387103, 'reg_lambda': 9.578684556863058} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# --------------------------------------------- 반년 주기 추가하고 학습  ---------------------------------------------------\n",
    "\n",
    "# ----------------------------------------------------- 데이터 학습 --------------------------------------------------------------\n",
    "\n",
    "# 목적함수 생성\n",
    "def objective(trial):\n",
    "    params = {\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 100, 2000),  # 트리 개수\n",
    "    'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),  # 학습률\n",
    "    'max_depth': trial.suggest_int('max_depth', 3, 15),  # 트리 최대 깊이\n",
    "    'subsample': trial.suggest_float('subsample', 0.5, 1.0),  # 샘플링 비율\n",
    "    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),  # 특성 샘플링 비율\n",
    "    'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),  # 리프 노드 최소 가중치\n",
    "    'gamma': trial.suggest_float('gamma', 0, 10),  # 최소 손실 감소\n",
    "    'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),  # L1 정규화\n",
    "    'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),  # L2 정규화\n",
    "    \"tree_method\": \"hist\",  # 트리 방법\n",
    "    \"device\": \"cuda\",       # GPU 사용\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    'random_state': 1\n",
    "}\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    xgb_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(train):\n",
    "        x_train, x_val = train.iloc[train_index], train.iloc[val_index]\n",
    "        y_train, y_val = log_y_df[train_index], log_y_df[val_index]\n",
    "\n",
    "        # XGBoost 모델 생성\n",
    "        xgb_model = xgb.XGBRegressor(**params)\n",
    "        xgb_model.fit(x_train, y_train)\n",
    "\n",
    "        # 예측 및 RMSLE 계산\n",
    "        y_pred = np.exp(xgb_model.predict(x_val))\n",
    "        mape = mean_absolute_percentage_error(np.exp(y_val), y_pred)\n",
    "        xgb_scores.append(mape)\n",
    "\n",
    "    return np.mean(xgb_scores)\n",
    "\n",
    "# Optuna 하이퍼파라미터 최적화\n",
    "n_trials = 200\n",
    "xgb_study = optuna.create_study(direction='minimize')\n",
    "\n",
    "for _ in tqdm(range(n_trials), desc='XGBoost 하이퍼파라미터 튜닝 중...'):\n",
    "    xgb_study.optimize(objective, n_trials=1, catch=(Exception,))\n",
    "\n",
    "print('최고의 MAPE값', xgb_study.best_value, '\\n')\n",
    "print('최고의 하이퍼 파라미터', xgb_study.best_params, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e4813b-ff28-482b-8bc6-341a786a5231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a97640ae-ca51-4fee-8f6f-8d9beadabcc1",
   "metadata": {},
   "source": [
    "<div style=\"background-color:red; padding:10px; border-radius:10px; font-size:18px;\">\n",
    "시도 6의 결과로 학습 후 제출\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961c7c05-d7fe-4472-bee1-f0337c02b5f6",
   "metadata": {},
   "source": [
    "시도 6 하이퍼 파라미터  \n",
    "\n",
    "최고의 MAPE값 0.043960694841799194 \n",
    "\n",
    "최고의 하이퍼 파라미터 {'n_estimators': 463, 'learning_rate': 0.07986115420116802, 'max_depth': 10, 'subsample': 0.8802837273216751, 'colsample_bytree': 0.900167513749665, 'min_child_weight': 2, 'gamma': 0.0059702090121105614, 'reg_alpha': 3.312339261946142, 'reg_lambda': 7.033865824347269}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0c2ee05-2251-410d-864c-a23d32852014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230130</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Holographic Goose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230131</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230132</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle Tiers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230133</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kerneler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230134</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kerneler Dark Mode</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id        date country              store             product\n",
       "0  230130  2017-01-01  Canada  Discount Stickers   Holographic Goose\n",
       "1  230131  2017-01-01  Canada  Discount Stickers              Kaggle\n",
       "2  230132  2017-01-01  Canada  Discount Stickers        Kaggle Tiers\n",
       "3  230133  2017-01-01  Canada  Discount Stickers            Kerneler\n",
       "4  230134  2017-01-01  Canada  Discount Stickers  Kerneler Dark Mode"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5627be29-ce85-4775-8073-24f0b1a65c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 98550 entries, 0 to 98549\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       98550 non-null  int64 \n",
      " 1   date     98550 non-null  object\n",
      " 2   country  98550 non-null  object\n",
      " 3   store    98550 non-null  object\n",
      " 4   product  98550 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e43deca2-3f77-4201-b64b-27b8c1e5df1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>num_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230130</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230131</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230132</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230133</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230134</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  num_sold\n",
       "0  230130       100\n",
       "1  230131       100\n",
       "2  230132       100\n",
       "3  230133       100\n",
       "4  230134       100"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "203ec278-1c3d-4075-9e48-b0e63a21f2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>year_sin</th>\n",
       "      <th>year_cos</th>\n",
       "      <th>group</th>\n",
       "      <th>mapped_weekday</th>\n",
       "      <th>mapped_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>340</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>340</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>340</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>340</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>340</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  store  product  year  month  weekday  day  week_of_year   day_sin  \\\n",
       "0        3      0        0  2017      1        6    1            52  0.017213   \n",
       "1        3      0        4  2017      1        6    1            52  0.017213   \n",
       "2        3      0        3  2017      1        6    1            52  0.017213   \n",
       "3        3      0        1  2017      1        6    1            52  0.017213   \n",
       "4        3      0        2  2017      1        6    1            52  0.017213   \n",
       "\n",
       "    day_cos  month_sin  month_cos  year_sin  year_cos  group  mapped_weekday  \\\n",
       "0  0.999852        0.5   0.866025  0.781831   0.62349    340               3   \n",
       "1  0.999852        0.5   0.866025  0.781831   0.62349    340               3   \n",
       "2  0.999852        0.5   0.866025  0.781831   0.62349    340               3   \n",
       "3  0.999852        0.5   0.866025  0.781831   0.62349    340               3   \n",
       "4  0.999852        0.5   0.866025  0.781831   0.62349    340               3   \n",
       "\n",
       "   mapped_month  \n",
       "0             4  \n",
       "1             4  \n",
       "2             4  \n",
       "3             4  \n",
       "4             4  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터 전처리\n",
    "\n",
    "# 테스트 데이터 전처리\n",
    "\n",
    "# =================================================================================================================================\n",
    "# ==================================================== 테스트 데이터 전처리 (시도 4로 ) ==================================================\n",
    "# =================================================================================================================================\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------데이터 전처리\n",
    "\n",
    "# 날짜 파생 변수 생성\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "test['year'] = test['date'].dt.year\n",
    "test['month'] = test['date'].dt.month\n",
    "test['weekday'] = test['date'].dt.weekday\n",
    "test['day'] = test['date'].dt.day\n",
    "test['day_of_week'] = test['date'].dt.dayofweek\n",
    "test['week_of_year'] = test['date'].dt.isocalendar().week\n",
    "test['day_sin'] = np.sin(2 * np.pi * test['day'] / 365)\n",
    "test['day_cos'] = np.cos(2 * np.pi * test['day'] / 365)\n",
    "test['month_sin'] = np.sin(2 * np.pi * test['month'] / 12)\n",
    "test['month_cos'] = np.cos(2 * np.pi * test['month'] / 12)\n",
    "test['year_sin'] = np.sin(2 * np.pi * test['year'] / 7)\n",
    "test['year_cos'] = np.cos(2 * np.pi * test['year'] / 7)\n",
    "test['group'] = (test['year'] - 2010) * 48 + test['month'] * 4 + test['day'] // 7\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------ 인코딩\n",
    "\n",
    "country_mapping = {\n",
    "    'Kenya': 0,\n",
    "    'Italy': 1,\n",
    "    'Finland': 2,\n",
    "    'Canada': 3,\n",
    "    'Singapore': 4,\n",
    "    'Norway': 5}\n",
    "test['country'] = test['country'].map(country_mapping)\n",
    "\n",
    "\n",
    "store_mapping = {\n",
    "    'Discount Stickers' : 0,\n",
    "    'Stickers for Less' : 1,\n",
    "    'Premium Sticker Mart' : 2}\n",
    "test['store'] = test['store'].map(store_mapping)\n",
    "\n",
    "\n",
    "product_mapping = {\n",
    "    'Holographic Goose' : 0,\n",
    "    'Kerneler' : 1,\n",
    "    'Kerneler Dark Mode' : 2,\n",
    "    'Kaggle Tiers' : 3,\n",
    "    'Kaggle' : 4}\n",
    "test['product'] = test['product'].map(product_mapping)\n",
    "\n",
    "# (월,화,수,목 = 0) (금 = 1) (토 = 2) (일 = 3)\n",
    "weekday_mapping = {\n",
    "    0 : 0,\n",
    "    1 : 0,\n",
    "    2 : 0,\n",
    "    3 : 0,\n",
    "    4 : 1,\n",
    "    5 : 2,\n",
    "    6 : 3}\n",
    "test['mapped_weekday'] = test['weekday'].map(weekday_mapping)\n",
    "\n",
    "# 월별 매핑\n",
    "month_mapping = {\n",
    "    2: 1, 5: 1, 4: 1, 3: 1,   # 2, 5, 4, 3월 → 1\n",
    "    9: 2, 10: 2,              # 9, 10월 → 2\n",
    "    6: 3, 7: 3, 8: 3,         # 6, 7, 8월 → 3\n",
    "    1: 4, 11: 4,              # 1, 11월 → 4\n",
    "    12: 5}                     # 12월 → 5\n",
    "test['mapped_month'] = test['month'].map(month_mapping)   \n",
    "\n",
    "# 연도별 매핑 (2017년 부터인줄 몰랐어)............\n",
    "'''\n",
    "year_mapping = {\n",
    "    2011: 1, 2013: 1,  # 2011년, 2013년 → 1\n",
    "    2012: 2, 2014: 2,  # 2012년, 2014년 → 2\n",
    "    2010: 3, 2015: 3, 2016: 3} # 2010년, 2015년, 2016년 → 3\n",
    "test['mapped_year'] = test['year'].map(year_mapping)\n",
    "'''\n",
    "\n",
    "\n",
    "# 필요없는 변수 삭제\n",
    "test = test.drop(['id', 'date', 'day_of_week'] , axis = 1)\n",
    "\n",
    "# 데이터 확인\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1827d6bf-3a52-4958-9fd6-5778dbc94dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "           Feature  Importance\n",
      "0          country    0.681670\n",
      "2          product    0.155700\n",
      "1            store    0.146062\n",
      "13        year_cos    0.003463\n",
      "15  mapped_weekday    0.002696\n",
      "16    mapped_month    0.002083\n",
      "10       month_sin    0.001815\n",
      "5          weekday    0.001674\n",
      "3             year    0.001396\n",
      "11       month_cos    0.000928\n",
      "7     week_of_year    0.000723\n",
      "14           group    0.000608\n",
      "4            month    0.000508\n",
      "12        year_sin    0.000380\n",
      "9          day_cos    0.000174\n",
      "6              day    0.000061\n",
      "8          day_sin    0.000059\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 최적의 하이퍼파라미터 가져오기\n",
    "best_params = {  \n",
    "    'n_estimators': 463,\n",
    "    'learning_rate': 0.07986115420116802,\n",
    "    'max_depth': 10, 'subsample': 0.8802837273216751,\n",
    "    'colsample_bytree': 0.900167513749665,\n",
    "    'min_child_weight': 2,\n",
    "    'gamma': 0.0059702090121105614,\n",
    "    'reg_alpha': 3.312339261946142,\n",
    "    'reg_lambda': 7.033865824347269,\n",
    "    \"tree_method\": \"hist\",  # 트리 방법\n",
    "    \"device\": \"cuda\",       # GPU 사용\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    'random_state': 1\n",
    "} \n",
    "\n",
    "# 로그 변환된 타겟 값 사용\n",
    "log_y_df = np.log(y_df)\n",
    "\n",
    "# 최적의 파라미터로 최종 모델 학습\n",
    "final_xgb_model = xgb.XGBRegressor(**best_params)\n",
    "final_xgb_model.fit(train, log_y_df)\n",
    "\n",
    "# 예측 및 지수 함수로 변환\n",
    "y_pred_log = final_xgb_model.predict(test)\n",
    "y_pred = np.exp(y_pred_log)  # 로그 변환된 값을 지수 함수로 복원\n",
    "\n",
    "# 변수 중요도 추출\n",
    "feature_importances = final_xgb_model.feature_importances_\n",
    "features = train.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 변수 중요도 출력\n",
    "print(\"Feature Importances:\")\n",
    "print(importance_df)\n",
    "\n",
    "# 변수 중요도 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance (XGBoost)')\n",
    "plt.gca().invert_yaxis()  # 중요도가 높은 순서로 표시\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7a9b759-bcae-4e99-8e92-199dfd8bb5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_6 = sub.copy()\n",
    "sub_6['num_sold'] = y_pred\n",
    "\n",
    "sub_6.to_csv('sub_6.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643a6e89-8e47-4989-8ffe-2b38c54d85c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063977e5-6cdc-40a0-aaaf-2261a48f3fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
